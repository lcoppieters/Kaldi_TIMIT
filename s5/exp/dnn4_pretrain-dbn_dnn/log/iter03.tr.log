vgnd012
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02_learnrate0.008_tr1.4029_cv1.7852 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03 
WARNING (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:228) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:408) Selecting from 1 GPUs
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:423) cudaSetDevice(0): Tesla K80	free:11372M, used:68M, total:11441M, free/total:0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:471) Device: 0, mem_ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:352) Trying to select device: 0
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:481) Success selecting device 0 free mem ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:FinalizeActiveGpu():cu-device.cc:308) The active GPU is [0]: Tesla K80	free:11300M, used:140M, total:11441M, free/total:0.987698 version 3.7
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.49621, max 8.18284, mean 0.00945758, stddev 0.991793, skewness 0.143257, kurtosis 2.14069 ) 
[1] output of <AffineTransform> ( min -36.9158, max 24.7803, mean -3.38814, stddev 4.48768, skewness 0.127033, kurtosis 1.76697 ) 
[2] output of <Sigmoid> ( min 9.28231e-17, max 1, mean 0.215358, stddev 0.327188, skewness 1.42904, kurtosis 0.509013 ) 
[3] output of <AffineTransform> ( min -25.9107, max 15.9131, mean -3.75423, stddev 2.9191, skewness -0.0761602, kurtosis 2.0435 ) 
[4] output of <Sigmoid> ( min 5.58615e-12, max 1, mean 0.121507, stddev 0.220797, skewness 2.46821, kurtosis 5.45759 ) 
[5] output of <AffineTransform> ( min -13.8568, max 12.6499, mean -3.05433, stddev 2.09663, skewness 0.599693, kurtosis 2.2402 ) 
[6] output of <Sigmoid> ( min 9.59532e-07, max 0.999997, mean 0.123783, stddev 0.204058, skewness 2.56603, kurtosis 6.30078 ) 
[7] output of <AffineTransform> ( min -22.1081, max 17.884, mean -2.07481, stddev 2.09127, skewness 0.373512, kurtosis 3.04519 ) 
[8] output of <Sigmoid> ( min 2.50356e-10, max 1, mean 0.203277, stddev 0.246065, skewness 1.69638, kurtosis 2.03274 ) 
[9] output of <AffineTransform> ( min -15.139, max 17.1658, mean -2.18051, stddev 2.68953, skewness 0.905312, kurtosis 2.0446 ) 
[10] output of <Sigmoid> ( min 2.66202e-07, max 1, mean 0.22032, stddev 0.294785, skewness 1.48454, kurtosis 0.905523 ) 
[11] output of <AffineTransform> ( min -30.0847, max 24.6914, mean -3.98665, stddev 3.58934, skewness 0.640842, kurtosis 2.276 ) 
[12] output of <Sigmoid> ( min 8.59779e-14, max 1, mean 0.139097, stddev 0.280907, skewness 2.1695, kurtosis 3.2627 ) 
[13] output of <AffineTransform> ( min -13.7735, max 21.914, mean -0.0201909, stddev 3.40346, skewness 0.634001, kurtosis 1.05311 ) 
[14] output of <Softmax> ( min 5.50308e-15, max 0.999051, mean 0.000518597, stddev 0.0154139, skewness 45.6047, kurtosis 2338.81 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -2.14548, max 2.16562, mean -0.000859157, stddev 0.0627005, skewness -0.46054, kurtosis 57.6515 ) 
[1] diff-output of <AffineTransform> ( min -0.472156, max 0.303082, mean 4.01177e-05, stddev 0.00910305, skewness -0.441253, kurtosis 108.117 ) 
[2] diff-output of <Sigmoid> ( min -1.96184, max 1.22561, mean -0.000301816, stddev 0.0825806, skewness -0.0508975, kurtosis 15.1227 ) 
[3] diff-output of <AffineTransform> ( min -0.320867, max 0.346753, mean 8.38776e-05, stddev 0.0108244, skewness 0.301832, kurtosis 72.7497 ) 
[4] diff-output of <Sigmoid> ( min -1.57624, max 1.42854, mean -0.000133738, stddev 0.100972, skewness -0.0343748, kurtosis 11.3544 ) 
[5] diff-output of <AffineTransform> ( min -0.407545, max 0.298259, mean 0.000118393, stddev 0.0115137, skewness 0.346781, kurtosis 60.0016 ) 
[6] diff-output of <Sigmoid> ( min -1.74828, max 1.28333, mean 0.00067993, stddev 0.0958488, skewness -0.0528421, kurtosis 10.9736 ) 
[7] diff-output of <AffineTransform> ( min -0.219389, max 0.208335, mean 8.33498e-05, stddev 0.00992333, skewness 0.075154, kurtosis 29.3187 ) 
[8] diff-output of <Sigmoid> ( min -1.04314, max 0.859617, mean 0.000337286, stddev 0.0679991, skewness -0.0554001, kurtosis 9.70139 ) 
[9] diff-output of <AffineTransform> ( min -0.16502, max 0.141056, mean 4.14645e-05, stddev 0.00735951, skewness -0.0574638, kurtosis 30.7543 ) 
[10] diff-output of <Sigmoid> ( min -0.733204, max 0.773562, mean 4.14614e-05, stddev 0.0545313, skewness -0.0449231, kurtosis 8.78218 ) 
[11] diff-output of <AffineTransform> ( min -0.215078, max 0.265719, mean 7.13306e-05, stddev 0.00874697, skewness 0.280828, kurtosis 47.4939 ) 
[12] diff-output of <Sigmoid> ( min -1.3369, max 1.25652, mean 0.000982327, stddev 0.0960164, skewness -0.0746731, kurtosis 5.31991 ) 
[13] diff-output of <AffineTransform> ( min -0.999998, max 0.989034, mean -1.06247e-08, stddev 0.0180146, skewness -26.2459, kurtosis 2018.11 ) 
[14] diff-output of <Softmax> ( min -0.999998, max 0.989034, mean -1.06247e-08, stddev 0.0180146, skewness -26.2459, kurtosis 2018.11 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -2.18064, max 2.22214, mean -0.000317689, stddev 0.140321, skewness 0.0114088, kurtosis 3.43296 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.794793, max 0.697712, mean 0.0102701, stddev 0.149073, skewness 0.0274178, kurtosis 1.38997 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.685043, max 0.873405, mean 0.00403143, stddev 0.0675523, skewness 0.336028, kurtosis 5.56323 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.629889, max 1.06687, mean 0.0214726, stddev 0.172794, skewness 0.40044, kurtosis 2.38594 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.773648, max 0.579133, mean 0.00329458, stddev 0.0449519, skewness 0.425493, kurtosis 8.44895 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.714073, max 0.810848, mean 0.0303087, stddev 0.168676, skewness 0.283392, kurtosis 1.90404 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.527116, max 0.503638, mean 0.00243741, stddev 0.0363009, skewness 0.152869, kurtosis 6.96655 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.573209, max 0.725355, mean 0.0213375, stddev 0.145254, skewness 0.00733468, kurtosis 1.42335 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.394364, max 0.389311, mean 0.0020481, stddev 0.0360073, skewness -0.00999351, kurtosis 3.55537 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.408012, max 0.377785, mean 0.0106149, stddev 0.109777, skewness -0.0565453, kurtosis 0.764501 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.410619, max 0.450836, mean 0.00371901, stddev 0.050235, skewness 0.204056, kurtosis 3.71652 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.456302, max 0.503344, mean 0.0182606, stddev 0.13572, skewness -0.00430475, kurtosis 0.980456 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.81686, max 1.88949, mean -5.1426e-08, stddev 0.0912898, skewness -4.9981, kurtosis 89.023 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.96751, max 1.55399, mean 1.97858e-09, stddev 0.289191, skewness -2.17251, kurtosis 14.5044 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-pdf[5.5.734~1-794732a]:main():ali-to-pdf.cc:68) Converted 3696 alignments to pdf sequences.
LOG (ali-to-post[5.5.734~1-794732a]:main():ali-to-post.cc:73) Converted 3696 alignments.
LOG (copy-feats[5.5.734~1-794732a]:main():copy-feats.cc:143) Copied 3328 feature matrices.
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:384) ### After 1012992 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.21036, max 7.88956, mean 0.00637491, stddev 0.994874, skewness 0.113357, kurtosis 2.26778 ) 
[1] output of <AffineTransform> ( min -44.5555, max 31.4468, mean -3.50207, stddev 4.9452, skewness 0.117035, kurtosis 1.71468 ) 
[2] output of <Sigmoid> ( min 4.46468e-20, max 1, mean 0.226224, stddev 0.340306, skewness 1.34288, kurtosis 0.206966 ) 
[3] output of <AffineTransform> ( min -29.9512, max 21.6924, mean -4.00565, stddev 3.2021, skewness -0.0690457, kurtosis 1.88063 ) 
[4] output of <Sigmoid> ( min 9.8255e-14, max 1, mean 0.122156, stddev 0.22964, skewness 2.43631, kurtosis 5.14727 ) 
[5] output of <AffineTransform> ( min -14.8517, max 13.5277, mean -3.10108, stddev 2.18434, skewness 0.561618, kurtosis 2.10058 ) 
[6] output of <Sigmoid> ( min 3.54791e-07, max 0.999999, mean 0.125612, stddev 0.209068, skewness 2.51821, kurtosis 5.95443 ) 
[7] output of <AffineTransform> ( min -22.9717, max 19.3182, mean -2.03145, stddev 2.16633, skewness 0.370927, kurtosis 2.9263 ) 
[8] output of <Sigmoid> ( min 1.05561e-10, max 1, mean 0.212316, stddev 0.253983, skewness 1.60317, kurtosis 1.64935 ) 
[9] output of <AffineTransform> ( min -15.9342, max 17.5905, mean -2.18671, stddev 2.84407, skewness 0.872987, kurtosis 1.87492 ) 
[10] output of <Sigmoid> ( min 1.20186e-07, max 1, mean 0.227406, stddev 0.304036, skewness 1.41401, kurtosis 0.642062 ) 
[11] output of <AffineTransform> ( min -30.2626, max 25.604, mean -4.21961, stddev 3.88171, skewness 0.579143, kurtosis 2.03162 ) 
[12] output of <Sigmoid> ( min 7.19676e-14, max 1, mean 0.139935, stddev 0.286628, skewness 2.14581, kurtosis 3.10764 ) 
[13] output of <AffineTransform> ( min -15.1309, max 24.9313, mean -0.0177714, stddev 3.68052, skewness 0.607746, kurtosis 0.995238 ) 
[14] output of <Softmax> ( min 2.33281e-16, max 0.999803, mean 0.000518617, stddev 0.0164971, skewness 45.8929, kurtosis 2321.26 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -2.76951, max 1.90067, mean 0.00055787, stddev 0.0571582, skewness -1.29593, kurtosis 93.8887 ) 
[1] diff-output of <AffineTransform> ( min -0.219835, max 0.442931, mean 5.80937e-05, stddev 0.00775226, skewness 0.998886, kurtosis 122.304 ) 
[2] diff-output of <Sigmoid> ( min -1.87108, max 1.98168, mean 0.000405618, stddev 0.0722212, skewness 0.123954, kurtosis 17.1719 ) 
[3] diff-output of <AffineTransform> ( min -0.319519, max 0.253899, mean 7.44908e-05, stddev 0.00940705, skewness -0.0163895, kurtosis 77.1057 ) 
[4] diff-output of <Sigmoid> ( min -1.78787, max 1.18518, mean 0.000224951, stddev 0.0923853, skewness -0.0537598, kurtosis 11.9612 ) 
[5] diff-output of <AffineTransform> ( min -0.269579, max 0.3028, mean 9.67625e-05, stddev 0.0103581, skewness -0.0231822, kurtosis 58.6121 ) 
[6] diff-output of <Sigmoid> ( min -1.29796, max 1.71614, mean 0.000835058, stddev 0.0885416, skewness 0.0829971, kurtosis 12.0228 ) 
[7] diff-output of <AffineTransform> ( min -0.186767, max 0.174286, mean 5.64011e-05, stddev 0.00888187, skewness 0.0580434, kurtosis 31.3263 ) 
[8] diff-output of <Sigmoid> ( min -0.927136, max 1.09843, mean 0.000267836, stddev 0.0615332, skewness -0.0146854, kurtosis 11.0597 ) 
[9] diff-output of <AffineTransform> ( min -0.143808, max 0.131249, mean 3.82895e-05, stddev 0.00651583, skewness 0.00983727, kurtosis 33.167 ) 
[10] diff-output of <Sigmoid> ( min -0.702395, max 0.559085, mean 5.14179e-05, stddev 0.0494603, skewness -0.155885, kurtosis 10.5742 ) 
[11] diff-output of <AffineTransform> ( min -0.19815, max 0.204788, mean 1.63721e-05, stddev 0.00765743, skewness 0.362981, kurtosis 57.0013 ) 
[12] diff-output of <Sigmoid> ( min -1.63369, max 1.36057, mean 0.000677254, stddev 0.0851701, skewness -0.0735631, kurtosis 8.33021 ) 
[13] diff-output of <AffineTransform> ( min -0.999998, max 0.972765, mean -6.32411e-09, stddev 0.0154019, skewness -27.2825, kurtosis 2478.52 ) 
[14] diff-output of <Softmax> ( min -0.999998, max 0.972765, mean -6.32411e-09, stddev 0.0154019, skewness -27.2825, kurtosis 2478.52 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -2.06591, max 2.08298, mean 0.000430443, stddev 0.121146, skewness 0.0422661, kurtosis 3.37384 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.411954, max 0.517966, mean 0.014872, stddev 0.125351, skewness -0.0966652, kurtosis 0.680397 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.588414, max 0.762281, mean 0.00448534, stddev 0.0617873, skewness 0.0246547, kurtosis 4.07138 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.53879, max 0.635591, mean 0.0190697, stddev 0.151946, skewness 0.000475163, kurtosis 1.13289 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.525232, max 0.538652, mean 0.00308426, stddev 0.042269, skewness 0.162193, kurtosis 7.35929 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.727432, max 0.631564, mean 0.0247712, stddev 0.15452, skewness 0.241064, kurtosis 1.60662 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.690494, max 0.440722, mean 0.00181378, stddev 0.0335172, skewness 0.0453692, kurtosis 6.69218 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.716324, max 0.574815, mean 0.0144387, stddev 0.126926, skewness -0.0483648, kurtosis 1.46547 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.409876, max 0.300064, mean 0.00208881, stddev 0.0332468, skewness 0.0969712, kurtosis 2.6431 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.342805, max 0.278378, mean 0.00980213, stddev 0.0945459, skewness 0.121501, kurtosis 0.199452 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.406575, max 0.425224, mean 0.000985179, stddev 0.0467433, skewness 0.113592, kurtosis 3.62199 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.465517, max 0.506363, mean 0.00419126, stddev 0.121461, skewness 0.0688246, kurtosis 1.14724 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.8558, max 1.61242, mean -6.59159e-08, stddev 0.0806237, skewness -4.66443, kurtosis 76.1552 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.84944, max 1.23933, mean -7.41967e-10, stddev 0.250878, skewness -1.83544, kurtosis 9.56835 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:395) Done 3328 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.763398 min, processing 22115.8 frames per sec; i/o time 2.62313%]
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 37614 216 186 380 133 108 339 588 415 2364 944 124 1446 467 142 200 440 282 444 415 596 437 143 810 434 252 254 309 472 738 646 1036 178 243 1381 668 1893 1078 400 136 117 241 135 365 622 468 155 416 3097 14611 2493 618 408 235 51771 1168 777 228 126 428 747 457 798 272 98 454 1896 1626 409 418 2680 178 690 281 333 325 584 1311 226 2446 3054 314 731 182 373 1087 182 328 630 717 294 207 1002 657 60 523 535 375 435 372 386 562 341 1111 328 238 337 276 252 710 996 131 339 179 670 652 666 308 288 1560 404 643 248 145 284 539 576 422 213 1237 470 576 382 533 345 319 612 207 497 390 354 215 758 133 353 358 478 429 280 791 97 527 601 1967 340 367 193 152 311 447 251 328 792 331 757 89 192 136 721 229 272 304 905 374 111 801 237 575 1661 593 78 323 456 229 482 317 137 470 482 1087 211 153 678 175 731 353 540 91 311 197 169 518 123 1173 370 429 388 487 376 167 395 341 363 364 1022 429 233 430 524 207 301 116 1045 235 111 966 500 707 493 383 255 294 217 383 213 394 200 539 443 428 660 328 537 378 272 361 126 279 241 669 167 389 240 433 331 437 427 117 148 383 272 315 871 420 321 1435 93 188 144 353 338 735 760 339 709 614 1416 140 1136 127 890 243 614 583 190 437 272 585 283 566 440 372 165 215 193 356 618 382 266 520 889 244 320 275 506 723 211 206 276 236 548 512 243 430 388 738 338 772 406 465 70 248 481 665 441 373 210 296 440 186 142 344 499 1312 353 472 355 367 1354 308 385 603 167 588 252 196 260 148 237 527 418 784 596 370 758 203 562 290 782 104 502 443 63 543 479 303 174 295 490 191 265 245 235 423 312 168 742 374 222 143 148 65 303 396 412 156 121 128 251 480 821 112 255 233 232 278 270 385 324 114 1345 333 315 1218 1563 314 252 399 372 1243 277 206 610 85 221 722 402 1005 389 424 294 115 494 279 294 209 245 315 1167 433 428 534 239 125 502 276 663 628 512 2599 304 229 381 414 308 946 609 199 1086 164 131 131 171 326 204 2044 177 391 239 260 812 374 820 74 206 244 680 203 323 125 217 193 134 438 364 564 106 241 693 603 251 1088 530 586 374 167 368 316 407 299 448 690 222 487 761 219 122 872 438 117 179 186 442 218 272 329 344 95 310 217 294 494 478 168 456 505 144 153 647 108 483 306 581 69 322 237 751 1361 238 151 286 479 543 359 159 671 435 174 184 766 596 798 303 344 335 222 250 71 844 620 248 292 82 102 449 750 429 418 287 119 311 408 574 263 1945 754 171 301 122 1833 305 488 297 999 784 409 783 668 72 312 345 348 261 290 391 346 522 140 179 263 177 119 631 995 224 649 308 447 323 744 257 161 501 401 163 153 364 452 152 481 373 652 346 925 158 372 307 394 833 339 127 302 375 211 440 317 319 181 455 372 358 777 413 685 160 446 200 749 906 81 462 109 930 915 669 163 242 567 944 219 548 46 573 633 748 611 240 290 121 407 450 361 194 260 129 108 873 599 187 551 178 193 748 810 417 670 136 465 102 327 553 348 164 108 725 535 315 370 197 300 221 322 920 191 407 584 288 182 406 372 375 1085 185 383 693 277 188 526 791 309 337 364 513 297 496 529 348 327 428 339 420 348 311 912 570 215 283 181 197 310 106 491 84 250 182 819 212 579 312 140 478 554 534 191 139 1196 445 315 486 723 232 304 227 930 299 207 695 203 276 1422 309 431 393 294 426 296 448 395 180 462 138 206 89 387 468 269 627 469 824 136 462 410 143 302 116 492 153 211 446 299 169 191 1232 150 764 247 490 325 1056 298 286 301 201 323 238 121 204 155 782 228 191 374 203 1553 143 111 301 571 601 1341 559 161 296 440 208 208 659 27 439 652 212 225 122 291 432 247 388 514 968 272 355 330 311 453 375 381 1796 601 167 154 391 1612 289 934 995 221 236 544 350 411 535 570 258 359 1029 328 119 412 334 503 202 93 538 337 152 286 504 160 737 103 397 386 402 1068 746 201 618 702 198 386 447 661 97 662 757 281 563 365 219 431 957 488 295 223 189 183 149 867 254 158 485 237 725 167 83 130 711 823 272 292 299 482 360 287 897 166 803 393 198 316 305 328 596 35 357 288 124 253 349 93 538 676 219 341 386 988 298 293 374 380 314 122 507 268 560 627 140 200 198 897 221 158 324 930 217 297 444 1331 350 723 383 301 576 394 120 337 627 281 645 486 312 454 903 244 1111 215 649 166 320 386 410 560 700 240 216 702 205 473 303 813 153 851 630 983 929 336 797 403 163 138 302 1163 284 144 920 430 183 352 417 239 235 406 421 385 194 546 537 527 195 440 139 425 253 167 557 616 182 503 316 551 172 350 301 298 313 198 216 1202 720 464 203 388 218 1487 141 1000 216 399 805 708 1049 499 138 390 140 174 363 218 340 334 303 846 382 219 193 705 395 225 507 265 1131 201 1164 377 666 495 1268 1167 379 832 259 397 393 421 361 476 364 269 378 211 958 396 473 1016 469 868 417 367 400 502 1215 1010 499 974 207 211 575 209 136 158 848 405 200 666 668 468 95 413 383 111 361 646 168 196 277 224 1446 706 215 977 140 596 278 517 241 184 595 965 703 164 153 395 723 515 152 362 537 167 769 397 550 1124 1066 365 373 502 356 726 1199 770 198 674 580 381 507 459 121 1126 303 544 707 1190 352 477 384 365 274 275 307 334 372 309 139 490 199 341 551 1239 339 239 514 111 193 343 371 301 411 336 319 197 293 513 239 294 259 1678 731 329 486 1388 255 356 115 479 457 515 298 509 477 669 907 367 166 298 1121 221 393 389 1189 1538 467 642 573 695 292 445 387 316 193 267 354 838 378 1236 358 561 535 421 704 465 604 366 509 364 136 452 276 342 390 512 270 680 716 707 650 202 188 590 222 413 205 164 267 96 496 482 243 362 525 326 483 779 542 429 117 778 627 542 313 430 426 400 236 174 900 562 430 206 615 608 440 744 186 666 511 551 824 190 314 452 441 202 1643 517 555 422 576 365 399 105 630 1462 177 225 688 245 264 405 584 174 300 881 472 366 1215 759 370 195 289 282 238 701 37 150 126 514 960 733 155 994 252 269 322 684 455 509 295 264 385 383 260 789 653 113 166 189 225 20 398 499 301 521 683 126 202 208 755 619 446 519 638 118 320 1393 155 339 221 998 302 152 322 291 292 1078 363 633 952 696 206 163 57 1143 1470 235 750 925 55 949 190 1157 142 238 368 645 432 508 627 292 262 1520 538 221 253 280 568 463 2791 178 681 335 293 531 652 2285 1337 534 204 454 1136 124 101 760 133 763 184 611 606 531 503 467 159 691 773 341 595 123 168 497 209 207 1071 164 282 244 591 588 786 731 413 445 1679 424 221 363 261 358 438 429 376 232 464 108 552 455 196 526 685 689 484 510 402 277 144 219 556 160 295 461 530 367 239 316 721 540 546 363 272 629 766 173 427 218 341 402 420 387 851 297 191 263 412 1258 511 543 630 383 632 350 273 525 249 610 317 383 192 532 927 284 703 1187 345 234 237 529 640 1153 184 205 689 665 682 338 254 448 575 838 1039 528 493 197 317 243 915 614 243 409 211 727 286 532 948 308 151 162 442 480 456 395 1410 1151 499 468 149 663 616 838 373 238 1263 506 1015 160 468 2725 190 667 729 531 314 779 494 448 409 393 217 97 437 381 208 127 720 257 394 438 52 502 969 121 410 194 524 737 213 202 386 329 295 401 324 155 503 363 297 234 642 2282 731 305 1195 780 711 334 338 259 446 228 274 152 1986 3421 196 654 231 219 269 1113 263 375 80 235 893 536 455 155 1863 434 296 224 396 136 176 426 475 182 1538 895 333 996 378 395 182 218 186 156 487 140 1216 174 282 773 446 303 833 426 500 356 282 537 421 492 149 55 187 304 597 388 814 375 1468 614 420 194 258 117 663 574 681 648 139 220 250 424 918 667 312 181 228 357 524 439 524 552 1428 515 332 292 908 191 117 987 582 431 182 557 1382 323 260 1189 861 1231 549 313 646 511 485 435 653 889 769 262 193 633 354 413 455 264 1091 506 177 117 159 2171 2543 405 157 556 363 861 652 680 799 386 346 587 621 491 204 336 434 703 228 623 158 488 450 259 244 641 225 155 626 854 491 373 1849 136 991 194 305 1887 971 715 348 795 551 344 260 660 839 173 401 413 387 386 2469 393 1038 212 254 1036 830 226 244 441 219 583 352 673 3172 414 538 359 402 967 462 85 360 1024 151 268 1352 800 382 462 1131 167 530 312 973 157 135 109 579 1380 577 167 325 660 641 486 120 263 246 324 337 144 415 530 558 277 512 312 643 381 144 742 452 634 1127 406 730 897 847 217 524 129 756 982 267 319 491 292 146 676 373 74 200 267 368 488 440 301 460 235 828 303 748 414 ]
@@@ Loss per-class: [ 0.546163 0.957366 1.17483 1.14246 1.16941 2.25229 1.78915 0.637073 1.27866 0.696407 0.41912 2.22659 0.918868 1.04022 1.57568 1.62462 1.23404 3.09361 1.21735 0.898631 0.977746 0.817571 0.906747 1.17655 1.44606 0.74307 1.04468 0.940324 1.01635 0.667861 0.628284 1.19292 0.808334 1.12169 0.484944 0.467037 0.513 0.336064 1.25248 2.50693 1.64506 1.37369 1.98864 1.06563 0.823553 0.550778 1.2271 1.28902 0.812274 0.899402 0.345709 0.868341 0.767729 1.22545 0.359884 0.918241 0.50742 1.19414 2.04523 0.697285 0.833647 1.55767 1.27559 1.45448 1.35127 1.16788 1.00715 0.928168 0.997565 1.12633 0.50518 1.071 0.660483 1.30503 1.14198 1.20184 0.957522 0.555866 1.70358 0.752999 1.13497 0.876239 0.833442 1.19537 1.71282 0.784061 1.14674 1.99994 1.31855 1.02585 1.24406 1.89882 0.792511 1.34293 1.6458 1.56286 1.41642 1.01258 1.60231 1.19426 1.15397 1.05776 2.15646 0.913288 2.25991 1.29113 0.632174 0.800533 1.7786 1.00164 1.16416 0.990914 1.41844 1.34201 1.52447 1.0267 0.825052 1.00999 1.86436 0.886068 1.07028 0.678676 2.09028 1.20794 1.85419 0.714785 1.88814 1.21213 1.25804 0.919893 0.845484 1.11851 0.864731 1.16028 1.1541 1.20546 0.998696 1.75056 1.52969 1.34188 1.16197 1.14522 0.6267 0.855161 0.651101 1.10377 1.18008 1.78566 1.70877 1.46986 1.43145 0.70383 0.985104 1.32373 0.794523 1.36058 1.60809 0.925544 0.978975 0.879053 1.86308 1.22006 0.686063 1.77232 0.583915 1.20183 0.768957 1.71703 1.16486 1.68459 0.884964 0.463642 1.62532 1.33182 1.52745 0.867848 0.808001 1.08407 0.727354 1.63715 1.21246 1.06675 0.847022 1.56221 0.656026 1.95673 1.51091 0.989266 1.58484 1.1215 1.94733 1.33512 0.562882 0.883028 1.0663 0.893755 1.16766 1.14884 0.939139 1.3021 1.55557 1.31915 1.10934 0.97839 1.1854 0.935816 1.28038 1.17216 0.807524 1.62812 0.72722 0.745455 2.17106 1.69923 0.778775 1.07227 1.06221 0.95688 1.86624 0.647734 0.862723 2.87976 1.14275 2.0546 2.72866 1.75241 1.65372 0.848103 0.829459 1.36301 0.891319 1.93521 1.11418 0.524439 1.37141 0.944182 1.38796 1.54183 0.841627 1.52736 0.379824 1.2436 0.668057 0.78437 0.970981 1.57228 1.41028 1.05067 1.86473 0.631953 0.765864 1.10108 0.869786 0.830867 0.664299 1.3876 0.784925 1.96687 0.869169 0.781002 1.96496 2.32913 0.673558 1.39125 1.00446 0.747277 1.15771 1.0516 2.46557 0.792461 1.51105 0.821163 0.788716 1.55632 1.50253 0.9805 0.444499 2.45892 0.476682 2.01853 0.948901 1.41269 0.676334 1.97646 1.17666 1.03908 1.14495 0.646759 0.896505 1.93955 0.745066 0.8089 0.867197 1.21968 1.15141 1.36996 0.622599 1.50447 0.953221 0.872104 0.537419 1.18265 1.47701 0.972816 0.827652 0.729744 1.26873 0.636756 0.990476 1.32474 1.08994 1.91146 1.18334 0.825428 1.14361 0.636377 1.05814 1.0886 1.21304 0.778268 2.04371 2.3548 1.23184 0.894058 0.853903 2.15472 1.14122 1.46445 0.813527 0.737354 1.36954 1.90173 1.28557 0.477592 1.66351 1.07872 1.11417 1.25274 1.34863 0.937315 0.765207 1.61668 1.55127 1.51697 1.36258 1.14963 1.57597 1.24296 1.26692 1.41165 1.71115 0.608296 1.28444 0.933963 1.65169 1.1876 0.766502 1.24742 1.25761 0.884709 0.98128 2.37964 1.83212 0.657498 1.33416 1.32025 1.13753 2.06364 0.658635 1.41288 1.24292 1.15341 1.86708 0.700656 1.09537 1.20077 0.753656 1.29628 0.742205 1.24344 1.31647 2.07532 1.23666 1.15214 1.36129 1.01143 1.61235 1.06602 2.20544 0.886079 0.902271 1.13482 0.934219 2.40314 1.20278 0.932141 1.12559 1.27388 2.04007 1.46414 0.925084 1.21875 1.46355 1.62141 0.967026 0.90095 0.939314 1.57041 0.501555 0.974944 0.788003 1.40938 0.914953 1.64573 0.959871 1.10781 0.906536 0.447168 0.938314 0.931137 0.977655 1.10694 1.62927 0.710934 1.00822 1.21414 1.66781 1.69714 1.76939 1.15899 0.792901 0.797039 1.67381 1.43918 1.09865 1.55023 0.93213 0.953047 0.720008 0.842691 0.661666 1.14673 0.985423 1.26618 1.43165 1.08558 1.22723 1.84097 0.720498 1.66722 1.88236 1.8519 1.84658 1.1999 1.31949 0.637171 0.916681 1.32786 1.13895 1.60145 0.680063 1.47526 1.07224 1.45226 1.14785 1.3274 0.527005 1.19862 0.981868 2.84929 1.75727 1.80617 1.98873 0.675375 1.56408 0.971856 1.21298 1.50198 1.13677 1.43676 0.789408 0.896458 1.13444 1.03672 1.18704 2.18039 1.3664 0.763156 1.2905 1.01205 1.42419 0.735138 1.07705 1.33819 1.25618 1.52443 1.4734 0.854146 1.19409 1.49536 1.52426 2.41291 1.40061 1.39298 1.05853 0.909817 1.42982 2.36357 1.57239 1.15995 2.16235 1.58647 1.16255 1.32873 0.742175 0.708067 0.981537 0.920648 1.01515 1.66867 1.37653 1.31071 0.999894 1.06402 1.21126 2.52829 1.22556 0.952616 1.57759 1.06279 1.19078 0.972453 1.62607 0.951016 1.72396 1.13192 2.86461 1.05911 1.20648 1.53972 0.763473 1.34736 1.03143 1.51405 1.03061 1.70828 1.90339 1.26381 0.47672 1.21223 1.51932 0.984645 2.24443 1.49802 0.927511 1.21171 1.34774 1.44827 0.831818 1.34865 1.80137 0.792572 0.803235 1.93496 1.38577 1.13811 1.42977 1.53944 1.84998 1.50897 1.47278 1.58204 1.07127 1.04927 0.64877 1.56557 1.0047 1.20566 1.60894 1.48435 1.71946 1.35491 2.27727 1.51321 1.20714 1.14731 1.32946 1.93366 2.44765 0.936862 1.326 1.72277 1.35611 1.74957 1.07909 1.46869 0.946761 1.36941 1.11921 1.41641 0.682935 1.37815 1.47467 1.67792 1.89672 0.834013 1.40486 1.23843 1.12849 1.7593 1.31086 0.623488 0.866623 0.948552 1.35448 1.3784 1.28013 1.25764 1.39946 0.824087 0.873113 2.26337 0.583623 0.792177 1.84498 0.956354 1.33286 0.889399 2.002 1.49287 0.632568 1.19556 1.74631 1.69956 0.881121 1.59546 0.880939 1.57178 1.05747 1.11244 1.13891 1.26694 1.10319 1.16841 0.949531 0.81413 2.05503 2.19093 1.13003 0.964978 1.27545 1.3494 1.26522 1.01947 0.916447 1.72799 1.05048 0.820068 0.97685 1.35454 1.14994 0.832038 1.36363 1.33003 1.9478 1.53808 1.4312 0.672718 2.50316 1.23263 1.13125 1.26836 1.06134 0.882612 1.48757 1.17657 1.08555 1.24056 1.70571 0.937938 0.892103 1.08591 1.39063 2.02281 0.825288 2.29131 2.10661 1.0988 1.35701 2.70937 2.39744 1.88796 0.965011 1.24113 1.44917 0.878648 0.97653 2.61993 1.81794 1.25738 1.19848 1.02833 1.28243 1.02274 0.459343 1.47422 1.15362 1.39945 0.658183 0.975254 1.59182 1.09609 1.15883 2.06978 1.1779 1.16289 1.36393 0.804854 0.993478 1.58535 0.824547 1.19404 1.17806 0.967787 0.798859 1.06499 1.79817 1.2409 2.70057 2.71042 1.86812 1.43387 4.69301 1.37357 1.62857 1.27762 1.21127 0.724899 1.00528 1.45858 1.61782 2.01561 1.39203 1.73419 1.21764 1.49752 1.83274 2.13926 0.796015 1.08096 1.63052 0.761344 1.41133 0.816566 1.23862 1.21352 0.973432 1.34507 1.39712 1.15135 1.64866 1.52478 1.17969 1.8341 2.03725 2.4579 1.04234 1.65041 1.10102 0.891214 1.79219 1.98592 1.51404 1.2494 1.13122 2.20366 1.08552 1.33082 1.24884 1.07695 1.22491 1.95405 1.50963 1.7473 1.4237 1.33655 2.16282 0.807403 1.19057 1.3748 1.80388 2.00475 1.44841 1.24717 1.13313 1.51139 1.01235 0.807592 1.15429 1.5229 1.30878 2.73825 1.37605 1.17592 1.69036 1.85527 3.32844 0.692054 1.00167 1.56723 1.22003 1.71413 1.39747 0.895847 1.54763 2.15045 0.876415 0.707406 1.45577 1.25301 1.50232 1.82811 0.794525 1.20864 0.821877 1.03375 1.26036 1.17188 1.49718 2.13878 0.878983 1.27836 2.08242 1.20702 1.50017 1.49516 1.55531 1.6138 1.45155 1.16916 1.30312 1.0856 1.43268 0.694556 2.5407 0.785471 0.993975 1.48491 1.49786 2.01684 1.32532 0.972896 1.52599 1.24552 0.977183 3.51119 1.4719 1.12255 1.08376 1.87698 1.36376 1.71198 1.60724 2.12946 0.892646 2.12416 1.85352 1.35225 1.05121 1.34804 1.40007 1.5003 1.31285 1.89505 1.57982 1.15526 0.90057 1.23455 0.849448 1.76814 0.910634 1.10998 1.43563 0.622563 1.11491 2.45301 0.998298 1.11727 1.06702 1.05805 1.32806 1.08014 1.8185 1.55441 1.87421 1.27757 0.829485 0.889389 1.74764 2.34086 1.19665 0.664311 1.66177 1.16805 1.26655 1.19873 1.11503 0.916791 1.22198 1.63369 1.13519 1.01501 1.57469 2.59609 1.36007 1.71105 0.946627 0.761401 1.14164 1.25813 1.2615 0.949803 0.762461 0.836318 1.20959 1.71921 0.869206 1.37246 2.10853 1.17409 1.36901 3.62893 1.0825 1.45379 2.134 0.619668 1.71754 0.98313 1.11799 1.26828 1.40829 1.30948 1.22817 1.46185 0.692976 0.879121 1.52377 2.57812 1.03952 1.12447 1.25084 3.65444 1.01248 1.09507 0.976982 1.3674 1.8503 1.36329 1.58887 0.879841 1.27892 1.46187 0.861537 1.16986 1.33045 1.78406 1.13371 0.62043 0.840446 1.09374 1.40455 1.82672 1.25661 0.829033 1.22848 0.940233 0.933515 1.64875 1.39085 0.676329 1.47246 2.20836 1.62539 1.73808 0.859681 1.22815 1.70462 1.23923 2.13202 1.59376 1.33326 1.71658 0.958069 0.890125 1.69178 0.72162 2.94312 1.20804 0.989138 1.28378 1.22267 0.624977 1.13749 1.70534 1.04121 1.30898 1.1466 1.21566 1.07238 2.00785 0.828924 0.960083 2.02605 0.900504 0.642441 1.04467 0.940899 1.49773 1.79399 1.52313 1.08874 1.04628 1.56583 1.36447 1.22916 1.64953 1.43277 1.20632 1.55399 1.12545 1.49234 1.43036 2.24192 2.15247 1.78441 0.872994 0.926036 1.46441 1.41644 1.642 2.0789 1.32311 1.6689 1.70966 0.816006 2.20911 1.3808 1.04796 1.26399 1.52059 1.66007 1.6221 1.03262 1.19405 1.55565 0.638972 2.18425 1.29931 0.938401 1.62479 0.519475 1.37558 1.14803 0.832603 1.24668 2.18583 1.01812 1.13859 1.85898 2.4297 1.17673 1.10239 1.8513 1.77257 1.16288 1.64048 0.966296 1.15965 1.7458 1.14732 1.04218 2.20514 1.29621 2.22012 0.944246 0.968694 0.74194 1.16011 1.87336 1.38878 1.21295 1.52551 2.1826 1.09383 0.95345 1.7453 1.65266 1.88468 1.6048 1.5728 0.881518 2.83555 1.22489 0.911554 1.39502 1.04929 1.05022 1.12349 1.37799 2.70984 1.01688 1.25837 1.08033 1.23657 1.30572 1.54648 1.22112 0.847342 1.15397 1.72115 1.4484 1.11485 1.68153 1.12281 1.20206 1.38204 1.44676 1.22888 1.54699 0.967496 1.31642 1.46808 2.42887 0.844087 2.04106 1.73443 0.822776 1.35127 1.1299 0.887617 1.04162 1.68341 1.26397 1.39469 1.84793 2.44134 1.41492 1.259 1.61697 1.88459 2.23553 1.62246 1.20775 1.74322 2.36805 1.38637 1.06654 1.34293 1.08959 1.30036 1.06776 1.58386 1.76144 0.91189 1.10327 1.52938 0.834196 1.46882 1.11489 1.22862 1.96053 2.01894 1.98018 0.736476 1.5048 1.4535 1.39538 0.48158 1.22582 1.57045 1.38938 0.723173 1.1452 1.9709 1.72345 1.56709 1.57094 0.88394 2.11346 0.950011 1.67007 1.39753 1.08689 0.906801 1.53057 1.19159 1.36396 0.618295 1.53104 1.54069 1.2993 1.4196 1.07539 1.15917 1.62631 1.62831 2.60783 1.38001 1.61347 1.84102 1.45076 1.51826 1.67397 2.04668 1.94017 0.645407 0.615765 1.82048 1.69624 1.40198 2.97643 2.03647 2.06369 2.15711 1.62787 1.27723 1.39235 0.999099 1.21109 0.979692 1.16899 2.10258 1.0768 1.23834 1.71363 1.00935 0.773308 0.928035 0.856721 0.996376 1.10981 1.38575 1.29699 0.764674 1.20157 1.19276 2.16663 2.11511 1.61577 2.59384 1.49351 1.62068 1.19328 0.742561 2.10193 1.14257 1.38334 0.899825 1.42276 1.24431 1.83561 1.86296 1.65723 1.34863 2.40122 1.14253 1.21559 2.05861 1.0037 1.49781 1.00391 2.32868 1.26437 1.34792 1.71712 2.71902 1.02809 1.08526 2.51932 1.24229 1.23001 1.6052 0.737315 1.25536 2.15638 2.0501 0.965902 1.05818 1.2749 2.12141 1.22617 1.79735 0.941805 1.04429 1.6659 1.09562 1.27613 0.896748 1.87137 1.89817 0.979513 2.69849 1.21117 2.4485 0.792133 1.44006 1.24009 1.02543 1.32725 1.47383 1.07088 1.90307 1.68293 1.1433 1.70647 1.53768 1.23572 1.00848 2.05543 1.62003 1.41862 2.31934 0.8643 1.23303 1.6101 1.28758 2.1365 3.63294 0.934896 2.88919 1.73556 0.641735 1.17563 1.50382 1.06613 1.21679 1.04039 1.7924 1.30206 0.948287 1.13684 1.33869 1.3549 1.14332 1.22285 1.09155 1.12187 0.6307 1.34814 1.01511 1.13293 1.2251 1.1584 1.70951 3.86014 0.958604 0.86015 1.26312 1.25149 1.22654 1.90343 2.26793 1.39027 2.4705 1.01257 0.982377 2.21951 0.832569 1.38685 2.13454 3.21481 1.00968 1.3916 1.46762 1.58451 2.33644 1.67738 1.28189 1.23055 1.06714 1.25949 1.42001 0.878882 1.81325 2.63767 1.81149 0.885937 1.22222 1.52725 1.67925 2.33737 1.39829 1.77802 0.705337 1.86225 1.36552 2.68693 0.562943 1.81925 1.0563 1.14144 2.40842 3.31448 0.863243 1.15566 1.46317 1.38303 1.57622 2.33009 2.99699 1.63011 1.72165 1.40192 1.72892 1.28092 0.581575 1.26598 0.765967 1.52364 0.649611 2.31853 1.51176 1.21864 1.24623 1.77134 1.25933 1.65203 1.43956 1.61212 1.4473 0.913206 4.09041 1.26135 1.7335 2.24527 1.45195 1.22488 1.58949 0.731221 1.00212 1.55137 1.64594 2.1776 1.01467 1.33981 2.57284 1.50603 1.30399 1.20835 3.39671 1.6965 1.13652 1.69856 1.49636 1.22977 1.0024 0.864337 2.5031 1.23168 1.30939 1.30096 1.27623 0.895154 2.14196 2.26483 1.30366 1.66867 2.22394 2.05359 1.56461 1.37656 1.66665 1.42013 2.32672 1.00714 0.713653 1.21851 1.33828 1.56744 1.30123 1.15419 1.06371 1.63659 1.43117 1.45026 1.45986 1.44274 1.96489 2.09565 1.57047 0.810836 1.0991 1.31128 2.05364 1.88425 1.73138 1.51536 1.16212 2.26114 1.06358 1.14432 1.15965 2.19128 1.6285 1.68149 1.11835 1.37427 2.40095 1.78056 1.53067 1.6832 1.78133 1.8967 2.00947 2.46641 1.10219 1.19277 1.4674 0.965299 2.17206 1.8737 1.54707 1.69262 1.77741 2.40763 0.987032 1.27492 1.56827 1.99619 0.719809 1.34233 1.42087 1.43618 1.31296 1.28483 1.68344 2.0234 1.19458 1.68423 1.36168 3.04363 1.57956 2.21599 2.36264 2.54586 1.32467 1.4668 1.45999 1.81494 1.15253 1.16548 1.33744 1.61364 1.6729 1.13421 1.6429 1.33675 1.92771 0.975857 1.58502 1.51618 1.21335 1.68532 1.32102 1.08277 0.777867 1.50857 1.35082 1.32545 2.84985 0.968368 1.27675 1.18205 1.51019 2.14521 0.997536 1.69033 1.05908 1.59249 1.50224 1.35564 2.90026 1.74939 1.57627 1.23265 0.846652 1.11492 2.29528 0.825221 0.986233 1.45796 2.32118 2.03452 1.78943 1.18335 1.43712 1.69461 1.66757 1.35572 1.68286 1.86811 1.57286 1.27134 1.06636 1.41255 2.59341 1.53449 0.990652 1.4127 1.38711 1.37429 1.49638 1.40728 1.97658 3.31566 2.53556 1.11908 2.24981 1.32109 2.39299 2.16073 2.05077 2.28708 1.31193 2.33626 1.57155 1.22837 1.4342 1.12618 1.11855 1.04017 0.967314 1.42338 2.04452 2.27237 1.25688 1.33336 1.27973 0.962213 1.26968 0.907734 2.08016 1.19085 1.8818 1.80524 0.605442 1.10108 1.16783 1.06947 1.02459 1.16332 1.5617 1.09111 0.937685 1.43036 1.62509 1.18147 3.22899 0.915714 0.810568 0.971778 1.06394 1.12051 1.2242 1.56787 0.396066 2.42807 1.73355 1.43465 1.83556 0.843412 0.957246 1.74474 0.791104 1.5252 1.36258 1.29872 0.923813 0.647124 1.00708 3.95094 1.37287 1.16612 2.09394 1.02784 1.66163 2.30945 0.710203 1.48192 2.40847 1.81438 1.43758 1.61655 1.59168 0.708059 1.14958 1.80359 1.84928 1.4935 1.5682 2.17001 1.22474 0.977703 1.23554 1.04168 1.11289 1.77242 1.70491 2.0634 1.45835 3.25514 2.54233 2.17988 1.56665 1.0184 1.61665 1.3946 2.00727 0.524789 2.13131 2.07318 2.05802 1.41223 2.664 1.68876 1.37562 1.63839 0.975397 1.13474 1.59709 1.13108 2.96955 0.874264 1.05842 1.47201 2.00437 1.76018 1.65187 2.42254 2.46245 1.59909 1.08013 1.4103 2.08423 1.46968 2.51096 1.36575 2.5573 1.53388 0.871233 1.3781 1.82842 1.60663 0.778249 1.46871 1.44917 0.87272 1.52147 1.61156 1.68408 0.979408 2.23428 0.803562 1.45725 2.24509 1.55058 0.853935 1.62367 1.73743 1.7414 1.15008 1.18175 1.53953 1.47886 1.41313 1.28569 1.1095 1.18514 1.21576 1.1711 1.21175 1.14193 1.24123 1.31063 2.91776 1.29449 2.26125 1.70975 1.96048 1.45074 1.11222 2.41655 0.970302 1.89668 1.10597 1.46209 2.29765 1.51944 1.28574 1.32573 2.16119 2.0317 1.66586 3.12363 1.64368 1.43781 2.96937 1.33654 2.33855 1.15604 1.46959 1.26216 1.52808 1.30514 1.09725 1.38892 0.939753 2.33347 1.64594 1.25036 0.888196 1.4113 1.64419 1.50824 1.46281 1.49591 2.1087 1.40154 1.59387 1.39286 1.74138 1.53976 2.02281 1.50056 0.795471 1.87874 1.01501 1.31053 1.99565 0.899195 0.940021 1.07769 4.68348 1.07597 1.14813 1.56269 2.63485 1.10212 0.861633 0.885367 0.829279 1.32319 1.88278 1.48885 1.7492 3.90398 1.59912 0.922753 1.89814 0.999682 0.8883 1.08447 1.59349 2.48738 1.04193 1.33846 1.14146 1.59747 2.31266 2.58672 1.14519 2.19296 1.17921 1.8821 1.6672 1.08577 1.82746 1.25606 1.12219 1.5325 2.78104 2.90924 0.959816 1.17291 1.26508 2.09816 1.02907 1.70819 2.23526 1.58201 1.55293 1.12729 2.45457 0.800062 1.12569 0.983508 1.10096 0.860559 0.971977 3.29987 1.5703 1.38242 1.15713 1.47807 1.37501 3.26027 1.10211 1.07587 1.68292 1.05225 1.28376 2.35975 2.62879 1.32843 2.1299 3.42471 2.2887 2.14691 2.77483 1.21026 1.10775 2.61761 2.47254 2.56037 1.21507 1.77995 1.76256 1.61581 ]
@@@ Frame-accuracy per-class: [ 79.6368 73.4411 64.8794 60.4468 68.9139 37.788 46.8336 81.9031 61.8532 78.7481 88.0889 32.1285 69.6163 69.3048 48.4211 60.3491 61.975 13.4513 64.5669 72.4428 73.596 72.9143 69.6864 65.7619 53.6249 81.5842 67.1906 68.8207 68.7831 78.673 81.5159 59.5273 76.7507 72.6899 85.9211 87.2102 86.4008 90.3106 63.4207 29.304 51.9149 51.7598 44.2804 60.4651 79.0361 83.2444 61.7363 64.1056 74.7054 68.1039 88.5502 71.1399 76.377 65.8174 87.6312 73.8554 83.3441 61.7068 45.8498 77.2462 75.4515 53.1148 59.9875 61.6514 60.9137 63.1463 67.5982 71.9336 69.5971 66.4277 85.8049 74.5098 76.4663 55.0622 64.4678 62.6728 68.0924 83.4159 50.7726 76.2314 46.8162 73.4499 75.3247 64.6575 44.7122 75.4943 68.4932 37.4429 63.2831 61.4634 60.781 40 80.1995 55.057 47.9339 50.0478 56.0224 67.1105 53.5017 63.3557 66.2354 69.1556 30.1611 68.0162 26.484 60.7966 84.1481 77.396 48.7129 73.4694 66.2318 73.0038 54.4919 67.4095 54.7353 73.2567 73.9685 67.423 47.1404 69.7212 62.7936 78.3217 39.0342 68.0412 47.1002 79.5181 33.6513 66.7456 61.8267 75.5556 77.7896 65.2212 77.1242 64.8547 64.5441 61.0329 70.0408 42.8916 53.8693 63.5083 65.7264 64.9652 79.7627 68.1648 79.4908 66.9456 65.4127 47.0314 57.3975 55.0853 58.4615 75.8294 68.9942 60.1271 76.0646 59.8639 54.7804 70.1639 69.9839 71.0615 48.1113 60.8828 79.3691 46.1538 81.9802 65.9218 80 44.6886 68.3299 47.0588 74.1284 85.3859 54.1137 58.2109 55.6054 74.8596 78.3158 69.1573 78.062 50.0421 66.242 68.9335 75.1369 51.4161 79.5855 37.4803 52.3636 73.9639 54.9223 65.1954 43.9716 59.2834 82.9772 70.0855 69.7198 74.3989 67.5301 63.388 75.7624 60.2532 53.6873 57.6663 69.6356 67.9165 65.0472 73.1083 63.0631 65.8462 77.2908 44.1791 76.6119 79.063 41.5406 52.6749 76.088 70.78 68.9507 69.6864 32.2212 78.0723 74.6269 18.8841 66.4754 42.0382 17.9372 49.7672 59.7403 74.7703 77.4063 59.7132 72.7984 47.1986 68.046 82.9205 59.0164 71.7364 56.8579 52.456 73.0552 50.175 90.0833 63.0137 80.186 75.2972 77.4312 54.7718 57.7075 71.9141 55.0725 80.5078 74.0299 70.6033 78.1705 76.8166 81.448 60.3429 74.8538 43.4043 76.0943 77.4446 40.7339 27.8922 81.354 59.6908 69.3624 77.325 64.1711 67.9045 24.2215 77.5106 58.7888 76.1387 78.238 52.7246 56.9415 66.7209 87.3985 32.0285 83.15 29.0196 70.2976 57.4949 81.6924 46.958 72.9659 73.8286 64.9541 80.4441 72.3104 44.3071 76.958 75.1678 70.6949 60.3248 58.3979 61.1501 81.4875 50.1961 69.7936 74.3516 83.7549 63.8037 59.9064 73.6842 74.0375 79.0601 58.6288 80.3874 71.6094 63.0021 68.7329 51.5122 68.1725 76.6551 63.8353 81.7874 65.5835 69.7735 59.5326 75.6176 51.0638 38.2294 66.0436 76.6341 72.9332 43.3735 64.6081 52.6138 74.6879 75.067 62.4561 43.8316 59.2593 86.0952 58.5573 66.455 70.0422 65.034 60.9819 73.5818 74.9676 46.396 60.2985 57.6041 65.7426 65.1399 54.8944 65.3199 64.8421 59.5261 54.4803 82.4729 65.7167 71.7949 51.0218 66.3391 79.2889 64.3718 60.7029 70.8134 75.2239 35.1747 40.9449 82.2447 60.4797 58.3196 65.9026 36.8866 80.9378 62.141 63.2768 70.0611 47.983 80.5195 69.44 67.0623 76.229 60.8812 78.6517 59.9303 63.2997 42.7481 61.6145 63.3039 61.8182 71.5655 51.8519 71.5953 47.7137 72.2164 73.6458 62.2222 69.6673 29.1221 64.5161 75.4039 70.61 63.2944 38.2126 57.6419 71.126 64.4678 52.6149 50.9643 70.0352 72.496 76.0396 55.3191 85.1007 71.1701 75.3153 59.0799 75.6757 59.6491 70.8804 65.6055 72.5466 87.2203 71.3736 73.9694 67.9117 71.8615 55.814 77.6386 75.0424 61.0979 51.3238 49.7623 47.6231 62.2837 71.8786 77.8297 56.785 60.5578 62.8856 54.6112 72.6451 74.6221 78.6341 76.7071 80.7882 67.9739 65.7929 63.4499 56.0778 69.308 62.6743 47.619 80.5338 52.8875 54.7529 52.4715 48.3965 62.7871 63.5697 80.8511 74.3662 61.0473 68.0585 47.6008 81.6 57.1429 71.0542 64.4295 64.891 58.0777 84.3497 68.3047 72.9521 25.498 58.8506 42.3773 46.8401 77.5371 61.7284 74.4021 65.7277 59.6273 64.5999 56.8351 77.9324 73.0363 63.3365 71.2702 65.9546 38.209 56.445 76.4613 58.8957 68.4474 61.3155 79.0731 74.1573 63.1795 67.2357 49.6583 60.4082 75.1862 61.5735 57.8723 51.8106 33.7802 63.5028 56.7506 67.5229 71.9272 60.3774 34.555 55.0725 62.5287 40.747 53.185 66.4577 62.908 76.8894 76.9535 68.5121 72.3127 70.7336 54.3779 59.152 55.4649 72.9149 71.9424 66.6667 39.5789 63.2069 70.2901 49.8952 75.2475 65.9686 74.244 54.0938 70.0974 54.5455 67.4609 25.2583 69.341 68.8347 57.4038 76.6136 52.0977 72.4876 52.2496 66.1699 64.2697 45.509 60.1399 86.5601 65.5923 55.5332 69.0598 37.5758 58.5366 70.9677 63.9574 62.3981 57.5866 77.2174 63.5983 52.9695 74.6634 72.0627 43.6433 53.5595 69.3174 68.2216 56.0531 40 47.6684 56.3011 53.4289 70.2521 68.8344 82.0905 57.6313 68.2833 64.3231 60.6897 50.56 41.3893 62.8407 43.2122 60.5852 66.9221 62.3377 61.244 51.2456 34.5404 71.7268 64.7887 51.046 58.749 46.6097 68.5969 50.0385 70.9887 60.5587 67.3879 55.3392 80.7767 63.7771 52.4427 55.0436 51.3761 78.8274 62.8258 63.8674 70.8197 48.3904 60.241 81.3793 70.4185 72.8255 69.4006 61.745 61.4634 64.3853 57.5885 73.6377 76.0784 30.4132 80.9587 76.1229 45.63 71.4961 59.7809 77.135 46.5423 58.255 82.0084 65.0804 54.4135 50.3282 77.2586 51.7357 73.8155 50.4336 65.8577 69.9387 67.4595 58.4475 64.9113 65.6472 73.0396 79.5107 42.4742 27.6652 65.1138 68.3371 59.6171 60.2151 56.6696 68.824 73.0795 48.242 72.7651 75.043 70.7819 62.3313 64.3729 79.9447 60.1542 53.7428 54.0541 57.1429 55.5238 79.0659 24.5333 66.1831 64.986 65.6331 70.9419 74.7687 57.9641 67.5615 68.8645 62.2986 52.6829 74.8092 74.7967 68.0057 57.1429 51.6129 75.8098 40.8964 34.2314 70.1754 62.7848 27.9534 37.4718 50.2326 69.4188 62.6632 58.6503 75.4491 71.7504 25.7534 46.4945 62.5503 64.7137 71.7642 60.9164 71.1864 86.9503 60.9009 67.374 60.7787 81.4908 73.021 53.9259 65.5693 66.0175 41.6807 67.6737 65.7224 59.3974 75.4198 66.5111 55.9647 74.9108 65.7102 67.4157 71.6712 76.5995 68.2135 54.6737 58.4022 30.8861 29.6296 46.9484 63.6826 7.10059 63.0739 53.6986 64.4295 66.8235 78.3434 70.72 64.0569 52.4556 47.0694 58.9336 46.9974 62.3656 56.331 49.1582 41.5214 73.7924 67.3117 52.4731 74.8768 55.3846 78.345 66.778 66.988 69.734 58.4767 61.4828 63.1283 46.2036 53.7659 67.3443 52.6316 45.2521 40.1349 68.4504 50.0632 68.6981 75.027 51.2635 41.1622 60.3352 64.2581 65.9552 40.4453 68.0478 65.1757 67.4348 64.4689 59.2432 42.3873 55.7491 46.281 62.6609 59.8985 41.6938 76.1229 67.1892 58.0968 44.8378 41.2533 56.7951 65.7807 64.3558 61.0101 71.3558 79.2627 67.3923 55.9464 64.5724 25.539 60.0496 66.7697 54.5073 51.0288 26.4059 81.672 72.8435 50.7659 63.7076 52.0694 55.5283 72.224 51.5679 41.2556 74.9585 79.2651 56.0266 62.8401 57.1939 47.0588 77.2344 69.0125 79.1367 64.7482 66.5656 80 61.2059 40.613 71.0588 62.5277 42.449 64.494 53.6416 56.1616 53.7967 49.5627 57.8214 62.0183 54.8523 65.053 61.9583 81.3671 33.2889 79.4233 71.4723 54.5303 54.9254 49.1909 57.9821 72.4961 60.1036 64.7405 75.5399 15.3499 60.4651 60.0551 71.8973 49.3317 59.197 48.3786 49.1296 40.3338 75.2793 45.3577 47.6987 61.8182 67.5635 57.3982 53.3333 62.0321 64.8097 35.8519 49.8361 69.808 69.7721 55.4517 77.8305 47.343 78.239 65.4592 54.9068 81.329 71.9357 32.2581 70.8165 66.7616 65.4912 71.4101 60.3352 67.5737 51.2821 57.2075 36.1716 63.5879 73.6469 71.1354 56.0364 31.7497 63.9164 81.2692 51.7766 68.9038 63.8522 62.6703 63.5452 72.2767 64.4401 59.306 71.2667 72.8421 52.5155 30.4478 59.8802 52.1073 74.2094 77.7171 71.9266 66.6667 66.4441 73.1606 77.1151 79.3043 61.9499 49.2492 73.3043 63.2783 38.7909 66.3507 63.8298 19.4825 66.3873 53.5211 40.5594 84.5754 49.7992 74.9507 60.9442 65.2406 48.6537 63.4146 67.8815 60.0293 78.3959 71.219 61.6415 40.8859 66.4887 66.2286 63.593 17.9592 73.1034 66.6667 72.0785 61.3546 43.4164 61.8454 55.4156 74.0947 64.1084 57.4132 74.8844 64.5889 59.7701 44.3697 66.5917 81.6373 74.1797 67.5881 63.3638 55.7214 65.3946 79.0875 64.7303 71.7037 73.9442 54.3517 56.3904 80.1644 60.48 43.1243 52.352 44.1718 76.3833 64.0371 50.0385 63.6637 34.6334 50.194 63.581 47.9929 70.5211 73.5967 42.9561 80.427 20.9246 64.6251 64.2504 59.1272 60.5863 81.0335 67.8826 47.2801 71.0059 61.2184 68.9655 67.4102 72.1713 43.3213 74.7107 71.7662 50.2636 71.9723 80.6084 69.6864 68.6649 53.9007 42.8743 53.8622 68.3652 69.6187 53.1435 56.2905 61.6967 47.9414 56.5581 64.8341 47.0588 66.7423 63.0824 61.1046 31.9527 53.7313 47.3543 76.5612 70.137 57.1996 57.8199 48.9574 50.4348 55.0642 54.063 54.2714 71.7703 42.3174 54.5035 70.7692 63.9833 52.5296 49.6314 54.0541 67.7346 63.1261 55.8304 82.3588 42.4942 59.0738 72.6257 50.247 84.04 58.2583 63.5379 76.0563 66.1922 37.2493 70.4264 60.8696 39.3539 29.5964 64.5799 63.4377 43.6601 53.303 65.1163 52.3033 72.0607 66.0754 48.867 66.6667 70.3491 46.6501 61.228 25.6954 70.3676 70.4339 77.5719 62.0128 47.4308 58.2583 65.5106 54.3396 38.1194 66.9039 68.0498 50.787 54.321 51.9481 55.4822 55.3191 73.9697 34.8045 62.9356 75.2582 59.4249 65.285 68.7425 66.3946 59.4257 27.4627 67.2974 62.8402 71.2713 58.3889 64.0964 55.3191 63.2493 74.463 68.1319 46.0568 59.7525 64.1184 46.8828 63.1658 59.5363 60.619 55.4974 60.7013 57.6271 71.7489 55.0484 50.2707 42.73 73.2824 33.5135 49.8886 77.1517 61.9958 64.5012 71.202 62.6335 54.4845 63.1957 58.744 50.5176 31.4363 58.9421 66.0798 54.2999 56.535 35.8306 52.086 66.3442 49.4665 31.4754 60.4138 64.9302 53.7313 70.4353 64.6541 70.2997 49.3553 49.6015 72.5034 65.5957 55.9204 75.1753 58.9126 70.0292 63.3355 45.3401 45.0704 41.5159 78.3748 56.3547 57.2361 56.7901 85.1309 63.5914 57.1166 59.5053 79.7984 63.5461 45.0262 52.0156 61.2859 51.7304 75.1361 28.6179 75.6353 52.6174 58.8045 66.6667 73.1906 59.6491 61.4934 60.7434 83.8241 59.2047 53.8622 60.447 50.2242 68.7339 71.3246 56.5276 57.7114 28.4326 60.6241 51.9562 48.6076 55.1959 56.2804 50.9395 46.18 43.5453 81.263 84.0738 48.5584 43.5766 58.4084 22.7006 44.6003 40.6926 34.4108 48.5246 61.8817 64.9916 67.7134 64.9215 71.2472 67.6584 41.6327 66.6667 60.3015 46.3665 66.8172 76.493 72.1438 70.1135 67.4683 71.6578 62.7237 60.1569 76.9231 65.2991 65.0954 44.3871 44.8657 52.7132 26.9159 57.5458 54.025 60.2378 75.5358 47.6987 63.5797 62.7451 73.5469 60.6104 64.232 50.4549 47.749 46.1237 58.4362 30.0366 63.8674 67.9928 44.6715 70.4225 57.1707 73.1978 33.2109 62.247 62.7562 51.96 37.037 73.7401 60.1185 31.4607 60.2177 61.8005 55.9271 81.4953 65.285 37.0594 39.171 67.7618 69.2414 64.1294 40.4288 63.4953 55.805 73.7327 69.383 62.9787 71.034 64.0637 75.9447 41.4673 47.619 70.5744 30.4619 67.2304 34.384 77.9567 57.0667 62.2532 67.3123 64.5004 54.5604 73.0988 45.6682 52.0107 67.6669 52.7859 54.3971 65.4942 70.8661 44.5151 50.8287 59.1166 32.0988 74.962 58.9372 51.6652 64.142 39.7225 16.4159 72.8411 18.0095 49.0087 81.5043 63.662 52.7716 64.3428 63.5438 68.0529 53.021 57.6561 72.7794 67.5541 62.9609 60.3175 64.6658 65.1584 71.8894 66.3968 83.376 62.1762 74.6903 66.2474 61.7249 69.3333 53.8206 13.4387 72.1088 75.0651 62.304 68.8103 60.9351 52.2772 38.961 53.9535 33.8934 71.5697 69.8724 37.225 71.0775 55.5123 38.3312 20.3455 67.7644 59.5256 52.8634 60.6607 49.0765 45.2328 58.5366 67.2522 65.2653 66.0033 58.1016 72.1287 41.8972 35.5556 53.2374 74.2555 66.3438 57.1109 50.6256 36.4918 54.8523 45.5538 78.6509 46.3023 60.6775 32.9571 82.7241 46.6116 69.5082 68.2171 29.1595 31.1111 75.197 70.1513 54.3015 60.0525 53.2663 38.2567 22.0183 62.6087 47.3983 62.4277 45.0106 61.8254 80.0648 57.6577 74.9868 57.7428 79.8272 36.4912 52.8302 58.616 63.0519 53.4104 62.5369 53.2271 59.1453 57.1429 52.8773 72.9805 14.447 63.9053 54.902 43.6236 56.9579 65.4487 54.3417 79.0902 70.6408 58.2624 52.4929 35.5556 71.3192 60.4112 37.4181 57.2127 58.3058 64.2323 25.7028 52.2167 64.8258 59.176 54.093 68.2927 70.3189 77.1641 26.1524 64.7468 63.1016 68.9655 61.1714 74.596 38.9458 41.9815 51.8219 53.4125 33.9698 42.0048 57.3494 62.3425 51.6717 58.7611 39.2638 67.6247 77.825 61.0299 61.7908 55.8646 65.5443 64.2453 67.1378 51.4673 61.0729 61.1855 53.8354 57.9247 40.5122 43.5591 55.914 76.4263 64.5161 60.2715 32.9308 46.3104 47.8632 58.0598 64.2495 40.4541 66.0137 66.3354 65.2252 34.6021 51.4806 56.4241 70.405 60.5753 36.8364 50.1414 47.8912 57.62 50.5529 42.8274 37.7428 33.6688 68.2256 62.0183 58.618 72.7984 36.8876 57.076 56.7506 50.9517 47.9503 36.3853 73.8065 63.1826 59.8319 45.4308 77.4194 64.4848 58.5618 60.0196 64.5814 59.4766 55.2803 49.3281 64.7646 51.1883 58.8011 29.6593 54.5455 40 36.5059 27.013 60.8451 60.0539 56.239 43.7811 61.5579 62.2287 65.2452 53.0526 52.1246 67.7596 48.2011 59.0786 38.9294 67.4402 52.2915 53.3333 63.5155 48.3301 69.3423 71.0686 77.5194 52.8139 65.6575 61.6008 28.8608 71.1811 65.7084 66.3026 55.0041 43.1211 67.3993 60.5201 72.5773 53.4031 59.5305 57.8809 38.8979 56.1056 60.9231 63.5028 72.2164 70.5367 36.1568 77.9156 71.9931 58.2583 36.0726 50.1672 48.6812 66.18 58.4377 46.8541 54.0881 61.1793 54.689 48.5475 56.6978 61.8997 68.0976 64.5669 28.015 58.6703 70.555 52.4642 56.9596 60.2629 57.748 57.1429 44.9809 19.3103 19.4872 66.5143 46.1337 58.5132 42.3529 34.9757 39.6117 40.0507 60.2052 38.0952 53.3333 59.6184 60.9053 68.9403 66.3239 69.7807 67.2542 57.6112 44.4444 41.1384 63.7329 60.2369 64.01 67.7966 54.6624 72.4926 44.8418 65.8824 47.3348 47.4708 80.4381 62.0643 64.4845 67.1685 74.1832 68.4469 55.0075 70.901 74.3738 55.0952 52.0788 64.4809 17.0492 69.5696 67.4558 71.2468 69.6715 66.0907 67.8815 52.3191 87.6515 35.6736 53.7949 59.6273 43.7367 75.4337 75.1165 48.9572 79.0997 50.711 65.5926 63.4064 72.6058 80.7062 67.3993 7.93201 64.0094 66.4564 38.9041 69.0283 51.8146 38.6807 79.8796 64.9934 35.3982 47.6712 55.3776 54.6917 52.3962 79.3846 60.4982 46.3625 45.2722 63.7168 53.0058 39.4177 57.3311 71.8656 60.7268 71.5285 70.1262 49.5575 55.6279 41.9929 60.9137 20.7358 36.036 35.2 60.0985 67.7824 58.1725 59.0546 50.0666 85.5295 41.4972 34.9584 44.2159 61.1219 39.1489 50.0377 62.8372 50.1834 72.6291 63.0824 48.9796 67.0659 27.3263 71.5297 71.0112 58.24 55.0964 47.2648 54.2657 38.3222 35.7224 54.9094 65.5204 52.4326 41.7071 60.4511 32.1368 57.0171 34.9869 61.2766 75.5443 58.0258 48.6674 51.5068 75.157 57.5769 58.1144 77.9271 56.9147 53.2792 50.7511 74.6133 37.6396 76.8755 57.2825 39.3409 53.2721 74.5218 52.2766 46.1339 53.7143 59.9483 64.7198 53.3145 51.0278 54.8847 62.3819 66.6056 65.3504 68.7324 61.2766 66.4577 65.2084 57.5978 61.4057 25.3968 59.8383 42.3659 52.2345 47.8161 61.2785 64.7905 31.0479 73.0159 40.1702 68.8656 54.7304 34.2298 51.4116 63.9816 59.8436 43.326 40.417 52.9968 24.1556 54.384 58.1888 28.6299 62.0421 37.2506 67.5241 52.0351 63.5459 63.2757 62.6506 68.6672 65.2015 69.1881 31.8766 50.0818 59.1258 72.4653 52.97 54.5194 50.4085 56.9356 56.0232 46.0653 63.7396 52.8886 61.0951 42.8394 59.734 41.8065 56.1449 76.4932 48.5388 68.3678 63.0588 44.4008 73.7096 75.4967 63.1347 6.54397 69.9887 63.7813 47.4722 26.383 67.2606 74.5784 75.2714 72.9805 58.4145 33.2919 57.261 48.8649 10.5263 52.982 71.0591 42.9043 69.6462 70.6839 68.2074 55.1634 33.0811 68.0513 61.4925 65.033 59.52 34.8228 40.6349 67.1587 34.7032 66.0915 48.8953 47.619 75.8209 50.384 63.7396 71.2393 58.5817 22.4066 26.5655 74.2394 69.0293 63.7037 43.5986 70.7581 55.4194 37.2426 57.6577 58.1463 70.08 34.4988 76.0157 70.5882 73.4007 72.9282 76.911 71.929 22.1402 52.1561 61.6156 67.3746 59.7701 62.7264 23.166 68.341 67.9898 51.5888 72.6135 65.3103 39.6581 36.1775 62.5277 34.5382 29.5302 32.9177 45.2336 27.6798 62.2313 70.6016 25.2073 32.5733 36.0934 66.6264 52.0593 51.7034 50.1809 ]

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.19669 (Xent), [AvgXent: 1.19669, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 64.8534% <<

