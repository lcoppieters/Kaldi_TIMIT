vgnd012
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.004 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03_learnrate0.008_tr1.1967_cv1.7555 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter05 
WARNING (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:228) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:408) Selecting from 1 GPUs
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:423) cudaSetDevice(0): Tesla K80	free:11372M, used:68M, total:11441M, free/total:0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:471) Device: 0, mem_ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:352) Trying to select device: 0
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:481) Success selecting device 0 free mem ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:FinalizeActiveGpu():cu-device.cc:308) The active GPU is [0]: Tesla K80	free:11300M, used:140M, total:11441M, free/total:0.987698 version 3.7
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.49621, max 8.18284, mean 0.00945758, stddev 0.991793, skewness 0.143257, kurtosis 2.14069 ) 
[1] output of <AffineTransform> ( min -38.4348, max 27.6271, mean -3.4825, stddev 4.94866, skewness 0.118376, kurtosis 1.69988 ) 
[2] output of <Sigmoid> ( min 2.03216e-17, max 1, mean 0.227315, stddev 0.340789, skewness 1.3345, kurtosis 0.185186 ) 
[3] output of <AffineTransform> ( min -27.7644, max 16.3063, mean -4.02436, stddev 3.19782, skewness -0.0896993, kurtosis 1.79987 ) 
[4] output of <Sigmoid> ( min 8.75158e-13, max 1, mean 0.121024, stddev 0.22784, skewness 2.44937, kurtosis 5.2351 ) 
[5] output of <AffineTransform> ( min -14.288, max 12.7787, mean -3.10476, stddev 2.15837, skewness 0.568866, kurtosis 2.12252 ) 
[6] output of <Sigmoid> ( min 6.23462e-07, max 0.999997, mean 0.124111, stddev 0.206647, skewness 2.53874, kurtosis 6.1011 ) 
[7] output of <AffineTransform> ( min -21.9102, max 18.6468, mean -2.03808, stddev 2.13635, skewness 0.367257, kurtosis 2.8887 ) 
[8] output of <Sigmoid> ( min 3.05143e-10, max 1, mean 0.209905, stddev 0.251559, skewness 1.62917, kurtosis 1.75358 ) 
[9] output of <AffineTransform> ( min -15.4435, max 17.7514, mean -2.20951, stddev 2.8148, skewness 0.891778, kurtosis 1.96735 ) 
[10] output of <Sigmoid> ( min 1.96315e-07, max 1, mean 0.22362, stddev 0.301469, skewness 1.44707, kurtosis 0.749431 ) 
[11] output of <AffineTransform> ( min -30.2683, max 25.4535, mean -4.22716, stddev 3.85059, skewness 0.579486, kurtosis 2.08226 ) 
[12] output of <Sigmoid> ( min 7.15541e-14, max 1, mean 0.137707, stddev 0.284249, skewness 2.17585, kurtosis 3.24798 ) 
[13] output of <AffineTransform> ( min -14.4358, max 23.8413, mean -0.0191346, stddev 3.67634, skewness 0.611707, kurtosis 0.99976 ) 
[14] output of <Softmax> ( min 3.55495e-16, max 0.999428, mean 0.000518613, stddev 0.0160181, skewness 45.329, kurtosis 2290.9 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.67329, max 1.95007, mean -0.00108696, stddev 0.0670144, skewness -0.599113, kurtosis 34.3252 ) 
[1] diff-output of <AffineTransform> ( min -0.27283, max 0.22655, mean 5.61393e-05, stddev 0.00894115, skewness 0.34414, kurtosis 55.2295 ) 
[2] diff-output of <Sigmoid> ( min -1.21213, max 1.29441, mean -0.000160561, stddev 0.0842051, skewness -0.0423586, kurtosis 11.768 ) 
[3] diff-output of <AffineTransform> ( min -0.243014, max 0.261898, mean 8.71774e-05, stddev 0.0109823, skewness 0.293789, kurtosis 60.5981 ) 
[4] diff-output of <Sigmoid> ( min -1.33473, max 1.37617, mean -0.000170556, stddev 0.106316, skewness -0.0194402, kurtosis 9.95692 ) 
[5] diff-output of <AffineTransform> ( min -0.259363, max 0.295922, mean 0.000127249, stddev 0.0119395, skewness 0.432884, kurtosis 52.5273 ) 
[6] diff-output of <Sigmoid> ( min -1.81381, max 1.4093, mean 0.000741619, stddev 0.101316, skewness 0.0112277, kurtosis 10.4456 ) 
[7] diff-output of <AffineTransform> ( min -0.218154, max 0.20562, mean 9.06037e-05, stddev 0.0101773, skewness 0.161112, kurtosis 28.7957 ) 
[8] diff-output of <Sigmoid> ( min -1.17225, max 0.921035, mean 0.000362486, stddev 0.0698387, skewness -0.0173022, kurtosis 9.87677 ) 
[9] diff-output of <AffineTransform> ( min -0.191069, max 0.164532, mean 3.75523e-05, stddev 0.00743371, skewness 0.0722784, kurtosis 32.561 ) 
[10] diff-output of <Sigmoid> ( min -0.819641, max 0.78792, mean -7.31473e-05, stddev 0.0561848, skewness -0.0361399, kurtosis 8.94048 ) 
[11] diff-output of <AffineTransform> ( min -0.233631, max 0.22822, mean 7.4813e-05, stddev 0.00875411, skewness 0.429337, kurtosis 55.3785 ) 
[12] diff-output of <Sigmoid> ( min -1.33086, max 1.2764, mean 0.00096372, stddev 0.0979123, skewness -0.0712163, kurtosis 6.40236 ) 
[13] diff-output of <AffineTransform> ( min -0.999998, max 0.983291, mean -8.98185e-09, stddev 0.0170423, skewness -25.6287, kurtosis 2172.84 ) 
[14] diff-output of <Softmax> ( min -0.999998, max 0.983291, mean -8.98185e-09, stddev 0.0170423, skewness -25.6287, kurtosis 2172.84 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.14858, max 1.07531, mean -0.000478786, stddev 0.136198, skewness -0.00985896, kurtosis 1.74548 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.484529, max 0.623825, mean 0.0143717, stddev 0.147272, skewness 0.0815377, kurtosis 0.278209 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.645916, max 0.813905, mean 0.00450963, stddev 0.0721749, skewness 0.347378, kurtosis 4.55932 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.633064, max 0.853086, mean 0.0223173, stddev 0.181513, skewness 0.429236, kurtosis 1.85936 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.668313, max 0.660796, mean 0.00359081, stddev 0.0483407, skewness 0.362498, kurtosis 7.73396 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.971627, max 0.828676, mean 0.0325759, stddev 0.182566, skewness 0.207114, kurtosis 2.61233 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.701558, max 0.465003, mean 0.00270098, stddev 0.037691, skewness 0.161423, kurtosis 6.51902 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.627282, max 0.686488, mean 0.0231944, stddev 0.150094, skewness 0.0126457, kurtosis 1.1499 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.404292, max 0.325168, mean 0.00199426, stddev 0.0374065, skewness -0.0201909, kurtosis 3.20102 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.437121, max 0.371294, mean 0.0096134, stddev 0.111293, skewness -0.105726, kurtosis 0.869882 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.405284, max 0.475566, mean 0.00399979, stddev 0.0510737, skewness 0.20676, kurtosis 3.80574 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.469645, max 0.493977, mean 0.0191521, stddev 0.134599, skewness 0.0509546, kurtosis 1.16014 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.61618, max 1.96548, mean -1.24087e-07, stddev 0.087077, skewness -4.91338, kurtosis 93.0874 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.6663, max 1.4688, mean 8.65628e-10, stddev 0.273327, skewness -2.10062, kurtosis 14.4435 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-pdf[5.5.734~1-794732a]:main():ali-to-pdf.cc:68) Converted 3696 alignments to pdf sequences.
LOG (ali-to-post[5.5.734~1-794732a]:main():ali-to-post.cc:73) Converted 3696 alignments.
LOG (copy-feats[5.5.734~1-794732a]:main():copy-feats.cc:143) Copied 3328 feature matrices.
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:384) ### After 1012992 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.21036, max 7.88956, mean 0.00637491, stddev 0.994874, skewness 0.113357, kurtosis 2.26778 ) 
[1] output of <AffineTransform> ( min -44.634, max 31.9729, mean -3.53228, stddev 4.99303, skewness 0.107605, kurtosis 1.65056 ) 
[2] output of <Sigmoid> ( min 4.12779e-20, max 1, mean 0.227082, stddev 0.341311, skewness 1.33551, kurtosis 0.184474 ) 
[3] output of <AffineTransform> ( min -29.9943, max 21.7179, mean -4.03218, stddev 3.2037, skewness -0.0933702, kurtosis 1.81486 ) 
[4] output of <Sigmoid> ( min 9.41152e-14, max 1, mean 0.120981, stddev 0.227449, skewness 2.44786, kurtosis 5.23477 ) 
[5] output of <AffineTransform> ( min -14.8054, max 12.8517, mean -3.08304, stddev 2.16402, skewness 0.523204, kurtosis 2.01898 ) 
[6] output of <Sigmoid> ( min 3.71628e-07, max 0.999997, mean 0.125973, stddev 0.207156, skewness 2.50788, kurtosis 5.94767 ) 
[7] output of <AffineTransform> ( min -22.6091, max 18.781, mean -1.92364, stddev 2.14992, skewness 0.325028, kurtosis 2.85474 ) 
[8] output of <Sigmoid> ( min 1.51695e-10, max 1, mean 0.223652, stddev 0.256647, skewness 1.50657, kurtosis 1.33256 ) 
[9] output of <AffineTransform> ( min -15.9626, max 17.8786, mean -2.03628, stddev 2.89281, skewness 0.833626, kurtosis 1.7511 ) 
[10] output of <Sigmoid> ( min 1.1682e-07, max 1, mean 0.243928, stddev 0.31212, skewness 1.29242, kurtosis 0.279295 ) 
[11] output of <AffineTransform> ( min -29.7318, max 26.8062, mean -4.15926, stddev 4.06065, skewness 0.562651, kurtosis 1.9275 ) 
[12] output of <Sigmoid> ( min 1.22367e-13, max 1, mean 0.149164, stddev 0.296848, skewness 2.03194, kurtosis 2.58623 ) 
[13] output of <AffineTransform> ( min -15.4215, max 25.1656, mean -0.0178882, stddev 3.89742, skewness 0.57261, kurtosis 0.896248 ) 
[14] output of <Softmax> ( min 5.47637e-17, max 0.999586, mean 0.000518625, stddev 0.0168835, skewness 45.642, kurtosis 2272.52 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.85537, max 1.30095, mean 0.000170594, stddev 0.0559591, skewness -0.264267, kurtosis 36.4264 ) 
[1] diff-output of <AffineTransform> ( min -0.189367, max 0.247688, mean 3.14744e-05, stddev 0.00774461, skewness -0.0757164, kurtosis 63.6234 ) 
[2] diff-output of <Sigmoid> ( min -1.71567, max 1.1216, mean 0.000372844, stddev 0.0727862, skewness -0.00219731, kurtosis 13.4277 ) 
[3] diff-output of <AffineTransform> ( min -0.332804, max 0.335866, mean 3.74218e-05, stddev 0.00960966, skewness -0.0589949, kurtosis 82.0621 ) 
[4] diff-output of <Sigmoid> ( min -1.59504, max 1.52363, mean 3.52733e-05, stddev 0.0959087, skewness -0.031104, kurtosis 12.6858 ) 
[5] diff-output of <AffineTransform> ( min -0.290869, max 0.297974, mean 5.61116e-05, stddev 0.0106377, skewness -0.376237, kurtosis 59.8841 ) 
[6] diff-output of <Sigmoid> ( min -1.50547, max 1.31931, mean 0.000412848, stddev 0.0916579, skewness -0.0120171, kurtosis 12.6037 ) 
[7] diff-output of <AffineTransform> ( min -0.206313, max 0.190655, mean 3.17069e-05, stddev 0.00900163, skewness 0.153346, kurtosis 31.6038 ) 
[8] diff-output of <Sigmoid> ( min -0.882279, max 0.807247, mean 0.000133527, stddev 0.0612549, skewness -0.0127934, kurtosis 12.0461 ) 
[9] diff-output of <AffineTransform> ( min -0.152554, max 0.141923, mean 2.46476e-05, stddev 0.00639305, skewness 0.00313298, kurtosis 35.5314 ) 
[10] diff-output of <Sigmoid> ( min -0.821703, max 0.688148, mean -0.000116951, stddev 0.0480272, skewness -0.162671, kurtosis 12.5663 ) 
[11] diff-output of <AffineTransform> ( min -0.18243, max 0.206142, mean 2.45332e-05, stddev 0.00737977, skewness 0.336535, kurtosis 62.4585 ) 
[12] diff-output of <Sigmoid> ( min -1.73553, max 1.42019, mean 0.000537363, stddev 0.0819573, skewness -0.0782991, kurtosis 10.4346 ) 
[13] diff-output of <AffineTransform> ( min -0.999998, max 0.971632, mean -4.83244e-09, stddev 0.0143384, skewness -28.0036, kurtosis 2697.79 ) 
[14] diff-output of <Softmax> ( min -0.999998, max 0.971632, mean -4.83244e-09, stddev 0.0143384, skewness -28.0036, kurtosis 2697.79 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -0.925188, max 1.23725, mean 0.000766243, stddev 0.120657, skewness 0.0173681, kurtosis 1.67547 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.446642, max 0.428257, mean 0.00805744, stddev 0.121173, skewness -0.155625, kurtosis 0.49505 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.648425, max 0.786119, mean 0.00235561, stddev 0.0627014, skewness -0.00773895, kurtosis 4.15259 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.601738, max 0.627964, mean 0.00958004, stddev 0.150931, skewness -0.0927022, kurtosis 1.17567 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.551892, max 0.644112, mean 0.00179065, stddev 0.0431412, skewness 0.0134162, kurtosis 7.3295 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.829014, max 0.650109, mean 0.0143646, stddev 0.159745, skewness 0.0444281, kurtosis 1.82347 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.583087, max 0.417189, mean 0.00102819, stddev 0.0341764, skewness 0.0680324, kurtosis 5.66063 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.41581, max 0.628526, mean 0.00811694, stddev 0.130415, skewness 0.0166668, kurtosis 0.735798 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.328265, max 0.305427, mean 0.00141207, stddev 0.0340951, skewness 0.115829, kurtosis 2.3581 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.307687, max 0.301178, mean 0.00630981, stddev 0.0944685, skewness 0.0861768, kurtosis 0.150478 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.441002, max 0.417865, mean 0.00157829, stddev 0.047, skewness 0.126589, kurtosis 3.26175 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.450742, max 0.485413, mean 0.0062805, stddev 0.115805, skewness 0.0353591, kurtosis 1.08006 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.73189, max 1.15328, mean -8.67754e-08, stddev 0.078154, skewness -4.59063, kurtosis 77.0488 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.72834, max 1.15881, mean 4.69912e-09, stddev 0.232409, skewness -1.84271, kurtosis 10.3823 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:395) Done 3328 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.761131 min, processing 22181.7 frames per sec; i/o time 2.25179%]
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 37614 216 186 380 133 108 339 588 415 2364 944 124 1446 467 142 200 440 282 444 415 596 437 143 810 434 252 254 309 472 738 646 1036 178 243 1381 668 1893 1078 400 136 117 241 135 365 622 468 155 416 3097 14611 2493 618 408 235 51771 1168 777 228 126 428 747 457 798 272 98 454 1896 1626 409 418 2680 178 690 281 333 325 584 1311 226 2446 3054 314 731 182 373 1087 182 328 630 717 294 207 1002 657 60 523 535 375 435 372 386 562 341 1111 328 238 337 276 252 710 996 131 339 179 670 652 666 308 288 1560 404 643 248 145 284 539 576 422 213 1237 470 576 382 533 345 319 612 207 497 390 354 215 758 133 353 358 478 429 280 791 97 527 601 1967 340 367 193 152 311 447 251 328 792 331 757 89 192 136 721 229 272 304 905 374 111 801 237 575 1661 593 78 323 456 229 482 317 137 470 482 1087 211 153 678 175 731 353 540 91 311 197 169 518 123 1173 370 429 388 487 376 167 395 341 363 364 1022 429 233 430 524 207 301 116 1045 235 111 966 500 707 493 383 255 294 217 383 213 394 200 539 443 428 660 328 537 378 272 361 126 279 241 669 167 389 240 433 331 437 427 117 148 383 272 315 871 420 321 1435 93 188 144 353 338 735 760 339 709 614 1416 140 1136 127 890 243 614 583 190 437 272 585 283 566 440 372 165 215 193 356 618 382 266 520 889 244 320 275 506 723 211 206 276 236 548 512 243 430 388 738 338 772 406 465 70 248 481 665 441 373 210 296 440 186 142 344 499 1312 353 472 355 367 1354 308 385 603 167 588 252 196 260 148 237 527 418 784 596 370 758 203 562 290 782 104 502 443 63 543 479 303 174 295 490 191 265 245 235 423 312 168 742 374 222 143 148 65 303 396 412 156 121 128 251 480 821 112 255 233 232 278 270 385 324 114 1345 333 315 1218 1563 314 252 399 372 1243 277 206 610 85 221 722 402 1005 389 424 294 115 494 279 294 209 245 315 1167 433 428 534 239 125 502 276 663 628 512 2599 304 229 381 414 308 946 609 199 1086 164 131 131 171 326 204 2044 177 391 239 260 812 374 820 74 206 244 680 203 323 125 217 193 134 438 364 564 106 241 693 603 251 1088 530 586 374 167 368 316 407 299 448 690 222 487 761 219 122 872 438 117 179 186 442 218 272 329 344 95 310 217 294 494 478 168 456 505 144 153 647 108 483 306 581 69 322 237 751 1361 238 151 286 479 543 359 159 671 435 174 184 766 596 798 303 344 335 222 250 71 844 620 248 292 82 102 449 750 429 418 287 119 311 408 574 263 1945 754 171 301 122 1833 305 488 297 999 784 409 783 668 72 312 345 348 261 290 391 346 522 140 179 263 177 119 631 995 224 649 308 447 323 744 257 161 501 401 163 153 364 452 152 481 373 652 346 925 158 372 307 394 833 339 127 302 375 211 440 317 319 181 455 372 358 777 413 685 160 446 200 749 906 81 462 109 930 915 669 163 242 567 944 219 548 46 573 633 748 611 240 290 121 407 450 361 194 260 129 108 873 599 187 551 178 193 748 810 417 670 136 465 102 327 553 348 164 108 725 535 315 370 197 300 221 322 920 191 407 584 288 182 406 372 375 1085 185 383 693 277 188 526 791 309 337 364 513 297 496 529 348 327 428 339 420 348 311 912 570 215 283 181 197 310 106 491 84 250 182 819 212 579 312 140 478 554 534 191 139 1196 445 315 486 723 232 304 227 930 299 207 695 203 276 1422 309 431 393 294 426 296 448 395 180 462 138 206 89 387 468 269 627 469 824 136 462 410 143 302 116 492 153 211 446 299 169 191 1232 150 764 247 490 325 1056 298 286 301 201 323 238 121 204 155 782 228 191 374 203 1553 143 111 301 571 601 1341 559 161 296 440 208 208 659 27 439 652 212 225 122 291 432 247 388 514 968 272 355 330 311 453 375 381 1796 601 167 154 391 1612 289 934 995 221 236 544 350 411 535 570 258 359 1029 328 119 412 334 503 202 93 538 337 152 286 504 160 737 103 397 386 402 1068 746 201 618 702 198 386 447 661 97 662 757 281 563 365 219 431 957 488 295 223 189 183 149 867 254 158 485 237 725 167 83 130 711 823 272 292 299 482 360 287 897 166 803 393 198 316 305 328 596 35 357 288 124 253 349 93 538 676 219 341 386 988 298 293 374 380 314 122 507 268 560 627 140 200 198 897 221 158 324 930 217 297 444 1331 350 723 383 301 576 394 120 337 627 281 645 486 312 454 903 244 1111 215 649 166 320 386 410 560 700 240 216 702 205 473 303 813 153 851 630 983 929 336 797 403 163 138 302 1163 284 144 920 430 183 352 417 239 235 406 421 385 194 546 537 527 195 440 139 425 253 167 557 616 182 503 316 551 172 350 301 298 313 198 216 1202 720 464 203 388 218 1487 141 1000 216 399 805 708 1049 499 138 390 140 174 363 218 340 334 303 846 382 219 193 705 395 225 507 265 1131 201 1164 377 666 495 1268 1167 379 832 259 397 393 421 361 476 364 269 378 211 958 396 473 1016 469 868 417 367 400 502 1215 1010 499 974 207 211 575 209 136 158 848 405 200 666 668 468 95 413 383 111 361 646 168 196 277 224 1446 706 215 977 140 596 278 517 241 184 595 965 703 164 153 395 723 515 152 362 537 167 769 397 550 1124 1066 365 373 502 356 726 1199 770 198 674 580 381 507 459 121 1126 303 544 707 1190 352 477 384 365 274 275 307 334 372 309 139 490 199 341 551 1239 339 239 514 111 193 343 371 301 411 336 319 197 293 513 239 294 259 1678 731 329 486 1388 255 356 115 479 457 515 298 509 477 669 907 367 166 298 1121 221 393 389 1189 1538 467 642 573 695 292 445 387 316 193 267 354 838 378 1236 358 561 535 421 704 465 604 366 509 364 136 452 276 342 390 512 270 680 716 707 650 202 188 590 222 413 205 164 267 96 496 482 243 362 525 326 483 779 542 429 117 778 627 542 313 430 426 400 236 174 900 562 430 206 615 608 440 744 186 666 511 551 824 190 314 452 441 202 1643 517 555 422 576 365 399 105 630 1462 177 225 688 245 264 405 584 174 300 881 472 366 1215 759 370 195 289 282 238 701 37 150 126 514 960 733 155 994 252 269 322 684 455 509 295 264 385 383 260 789 653 113 166 189 225 20 398 499 301 521 683 126 202 208 755 619 446 519 638 118 320 1393 155 339 221 998 302 152 322 291 292 1078 363 633 952 696 206 163 57 1143 1470 235 750 925 55 949 190 1157 142 238 368 645 432 508 627 292 262 1520 538 221 253 280 568 463 2791 178 681 335 293 531 652 2285 1337 534 204 454 1136 124 101 760 133 763 184 611 606 531 503 467 159 691 773 341 595 123 168 497 209 207 1071 164 282 244 591 588 786 731 413 445 1679 424 221 363 261 358 438 429 376 232 464 108 552 455 196 526 685 689 484 510 402 277 144 219 556 160 295 461 530 367 239 316 721 540 546 363 272 629 766 173 427 218 341 402 420 387 851 297 191 263 412 1258 511 543 630 383 632 350 273 525 249 610 317 383 192 532 927 284 703 1187 345 234 237 529 640 1153 184 205 689 665 682 338 254 448 575 838 1039 528 493 197 317 243 915 614 243 409 211 727 286 532 948 308 151 162 442 480 456 395 1410 1151 499 468 149 663 616 838 373 238 1263 506 1015 160 468 2725 190 667 729 531 314 779 494 448 409 393 217 97 437 381 208 127 720 257 394 438 52 502 969 121 410 194 524 737 213 202 386 329 295 401 324 155 503 363 297 234 642 2282 731 305 1195 780 711 334 338 259 446 228 274 152 1986 3421 196 654 231 219 269 1113 263 375 80 235 893 536 455 155 1863 434 296 224 396 136 176 426 475 182 1538 895 333 996 378 395 182 218 186 156 487 140 1216 174 282 773 446 303 833 426 500 356 282 537 421 492 149 55 187 304 597 388 814 375 1468 614 420 194 258 117 663 574 681 648 139 220 250 424 918 667 312 181 228 357 524 439 524 552 1428 515 332 292 908 191 117 987 582 431 182 557 1382 323 260 1189 861 1231 549 313 646 511 485 435 653 889 769 262 193 633 354 413 455 264 1091 506 177 117 159 2171 2543 405 157 556 363 861 652 680 799 386 346 587 621 491 204 336 434 703 228 623 158 488 450 259 244 641 225 155 626 854 491 373 1849 136 991 194 305 1887 971 715 348 795 551 344 260 660 839 173 401 413 387 386 2469 393 1038 212 254 1036 830 226 244 441 219 583 352 673 3172 414 538 359 402 967 462 85 360 1024 151 268 1352 800 382 462 1131 167 530 312 973 157 135 109 579 1380 577 167 325 660 641 486 120 263 246 324 337 144 415 530 558 277 512 312 643 381 144 742 452 634 1127 406 730 897 847 217 524 129 756 982 267 319 491 292 146 676 373 74 200 267 368 488 440 301 460 235 828 303 748 414 ]
@@@ Loss per-class: [ 0.443737 0.782882 1.03892 0.933392 0.887459 1.79415 1.56051 0.496292 1.02487 0.572842 0.322733 1.97809 0.770697 0.850199 1.32659 1.40196 1.0542 2.72298 1.00159 0.695234 0.826934 0.62437 0.701294 1.00209 1.21225 0.58176 0.856539 0.761734 0.836777 0.536749 0.5085 1.05297 0.620267 0.90304 0.366697 0.366898 0.421471 0.269682 0.999216 2.18217 1.36962 1.12632 1.64019 0.87398 0.668187 0.428177 1.03387 1.08448 0.722837 0.681129 0.28987 0.729088 0.66065 1.02324 0.294327 0.757811 0.39781 1.00027 1.71306 0.577804 0.701246 1.36184 1.10814 1.23239 1.10062 1.01009 0.885765 0.79264 0.852088 0.912875 0.441304 0.924803 0.511848 1.03856 0.938477 1.01253 0.777392 0.455932 1.4035 0.63188 1.01501 0.707591 0.66752 1.06541 1.47158 0.653938 0.903076 1.76983 1.09164 0.932366 1.00684 1.59788 0.640355 1.13227 1.28901 1.34316 1.17399 0.832473 1.36572 1.02952 0.915922 0.867501 1.85675 0.804982 1.8999 1.12087 0.527862 0.613195 1.51196 0.836463 1.00061 0.888037 1.27049 1.22284 1.31968 0.881182 0.674693 0.806342 1.54789 0.766826 0.929145 0.564506 1.7371 1.01493 1.59315 0.55745 1.63711 0.998898 1.01709 0.774902 0.677838 0.923379 0.714412 0.956526 0.944036 0.996159 0.83316 1.36614 1.32749 1.19402 0.940627 1.01898 0.473566 0.68792 0.55492 0.943184 0.927724 1.52363 1.44709 1.25734 1.12039 0.550532 0.835775 1.16097 0.634654 1.13385 1.33032 0.75388 0.778476 0.709472 1.5127 1.03237 0.564634 1.50614 0.453815 0.933965 0.668315 1.4725 0.978866 1.33549 0.720134 0.366622 1.36471 1.12253 1.23981 0.70806 0.672678 0.902114 0.600833 1.36951 0.973191 0.85675 0.68064 1.3183 0.523089 1.74758 1.24199 0.799651 1.3794 0.96946 1.66015 1.08749 0.445048 0.673669 0.877158 0.741316 0.95826 0.838628 0.754159 1.08176 1.46836 1.2201 0.880048 0.828654 1.02613 0.730448 1.08783 0.96352 0.704172 1.38244 0.623328 0.599977 1.83468 1.42707 0.616661 0.895454 0.906496 0.782821 1.65138 0.493183 0.717332 2.45228 0.945134 1.76567 2.32119 1.5124 1.39264 0.677921 0.715616 1.24157 0.738912 1.63698 0.915657 0.423147 1.13163 0.793536 1.21364 1.35258 0.736625 1.3395 0.309593 1.02799 0.537098 0.612315 0.772858 1.32995 1.18222 0.823672 1.61046 0.527773 0.610687 0.877648 0.68242 0.701311 0.529506 1.1554 0.627615 1.63296 0.680402 0.599298 1.72734 1.96232 0.543886 1.14934 0.755648 0.628477 0.869208 0.831034 2.16985 0.657088 1.2787 0.657078 0.647119 1.34217 1.27621 0.791857 0.357487 2.13113 0.383911 1.73537 0.788178 1.1422 0.537303 1.6527 0.896518 0.853138 0.962787 0.495864 0.694285 1.71109 0.566084 0.667579 0.65913 0.986845 0.919246 1.15469 0.511465 1.24946 0.74719 0.724903 0.399205 0.958421 1.31323 0.817053 0.662078 0.626797 1.05049 0.50655 0.755614 1.12883 0.909973 1.6968 1.02084 0.635138 0.968459 0.501762 0.908338 0.94569 0.962346 0.622 1.66563 1.98277 0.999629 0.754089 0.6799 1.88453 0.903006 1.24275 0.677282 0.565636 1.07489 1.62499 1.05555 0.40861 1.4043 0.838595 0.956498 1.02845 1.17238 0.702958 0.581112 1.4072 1.39537 1.26844 1.13138 0.954185 1.28501 1.03155 0.982359 1.22115 1.48091 0.494752 1.04968 0.788653 1.38799 0.968217 0.63792 1.02147 1.10002 0.753341 0.814239 1.9945 1.51383 0.550924 1.08617 1.11598 0.880354 1.78859 0.527191 1.1499 1.05653 0.926004 1.51097 0.577182 0.94429 0.986916 0.629186 1.12592 0.621387 0.962908 1.01175 1.71902 1.03013 0.930961 1.15694 0.819417 1.23739 0.874227 1.95087 0.740818 0.757261 0.916894 0.749411 1.98128 0.976116 0.705083 1.02879 1.06269 1.73282 1.18152 0.789465 1.00919 1.21139 1.40552 0.82501 0.759923 0.779703 1.32813 0.37689 0.828371 0.634221 1.13044 0.740421 1.47752 0.758704 0.959199 0.724762 0.34144 0.725648 0.76929 0.8093 0.914526 1.38257 0.549989 0.833051 0.927257 1.41573 1.37256 1.55351 0.953179 0.603438 0.645528 1.43834 1.18427 0.89171 1.28888 0.76918 0.784867 0.581628 0.697496 0.519497 0.907229 0.847865 1.0339 1.19715 0.915447 1.01212 1.61494 0.579622 1.43921 1.5754 1.64144 1.62025 0.992455 1.07093 0.542566 0.748104 1.10235 0.857395 1.29951 0.536536 1.23747 0.884673 1.19995 0.924997 1.05669 0.421318 0.961775 0.773327 2.42491 1.45827 1.4983 1.67985 0.535185 1.319 0.780043 0.928564 1.27602 0.962062 1.22058 0.661664 0.721488 0.890201 0.855564 0.947536 1.92424 1.1065 0.646484 1.09193 0.826995 1.22262 0.621711 0.887301 1.12865 1.06226 1.25074 1.25156 0.713348 1.01563 1.22207 1.3614 2.13842 1.16127 1.11024 0.871614 0.750909 1.16151 2.04429 1.28038 1.00255 1.90159 1.35345 0.966075 1.15295 0.613467 0.57995 0.765969 0.771548 0.822821 1.33229 1.11269 1.07498 0.80423 0.815424 0.95473 2.2394 1.03136 0.814028 1.3335 0.904651 0.947803 0.773239 1.37003 0.813246 1.53947 0.984796 2.57058 0.844229 0.99517 1.31447 0.598996 1.15708 0.892454 1.25659 0.851318 1.46973 1.59662 1.02779 0.364206 0.994889 1.25498 0.825848 1.98731 1.16226 0.726305 1.01759 1.14626 1.17353 0.657207 1.19849 1.51954 0.620921 0.624521 1.60616 1.22892 0.930987 1.34995 1.25029 1.49065 1.3229 1.20499 1.35236 0.881543 0.841417 0.539078 1.30507 0.816035 1.03985 1.39378 1.25577 1.43416 1.07012 2.01715 1.20231 0.970801 0.924359 1.08991 1.65945 2.11839 0.73718 1.07003 1.48591 1.08716 1.54568 0.827383 1.17954 0.743182 1.14787 0.948153 1.18843 0.526433 1.15668 1.21586 1.44803 1.60498 0.706406 1.18017 1.0323 0.876291 1.56642 1.1043 0.509247 0.684545 0.794456 1.08007 1.17342 1.06174 1.09065 1.15988 0.653225 0.708941 1.97501 0.470725 0.645092 1.63366 0.740877 1.1218 0.718562 1.59472 1.25383 0.527093 1.02973 1.48777 1.45606 0.772409 1.33344 0.67629 1.38326 0.90922 0.990135 0.960865 1.044 0.953934 0.899804 0.752332 0.665973 1.7026 1.96822 0.973315 0.761171 1.07409 0.994184 1.08628 0.86371 0.762161 1.48429 0.843311 0.695447 0.783466 1.11669 0.980969 0.699518 1.12617 1.12818 1.63484 1.26243 1.22257 0.564021 2.14527 1.0152 0.966763 1.06527 0.889671 0.738207 1.23744 0.998312 0.864939 1.05664 1.45139 0.795875 0.723951 0.918242 1.08137 1.87447 0.635688 1.95216 1.83738 0.902399 1.12746 2.33548 2.05794 1.57762 0.799808 1.02974 1.17646 0.72103 0.820282 2.26963 1.58459 1.07662 0.928481 0.900176 1.05866 0.85833 0.359505 1.20377 0.906923 1.18576 0.518498 0.798315 1.29565 0.897928 0.959857 1.74729 0.968147 0.953867 1.13775 0.651652 0.771659 1.34141 0.635442 1.01398 0.960296 0.79989 0.643578 0.895164 1.50366 0.989927 2.40112 2.32665 1.52722 1.23472 4.16889 1.13777 1.37823 1.08265 0.929312 0.574758 0.829638 1.23078 1.39561 1.70678 1.14426 1.43708 0.954727 1.29061 1.59055 1.86544 0.662075 0.923779 1.30568 0.619594 1.0925 0.699836 1.03152 0.993594 0.803436 1.1106 1.1246 0.999589 1.4446 1.24858 0.962998 1.56378 1.75561 2.11707 0.87122 1.36342 0.914211 0.730179 1.53647 1.5445 1.2823 1.01991 0.939104 1.90874 0.921221 1.13608 1.0162 0.834693 0.988627 1.66207 1.24785 1.40355 1.14387 1.12497 1.76309 0.673127 0.945408 1.14709 1.45442 1.72397 1.21908 1.00148 0.930128 1.27572 0.828471 0.638489 1.0085 1.28079 1.0638 2.4151 1.13146 0.956632 1.3887 1.57329 3.00054 0.560878 0.855881 1.22052 1.01609 1.46215 1.12449 0.759861 1.24147 1.89746 0.704244 0.56619 1.23797 1.06096 1.22397 1.49198 0.581665 1.02784 0.687078 0.877392 1.07186 1.1023 1.30064 1.84226 0.75775 1.0433 1.85255 0.929314 1.25602 1.25237 1.30267 1.34827 1.19898 0.97159 1.08351 0.874427 1.20981 0.525104 2.1576 0.608886 0.829686 1.26278 1.25173 1.71902 1.13666 0.803728 1.30371 1.08188 0.824302 3.18641 1.1874 0.896655 0.892341 1.59407 1.17181 1.47704 1.38523 1.84923 0.718588 1.87659 1.59354 1.20782 0.835931 1.13729 1.09815 1.19376 1.09572 1.6344 1.30615 1.00743 0.790782 1.09105 0.693687 1.56549 0.763997 0.906594 1.17548 0.49036 0.967093 2.03997 0.837044 0.943309 0.856979 0.888805 1.13084 0.882348 1.43997 1.32557 1.59737 1.04819 0.65001 0.693694 1.50979 2.01108 0.968565 0.537491 1.36973 0.939565 1.06192 0.932216 0.878558 0.744581 0.996921 1.39931 0.985338 0.85059 1.35524 2.21606 1.07757 1.30312 0.796282 0.604341 0.958574 1.11413 1.02712 0.771653 0.602297 0.694202 1.02156 1.40039 0.673746 1.15994 1.81 0.953506 1.11354 3.29757 0.884574 1.21904 1.83269 0.512104 1.46787 0.815191 0.94894 1.05598 1.13939 1.08973 1.00478 1.14263 0.551152 0.735393 1.24967 2.30164 0.865901 0.925617 1.07106 3.30949 0.867958 0.901737 0.744176 1.17396 1.63129 1.13837 1.34968 0.715804 1.03444 1.28375 0.712789 0.945709 1.08774 1.50599 0.860254 0.494443 0.686197 0.901994 1.19077 1.56102 1.06328 0.66439 1.02792 0.782758 0.744767 1.38034 1.20352 0.532248 1.216 1.95701 1.36943 1.49587 0.718197 0.990536 1.43556 1.03877 1.8327 1.2953 1.10687 1.43732 0.804681 0.683327 1.40715 0.581668 2.64484 1.01315 0.812591 1.11113 1.09922 0.517331 0.988248 1.49558 0.898555 1.12188 0.958513 0.962148 0.895696 1.76522 0.66736 0.798754 1.68521 0.728846 0.499426 0.849525 0.768519 1.25629 1.48506 1.20292 0.904254 0.88602 1.30868 1.10877 0.982954 1.41114 1.15994 1.00029 1.22051 0.9054 1.31918 1.1953 1.85844 1.73631 1.5544 0.711702 0.7075 1.24251 1.11063 1.42685 1.6971 1.08233 1.39592 1.43768 0.644654 1.88335 1.11506 0.87078 1.06433 1.25012 1.40334 1.36795 0.803879 0.995816 1.27966 0.507985 1.82014 1.13122 0.771204 1.3499 0.411705 1.17604 0.820151 0.668846 1.06391 1.77149 0.875596 0.922898 1.62896 2.11418 0.922197 0.903208 1.59863 1.55649 0.963984 1.39481 0.76117 0.928297 1.52164 0.927155 0.896037 1.95291 1.05559 2.0177 0.777119 0.772824 0.603978 0.96978 1.57462 1.10726 1.03334 1.30478 1.89944 0.932765 0.787431 1.53222 1.369 1.5917 1.3927 1.32601 0.722928 2.50881 0.96515 0.782227 1.19304 0.882892 0.79683 0.93192 1.15832 2.37627 0.877368 1.08645 0.862984 1.07863 1.06223 1.27927 1.04401 0.705886 1.00734 1.44469 1.21579 0.902569 1.38344 0.955774 0.968598 1.12683 1.16091 0.994361 1.30668 0.717257 1.04143 1.26789 2.17845 0.661063 1.79934 1.428 0.673893 1.11767 0.90622 0.721949 0.851307 1.48829 0.961413 1.17861 1.56032 2.07031 1.23749 1.04939 1.36339 1.5718 1.84575 1.40179 1.02207 1.47052 2.01341 1.16057 0.847424 1.11988 0.900694 1.14069 0.902732 1.37058 1.49573 0.721075 0.902831 1.29444 0.67282 1.2209 0.949742 1.03377 1.69616 1.77186 1.69394 0.568089 1.24724 1.18727 1.12758 0.368129 1.08913 1.33458 1.18679 0.593425 0.950471 1.65474 1.51814 1.29037 1.45345 0.723497 1.85579 0.787035 1.34309 1.1289 0.85831 0.735122 1.27439 0.943441 1.18791 0.520871 1.31613 1.28289 1.06407 1.11095 0.921887 0.971042 1.38629 1.37215 2.2374 1.11305 1.33006 1.60303 1.27151 1.28123 1.43331 1.80352 1.57059 0.540066 0.477774 1.449 1.45076 1.18013 2.60894 1.74973 1.62213 1.86733 1.3452 1.00872 1.15055 0.731129 1.06629 0.823467 0.95438 1.80895 0.899098 0.986605 1.51502 0.858989 0.599154 0.809405 0.719037 0.80369 0.952715 1.14163 1.12861 0.624416 1.02478 1.00367 1.89907 1.81546 1.43648 2.26931 1.19842 1.41263 1.02662 0.609962 1.80097 0.967467 1.17787 0.745064 1.22233 1.0384 1.6076 1.52213 1.4107 1.14031 1.9857 0.977039 0.966069 1.75519 0.799706 1.2573 0.833757 2.07337 1.08655 1.12364 1.45749 2.43008 0.833149 0.921443 2.17623 1.00683 0.992279 1.2266 0.571701 1.11349 1.88329 1.74949 0.792317 0.860184 1.06154 1.75594 0.956317 1.53396 0.771884 0.81579 1.44841 0.88828 1.11748 0.745913 1.59435 1.56365 0.762511 2.29719 0.942473 1.95986 0.6321 1.15811 1.00508 0.805753 1.11899 1.2507 0.894527 1.66707 1.41066 0.956788 1.46035 1.2744 1.03329 0.754928 1.75614 1.38925 1.17871 2.05977 0.733876 0.998624 1.35374 1.03955 1.84253 3.21 0.797002 2.46885 1.49022 0.533508 1.00813 1.28706 0.889561 1.04688 0.824576 1.56641 1.11402 0.75762 0.953921 1.08842 1.13049 0.973189 1.04095 0.887792 0.910183 0.487828 1.1493 0.805251 0.912941 1.02952 0.955201 1.44844 3.34491 0.768981 0.740752 1.04369 1.02447 1.02674 1.6814 1.9852 1.15199 2.14892 0.808405 0.778946 1.96186 0.65518 1.13529 1.78726 2.85159 0.822675 1.18616 1.16281 1.31844 1.97665 1.41629 0.916358 1.00683 0.873527 1.08671 1.17255 0.707211 1.62546 2.33669 1.59801 0.74886 1.05976 1.29198 1.4154 1.99312 1.10983 1.54554 0.590988 1.46502 1.13049 2.34449 0.469755 1.53516 0.834337 0.927331 2.13896 3.0038 0.718415 0.970443 1.23074 1.17563 1.35359 1.95857 2.46903 1.35149 1.47232 1.19579 1.39597 1.05855 0.48196 0.920586 0.634458 1.2484 0.507984 1.94855 1.28496 1.02576 1.0249 1.55689 1.0526 1.43844 1.16079 1.36094 1.27102 0.721967 3.71301 0.944328 1.4248 1.96219 1.16706 1.04125 1.32936 0.617471 0.769927 1.34363 1.43755 1.89296 0.858023 1.13739 2.20763 1.24866 1.07521 1.0061 2.98419 1.35652 0.929316 1.38129 1.28992 1.0523 0.828563 0.731397 2.25455 1.02332 1.08042 1.09649 1.04872 0.74965 1.84237 1.93433 1.04005 1.40457 1.9231 1.74468 1.29151 1.13692 1.38664 1.19118 2.06148 0.831146 0.575984 1.01442 1.1011 1.32657 1.1054 1.01181 0.839593 1.36732 1.19464 1.19643 1.22314 1.24617 1.71222 1.75882 1.35236 0.654705 0.838963 1.07911 1.80134 1.60646 1.46201 1.27216 1.022 1.96783 0.899561 1.00011 0.951524 1.91374 1.3513 1.46865 0.899566 1.13468 2.13524 1.48995 1.26883 1.43207 1.49457 1.65292 1.71524 2.1517 0.862238 0.952422 1.19818 0.805514 1.88121 1.62839 1.35788 1.35034 1.56905 2.03151 0.817984 1.06028 1.26031 1.66121 0.544845 1.11002 1.23485 1.22908 1.10368 1.032 1.42363 1.74251 0.980472 1.38627 1.15018 2.67435 1.38473 1.91003 2.05919 2.11796 1.10582 1.22704 1.19059 1.53501 0.975472 0.983367 1.13127 1.33606 1.42425 0.911513 1.40286 1.13559 1.65619 0.811861 1.369 1.26705 0.938678 1.38124 1.10281 0.931228 0.638587 1.26778 1.14164 1.09436 2.47123 0.78667 1.04756 0.999676 1.31716 1.78184 0.856682 1.43159 0.914217 1.35825 1.27255 1.17222 2.66694 1.49402 1.31816 1.0201 0.705993 0.949175 2.0108 0.694423 0.852939 1.1609 2.04265 1.63418 1.55288 1.03017 1.19929 1.40757 1.3866 1.12962 1.45584 1.60817 1.25664 1.02525 0.873634 1.12963 2.26182 1.31296 0.765504 1.17005 1.2256 1.14708 1.27221 1.16089 1.75176 2.90693 2.16837 0.928808 1.89212 1.06566 2.01947 1.88665 1.76336 2.03917 1.07889 1.88014 1.31477 1.06889 1.1744 0.903201 0.918553 0.914535 0.78703 1.21755 1.74048 1.98342 1.06286 1.14192 1.07247 0.75083 0.992348 0.732555 1.81921 1.04155 1.54111 1.55761 0.496941 0.912332 0.9682 0.863608 0.865582 0.991011 1.33943 0.910236 0.76217 1.1603 1.30221 0.987486 2.87609 0.787068 0.720332 0.753427 0.864178 0.888036 0.9414 1.26302 0.313769 2.04638 1.48234 1.12874 1.52152 0.729281 0.813665 1.50492 0.670253 1.32901 1.16411 1.14027 0.716343 0.513864 0.78139 3.39932 1.11205 0.960918 1.9036 0.897835 1.3943 1.96442 0.591596 1.28623 2.04777 1.5198 1.17338 1.37358 1.30053 0.552211 0.972419 1.59034 1.52734 1.24891 1.33688 1.89275 1.00538 0.80095 0.999304 0.872037 0.923912 1.51682 1.42668 1.86093 1.24972 2.74927 2.21931 1.90215 1.33078 0.850373 1.29768 1.17921 1.66756 0.426786 1.85411 1.78317 1.73764 1.14294 2.15894 1.39288 1.1225 1.38004 0.793014 0.936737 1.32992 0.918011 2.6129 0.700972 0.844545 1.30529 1.70991 1.46381 1.40375 2.16901 2.1873 1.36517 0.875523 1.2594 1.822 1.23631 2.1178 1.15433 2.22618 1.31842 0.720714 1.12228 1.55956 1.4614 0.63192 1.27645 1.2402 0.757126 1.2753 1.3957 1.44246 0.807685 1.93024 0.65886 1.27545 1.97402 1.30138 0.706587 1.39964 1.48831 1.44808 0.930201 0.968139 1.26576 1.237 1.21915 0.987275 0.905494 0.972149 1.06717 0.942397 0.990524 1.00236 1.08413 1.12219 2.49973 1.09102 1.98147 1.49858 1.69319 1.21086 0.952699 2.09143 0.806849 1.63627 0.912663 1.28771 1.92405 1.22591 1.05117 1.07085 1.83201 1.71472 1.38791 2.76024 1.46685 1.18531 2.63119 1.13921 2.02541 1.02198 1.24881 1.06189 1.25444 1.10122 0.930839 1.08751 0.791085 1.88788 1.32152 1.11 0.72117 1.22292 1.39329 1.25359 1.24738 1.27548 1.81648 1.20212 1.35519 1.20645 1.46053 1.29156 1.66622 1.24075 0.670238 1.5507 0.857673 1.0845 1.66521 0.770294 0.811252 0.851239 4.32499 0.904478 0.992344 1.34428 2.28013 0.924852 0.731557 0.763705 0.704368 1.10149 1.69067 1.27293 1.49016 3.5435 1.31691 0.747523 1.66717 0.827599 0.757756 0.919466 1.35233 2.21962 0.849475 1.15665 0.92195 1.36506 1.97638 2.2309 0.860037 1.81226 0.96354 1.63989 1.43277 0.921205 1.58566 1.05842 0.981046 1.2954 2.41811 2.5691 0.790565 0.97066 1.07212 1.75713 0.845242 1.45836 1.93499 1.32451 1.29034 0.926637 2.14151 0.625412 0.972962 0.812318 0.92882 0.703337 0.823487 2.8589 1.34102 1.15684 0.928149 1.30044 1.14172 2.86259 0.949107 0.878451 1.34812 0.890262 1.05616 2.03641 2.3215 1.10174 1.82849 3.04717 2.02912 1.86085 2.50454 1.01843 0.960567 2.24821 2.14625 2.27346 1.03406 1.51618 1.52251 1.37661 ]
@@@ Frame-accuracy per-class: [ 83.3562 77.5982 70.2413 65.9658 77.9026 47.0046 53.0191 87.5106 70.9988 83.4849 92.0064 40.1606 73.626 76.3636 58.2456 65.3367 65.6073 18.0531 73.5658 77.497 77.2842 79.0857 81.5331 70.5737 60.9896 85.5446 73.0845 75.9289 74.4974 82.8707 85.0735 64.9301 83.4734 76.386 89.468 89.3044 88.3021 92.8141 69.4132 34.4322 62.9787 59.2133 52.3985 68.3995 82.4096 86.873 64.3087 71.3085 77.385 77.2679 90.6357 75.0202 78.5802 73.4607 89.7212 78.2199 88.1029 69.1466 56.1265 82.6138 78.9298 56.1749 64.6212 65.3211 63.9594 71.0671 70.9201 76.6062 74.2369 72.6404 88.0806 75.07 81.1007 63.9432 70.7646 69.1244 74.4226 86.5421 58.7196 80.3597 50.221 76.9475 79.9727 63.0137 50.6024 79.3563 75.0685 44.4444 69.3101 64.669 66.5535 51.5663 82.8928 61.1407 66.1157 59.0258 63.1186 71.9041 59.2423 65.5034 70.3752 74.4889 36.3104 71.525 36.5297 67.086 86.8148 83.5443 50.6931 77.1288 71.5504 74.5247 60.972 68.5237 57.8673 77.0881 79.5199 73.5818 54.766 73.438 68.974 82.0513 45.8753 73.5395 54.4815 84.3373 40.5898 71.9527 66.9789 79.0303 82.2529 72.333 80.5229 73.477 70.3329 68.8576 76.2449 51.5663 59.0955 68.3739 71.9323 70.5336 85.6955 76.4045 82.3197 73.3612 71.2644 54.0163 63.8146 58.8756 65.641 82.8436 72.9842 65.7179 81.351 65.3061 59.4315 76.7213 77.6886 75.0838 55.2684 66.9711 83.7855 54.2986 85.9406 69.2737 79.4805 52.7473 70.9633 55.3377 79.2661 91.6256 60.5191 62.7503 63.6771 78.6026 82.5263 73.8488 82.2149 57.4558 72.6115 74.8068 81.0515 61.0022 84.1451 41.8898 62.5455 77.7896 60.7254 70.1609 54.8463 64.4951 87.3987 82.0513 74.9146 77.7935 73.6355 78.6885 81.5409 65.3165 51.3274 61.1379 72.8745 73.1146 70.1754 79.1618 66.1519 70.1538 82.3373 53.1343 80.4046 82.284 48.1431 61.1797 80.978 75.6694 71.5203 76.8873 35.653 85.3012 78.9386 24.0343 71.8317 47.1338 26.009 56.2856 64.9351 78.8693 81.8642 62.3207 75.1468 55.348 73.1034 85.7888 62.7635 76.5526 63.3416 58.3874 77.3393 57.1762 92.0515 69.102 83.3488 81.638 78.5321 61.964 60.8696 79.4275 57.1429 84.242 78.209 77.2786 81.4969 81.6609 85.0679 68.1143 81.8713 51.9149 80.1347 80.5737 49.9083 37.7179 84.3373 67.7765 74.339 81.435 73.7968 75.8621 31.8339 81.471 62.3338 81.4412 82.7087 61.2666 62.2974 70.952 89.94 38.4342 87.3735 33.7255 75.2386 65.2977 84.6216 53.8132 78.7402 77.2571 71.9266 84.8847 78.6596 49.7793 83.0874 78.6577 80.3625 66.8213 70.2842 67.8822 83.5893 59.6078 78.7992 80.3074 88.5891 71.5746 67.7067 75.8621 79.3682 82.3773 65.721 85.7143 81.0127 71.8816 73.8377 55.2195 71.4579 81.7654 71.2999 86.6622 70.6056 73.0097 65.4367 80.7734 58.156 42.6559 71.8588 80.0902 76.1042 47.6573 69.3587 61.0455 77.185 82.0375 68.7719 47.8955 67.4675 88.2286 64.215 72.8042 75.3868 71.2925 65.4854 81.0373 84.0467 47.7216 65.0746 64.7409 70.495 70.229 62.9559 68.0135 69.8947 65.4028 58.3035 86.4245 72.2548 74.4939 54.9769 72.7273 82.8444 72.2892 65.4313 74.6411 78.209 42.3901 56.6929 85.1886 68.8217 63.2619 72.7794 43.3164 83.792 64.752 67.42 73.3198 54.7771 83.8253 72.96 73.5905 81.0774 66.7557 84.4944 75.2613 70.7071 48.855 67.5453 69.6091 65.9394 77.3163 61.7284 77.0428 51.6899 76.3788 78.7584 65.7778 75.1468 37.6874 71.3978 81.8671 73.5675 70.2983 46.5331 67.2489 75.065 67.4663 60.2219 57.1194 74.3204 76.9475 81.9802 62.8285 91.0067 74.8693 80.7207 65.3753 79.7707 54.9708 74.4921 71.6955 77.5155 90.9 75.4814 76.5607 74.0238 77.0563 60.6673 80.5009 78.0985 70.1671 57.4338 57.6862 52.2484 69.6655 77.9463 83.2554 61.3779 70.1195 69.8507 60.7595 78.523 80.35 83.122 80.6694 84.7291 74.5098 72.0839 66.8275 64.5057 73.6397 72.5185 52.6316 84.3074 61.3982 57.7947 59.3156 57.7259 68.3002 72.3716 83.4923 79.4366 64.6232 74.3215 55.6622 85.2923 61.6822 76.1731 72.4832 72.6392 65.4397 88.0235 70.2703 80.0618 27.8884 61.6092 51.6796 51.3011 83.0103 67.4897 79.1851 74.1784 64.5963 69.3583 62.6346 82.3062 78.7322 70.4995 74.8508 74.2323 47.1642 65.943 78.0411 66.0123 74.7913 65.7748 81.1007 77.3034 69.1282 73.0138 57.8588 66.1224 80.2292 68.4151 61.2766 57.3816 39.6783 68.0226 66.8192 73.7615 77.39 66.7634 45.0262 62.8019 66.2069 44.4822 60.0607 71.8913 65.2819 81.4896 82.2948 76.8166 76.873 75.9846 59.9078 68.0455 64.6003 80.1376 79.1367 74.1085 45.0526 68.9288 74.8439 54.0881 78.5479 75.3927 77.7894 61.0856 74.548 53.9185 72.3753 32.3766 73.3524 72.6287 61.8395 82.1459 59.3613 75.7825 58.6357 73.6215 62.4719 53.8922 68.5315 90.5861 72.1998 64.7887 75.2137 46.0606 67.3171 77.4194 69.9534 68.2189 65.9498 81.3913 66.1088 59.39 82.0073 80.2437 50.0949 58.0314 74.7515 65.8892 64.0133 51.4286 53.6133 62.8478 57.9324 72.2689 75.1376 84.8948 65.2015 74.665 67.4645 68.9655 61.44 50.9407 70.5882 46.2715 69.8795 74.5849 68.6869 68.3254 56.2278 33.9833 78.5579 70.9859 57.7406 65.0831 49.2215 74.833 59.7383 77.7958 65.9218 72.3338 62.9953 83.4951 68.7307 59.0229 58.0324 55.0459 81.4332 66.941 68.9503 76.7213 51.298 66.1312 84.751 77.9221 77.4716 76.3407 67.3826 66.0163 68.1876 65.5069 78.6451 80.7843 35.3719 85.486 80.3783 50.8513 79.3701 65.4147 81.5427 54.8847 65.2349 84.2399 69.3248 62.636 56.7469 79.1277 56.215 79.8005 55.6371 71.594 72.3926 72.2162 67.5799 70.4997 72.9656 79.3129 83.792 49.8969 29.9559 69.5606 74.2597 67.4567 70.9677 61.5519 72.7703 77.4883 54.9469 78.1705 77.4527 77.3663 69.6933 65.9267 84.9239 64.7815 60.2687 61.0039 66.3594 60.7899 83.4028 29.3333 70.5349 70.5882 67.7003 74.8163 79.9506 63.7126 72.1849 75.4579 67.0247 55.6098 77.5573 79.6748 72.023 67.4772 54.3779 82.2881 49.6732 44.691 74.4939 67.8481 35.9401 45.1467 54.5736 75.937 69.4517 64.2945 79.7263 76.6031 31.2329 51.6605 66.3087 74.8336 74.9885 66.8464 76.1408 90.411 66.6667 74.8011 67.0465 86.4182 77.8675 62.8148 71.0562 71.0808 49.0756 71.7019 71.1992 67.4319 80.916 73.2789 60.6775 79.4293 72.3099 73.8363 74.7397 81.1569 77.0302 61.3757 67.2176 33.4177 35.4267 52.5822 68.7691 8.28402 67.0659 58.0822 68.3344 73.8824 82.4849 75.52 72.5979 57.0533 54.4635 67.1656 55.3525 66.6667 61.0949 54.0965 47.5436 77.9034 71.5964 60.2151 79.803 65.9341 81.2466 69.1152 68.4337 76.6355 66.8305 68.3544 66.0808 52.3425 61.8772 71.9187 56.3667 52.9894 47.2175 75.3623 57.1429 75.9003 79.1351 53.4296 54.7215 60.3352 69.6774 73.4258 47.8664 72.988 68.5836 71.4372 70.3297 67.2432 48.4775 63.4146 54.876 67.8112 63.9594 50.8143 78.9598 74.3561 63.773 57.8171 48.0418 63.4483 71.0963 70.896 67.0707 76.6565 82.9493 72.0303 63.6516 72.9494 32.8358 66.005 75.425 62.4738 57.6132 30.8068 85.5305 76.5495 60.8315 71.0183 57.6769 62.8993 77.1806 57.1429 43.0493 77.6119 82.4147 61.3466 68.3563 65.0581 56.9659 85.3288 71.7367 81.0552 72.4221 71.4177 80 66.6667 45.5172 73.4118 67.8492 47.3469 72.0412 61.9653 64.2424 59.2021 54.6161 66.3913 66.789 61.8847 71.407 69.3419 85.5568 38.8815 83.6173 76.7047 61.5129 61.4925 55.6634 65.645 78.7597 66.6667 69.5559 78.453 19.8646 69.3446 69.6051 76.7475 54.678 67.0401 53.4619 58.4139 44.5063 79.7475 48.7062 53.5565 66.4242 76.8311 63.1579 58.7654 68.4492 69.2665 39.1111 60.9836 74.3455 76.115 64.1745 82.4407 54.1063 83.522 72.1863 63.6025 84.9789 74.213 40.6948 76.152 72.1708 73.5516 76.8435 63.9106 74.9811 60.5128 61.7358 43.3003 71.4032 80.0355 77.4282 61.5034 37.3117 70.1828 83.3163 56.176 70.2461 70.1847 69.2098 74.2475 77.5793 68.7623 64.9842 74.3563 76.2105 58.0289 36.4179 63.4731 61.3027 77.0204 81.8458 76.3303 67.6923 69.4491 77.7202 80.9986 82.087 68.6351 52.8529 79.0292 69.3774 46.8514 69.8262 71.3584 22.8311 69.7402 67.6056 46.7133 86.3085 58.6345 80.8679 66.0944 70.5882 56.4531 67.997 74.2597 66.7643 82.7943 76.4795 68.6767 46.678 72.3632 72.0105 69.9523 17.9592 77.6355 72.6257 78.8582 68.2072 51.9573 67.8304 64.9874 80.2228 73.1377 58.6751 78.5824 72.0043 66.2069 53.7815 73.3408 85.843 79.03 73.9461 68.8396 61.6915 70.0781 83.3967 69.7095 77.3333 78.0876 63.5879 62.4322 84.2754 65.28 47.9648 59.9889 51.1247 80.4318 73.3179 54.9654 72.0721 43.3697 60.2846 71.8636 54.4157 76.374 81.0811 54.9654 83.274 23.8443 69.4826 73.1466 64.1672 67.7524 83.9695 71.6891 51.1439 74.7714 66.8648 72.9781 70.8798 76.4526 48.3755 79.0083 76.2355 54.4815 78.8927 85.7143 76.8873 73.5695 61.5603 55.8084 63.8831 75.1592 74.5387 58.1257 65.1102 68.3805 53.9799 64.7442 70.9005 55.7545 72.4177 66.6667 66.04 41.8146 59.7015 52.7354 79.6431 80.5479 62.5621 67.6145 55.3037 60.8696 63.0528 60.6965 58.2915 78.7879 45.8438 62.3557 76.0083 69.3963 60.0646 58.9681 60.4891 73.6842 68.7731 62.8975 88.056 48.037 64.5807 76.5984 57.0219 88.3278 62.4625 72.2022 80.4097 66.1922 46.4183 72.9023 68.1922 46.1087 34.3797 72.4876 72.1796 51.7647 56.0364 71.3178 57.9731 76.6119 72.7273 55.1724 74.9529 73.9726 51.1166 66.7239 29.6689 76.069 75.0757 82.2231 68.4368 56.6535 65.5856 70.5202 61.3836 43.4562 72.3606 74.4122 55.404 58.4362 60.4824 60.7662 60.0473 78.2473 39.8487 67.793 79.7836 66.2407 70.9269 76.8862 70.7483 67.4157 31.8408 71.9046 66.2048 76.0761 63.9302 70.8434 59.5745 70.5474 78.7589 71.7949 56.1514 66.3524 72.7497 52.8678 65.7164 69.7083 69.3703 60.733 68.1983 62.3207 84.3049 64.4537 56.9219 49.8516 78.8804 40 57.9065 81.1614 66.6667 72.8538 78.2609 71.1744 58.3403 70.377 64.9275 57.5569 39.5664 64.4836 70.2227 62.8287 58.3587 42.9967 58.1542 70.3525 56.644 38.0328 64.8276 74.9767 60.8955 74.0741 71.195 73.0245 54.4242 56.4463 78.249 73.8956 62.8856 82.7489 65.1067 74.9479 68.3971 51.8892 49.2216 49.2679 83.6173 62.4631 64.6355 66.6667 88.8593 67.5453 61.5243 65.7244 83.3263 69.5035 53.822 55.3966 65.3899 53.1876 77.677 34.7967 78.6248 62.0134 69.4669 76.7025 77.0642 64.6617 71.1567 65.8205 86.8899 64.5066 63.048 67.0554 62.7803 75.4522 75.1092 60.0269 62.0232 37.6671 69.2422 57.277 55.1899 58.6031 62.1227 55.9499 48.8964 52.0231 84.7781 87.6282 55.8422 50.7708 64.0259 31.3112 47.1248 51.0823 41.9187 55.082 66.9253 70.6868 77.527 66.8063 75.4294 72.5069 45.4422 71.4715 68.3417 52.6973 71.7833 82.5921 75.7381 74.9054 73.4482 76.5775 68.0156 65.9111 80.949 69.7436 68.4624 51.6129 50.5529 58.3979 31.7757 64.3159 57.6029 67.6354 81.4395 56.0669 69.9911 66.8534 77.5801 64.5848 69.6026 54.756 57.0259 54.5633 65.0206 39.5604 68.7293 70.5244 50.219 77.8489 62.2439 75.7856 40.2645 67.2715 66.2898 57.8017 36.0494 77.9841 65.199 40.4494 67.4728 66.18 63.8298 84.8598 69.4301 40.4834 44.5596 75.154 72.8276 71.1703 49.3109 68.0455 59.397 78.5253 76.135 70.6383 76.6859 67.8884 80.1843 55.1834 57.1429 76.4361 34.7066 72.7273 49.2837 82.8429 65.2444 69.2218 75.5448 69.8619 59.9836 76.504 49.0262 58.9812 73.3683 59.824 61.65 71.3159 77.6903 48.0127 57.6796 67.0442 37.037 78.7344 69.1787 60.8461 71.2426 43.3651 20.7934 76.3454 27.4882 56.1459 83.0085 68.7324 55.4324 69.4263 65.9878 73.724 58.4464 63.8152 75.6447 74.8752 69.7674 67.5132 70.3956 70.4237 76.6294 72.6046 85.9335 67.3575 78.9381 73.7945 66.8567 77.3333 59.8007 18.1818 76.9679 78.2926 68.7117 74.5981 67.4711 52.6733 45.6401 60.155 40.7597 76.8386 76.7419 40.9475 76.3705 65.1102 48.7614 25.3359 73.7175 65.6465 61.674 67.2673 55.409 55.8758 73.1707 74.5295 72.0721 68.325 66.5388 76.9568 47.4308 44.4444 55.1559 79.0205 68.7651 64.0538 56.5929 42.9131 64.9789 50.858 80.9473 54.6624 65.9794 37.9233 85.2278 52.562 73.4426 74.7287 33.9623 35.5556 78.1641 75.6534 63.457 66.5617 59.7272 44.5521 30.581 64.3478 55.5313 66.508 51.38 67.9547 83.1983 72.0721 77.9358 65.0919 84.3197 42.807 55.3459 67.8426 69.5585 55.7225 67.8466 58.4861 67.3504 65.5238 58.0072 78.5515 15.3499 69.8225 61.6756 49.2524 64.5092 70.3564 61.0644 82.0249 77.1982 61.3288 60.7714 42.6054 75.3446 64.2243 43.4051 66.0147 65.5666 70.4795 29.7189 58.1281 69.5595 65.1685 57.8913 72.0867 74.4072 77.3289 32.7375 71.6981 67.3797 72.7273 69.9928 77.8281 43.0454 48.6986 61.5385 58.1602 42.4121 44.8687 64.5783 66.9155 60.1824 63.3628 42.5358 73.5418 83.9422 67.5143 67.1224 61.6687 71.3805 69.7231 73.9694 57.3363 66.575 64.6272 60.8089 64.5382 44.0047 47.2776 62.3656 80.0861 72.8111 69.3213 37.7607 53.4351 52.0418 64.3326 68.8905 45.8204 74.0451 72.2981 70.2703 44.9827 60.1367 62.7134 72.2741 68.3587 43.3369 57.8699 59.0476 65.5532 56.5561 48.51 45.6984 39.5242 75.9285 69.3578 63.8602 77.3646 43.804 59.4152 61.3272 62.3719 54.9068 40.6659 77.9355 69.172 65.2101 54.3081 83.112 68.6061 64.2034 63.7341 71.7571 67.8826 60.7562 55.6522 71.8973 59.5978 65.0809 34.8697 60.4423 46.6142 42.2425 37.9221 64.7887 66.8464 64.3234 51.8834 67.5368 68.0174 65.6716 59.3684 60.4344 72.9118 55.0498 66.1247 45.2555 73.5315 56.1983 60.5128 69.1285 52.6523 73.5786 72.98 80.9779 59.9327 72.8477 67.8825 32.4051 78.4252 70.6366 73.4025 60.2116 52.1561 73.7485 65.721 75.8763 58.2897 65.3521 62.098 39.5462 63.3663 68.9231 68.0226 78.0437 74.2607 42.7307 80.6806 77.1168 65.4655 42.0491 56.1873 53.9563 68.2887 65.2355 56.7604 60.7966 66.0863 60.2172 56.6224 62.9283 71.9317 73.4911 74.5407 34.9064 62.3715 78.4572 61.0493 61.7062 66.1274 62.6533 62.0269 50.5718 19.7701 25.641 72.9143 56.6186 66.6667 47.0588 40.9438 49.7087 44.3599 66.3626 45.7143 58.5075 65.8071 65.8436 74.2996 71.9794 72.6406 73.6271 64.1686 54.321 46.8305 69.4992 65.9898 70.7347 73.0354 63.0225 78.4508 52.2696 73.2773 54.1578 53.6965 84.6878 67.5325 70.0491 74.4458 78.5394 72.6634 60.9865 75.3323 78.2274 61.1422 59.9562 68.1239 16.3934 73.8988 72.1613 74.8092 77.1581 73.4341 74.2597 59.3692 90.3458 43.2638 58.8549 65.8385 53.9278 78.5674 78.8444 55.9824 79.7428 55.7016 67.8941 68.4654 79.7327 85.4981 75.4579 13.5977 70.34 70.6625 42.1918 72.2782 57.8448 46.4768 83.994 70.0132 41.7193 51.5068 60.8696 60.5898 65.1757 83.2821 65.4804 50.7193 47.5645 67.2566 58.8235 44.5689 60.626 76.4247 69.4021 77.3227 74.3338 54.8673 61.2093 48.3986 68.0203 26.7559 45.045 38.4 61.7406 71.1297 66.1519 62.4923 58.0559 88.2533 47.681 42.3306 48.8432 64.9903 53.617 57.1213 68.0592 57.8136 78.1804 70.2509 57.1429 75.4491 33.9223 78.2798 76.5543 63.36 58.4022 56.4551 63.4965 40.8008 42.0933 59.8665 69.8643 57.0529 48.4966 68.5714 38.9744 63.6214 44.3864 65.5319 79.1899 66.2661 52.8389 58.0822 79.2825 63.5805 63.6785 80.9981 62.4632 59.083 56.5976 78.6169 41.4673 79.9691 63.5386 41.1946 60.1607 78.6534 55.6492 51.7219 57.9048 68.7339 70.5604 62.6234 57.5574 61.2514 71.4556 72.8355 71.4709 75.493 64.6809 70.8464 70.274 63.5738 68.0641 30.4762 63.0728 48.4182 58.3865 53.7931 68.4791 69.4184 38.8098 79.0765 45.7872 72.4055 59.8169 42.0538 60.9212 69.0449 67.8038 47.2648 47.1532 57.4132 29.8874 57.0477 67.052 32.7198 69.0569 42.1286 68.8103 59.3775 68.9292 67.1414 68.5408 72.6142 73.2601 73.9284 39.0746 58.2651 63.3113 75.6562 60.9364 60.5452 57.3224 62.738 62.119 52.2073 66.919 58.4872 67.4352 48.8169 67.231 50.0645 59.5084 80.0162 55.6544 72.7973 70.5882 53.831 77.6652 78.6273 73.2892 7.36196 73.8392 71.5262 54.4987 34.0426 72.7543 78.2979 78.649 78.5515 63.1433 38.2609 62.9457 54.7027 14.0351 61.8585 76.818 48.8449 74.1155 75.7856 74.0787 60.915 39.7838 74.3261 65.0746 72.95 62.08 42.9379 43.1746 71.5867 40.1826 71.786 54.7628 54.8918 77.6119 55.6068 69.947 73.7334 65.9815 28.2158 30.3605 79.1075 74.2681 67.5556 51.9031 77.0156 63.148 42.7932 64.5045 62.0488 73.28 40.7148 80.2097 74.0484 76.229 76.2431 81.3239 75.5654 25.3383 57.4949 66.8524 72.0944 65.7471 67.6835 30.1158 72.3067 75.1145 64.6729 77.3083 69.9898 47.5214 36.8601 70.0665 44.7122 34.8993 37.4065 53.0841 31.479 69.6008 74.2338 32.5041 38.0022 42.0382 70.4888 57.0016 56.513 55.971 ]

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.00577 (Xent), [AvgXent: 1.00577, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 70.0509% <<

