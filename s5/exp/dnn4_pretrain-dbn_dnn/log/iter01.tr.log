vgnd012
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet_dbn_dnn.init exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter01 
WARNING (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:228) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:408) Selecting from 1 GPUs
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:423) cudaSetDevice(0): Tesla K80	free:11372M, used:68M, total:11441M, free/total:0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:471) Device: 0, mem_ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:352) Trying to select device: 0
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:481) Success selecting device 0 free mem ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:FinalizeActiveGpu():cu-device.cc:308) The active GPU is [0]: Tesla K80	free:11300M, used:140M, total:11441M, free/total:0.987698 version 3.7
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
ali-to-post ark:- ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.49621, max 8.18284, mean 0.00945758, stddev 0.991793, skewness 0.143257, kurtosis 2.14069 ) 
[1] output of <AffineTransform> ( min -21.6297, max 12.9438, mean -3.24737, stddev 2.38597, skewness 0.142745, kurtosis 1.97125 ) 
[2] output of <Sigmoid> ( min 4.03964e-10, max 0.999998, mean 0.129408, stddev 0.222148, skewness 2.38031, kurtosis 4.95375 ) 
[3] output of <AffineTransform> ( min -18.9639, max 12.3104, mean -2.80469, stddev 2.03334, skewness 0.0610867, kurtosis 2.70761 ) 
[4] output of <Sigmoid> ( min 5.8086e-09, max 0.999995, mean 0.134872, stddev 0.203138, skewness 2.47228, kurtosis 5.78807 ) 
[5] output of <AffineTransform> ( min -14.8357, max 9.70179, mean -3.16305, stddev 1.97363, skewness 0.684975, kurtosis 2.31349 ) 
[6] output of <Sigmoid> ( min 3.6053e-07, max 0.999939, mean 0.111043, stddev 0.197402, skewness 2.83831, kurtosis 7.79325 ) 
[7] output of <AffineTransform> ( min -20.9061, max 13.8566, mean -2.84927, stddev 1.82536, skewness 0.584287, kurtosis 3.64616 ) 
[8] output of <Sigmoid> ( min 8.32929e-10, max 0.999999, mean 0.119831, stddev 0.192011, skewness 2.81226, kurtosis 7.76015 ) 
[9] output of <AffineTransform> ( min -14.183, max 9.70949, mean -3.33202, stddev 1.85513, skewness 1.19032, kurtosis 3.49568 ) 
[10] output of <Sigmoid> ( min 6.92469e-07, max 0.999939, mean 0.0949646, stddev 0.188695, skewness 3.22549, kurtosis 10.2137 ) 
[11] output of <AffineTransform> ( min -20.5405, max 19.0285, mean -3.31509, stddev 1.84593, skewness 1.45602, kurtosis 5.95977 ) 
[12] output of <Sigmoid> ( min 1.20052e-09, max 1, mean 0.0938031, stddev 0.19063, skewness 3.24721, kurtosis 10.1897 ) 
[13] output of <AffineTransform> ( min -3.09876, max 3.47779, mean -0.0162781, stddev 0.623158, skewness 0.0147562, kurtosis 0.32273 ) 
[14] output of <Softmax> ( min 1.716e-05, max 0.0120478, mean 0.000518672, stddev 0.000364584, skewness 3.02127, kurtosis 23.0559 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.0753985, max 0.149413, mean 3.46367e-05, stddev 0.00654654, skewness 0.175904, kurtosis 10.0248 ) 
[1] diff-output of <AffineTransform> ( min -0.0356597, max 0.039331, mean 5.85102e-05, stddev 0.00179028, skewness 0.661144, kurtosis 33.6229 ) 
[2] diff-output of <Sigmoid> ( min -0.154441, max 0.212576, mean 7.77789e-05, stddev 0.0142343, skewness 0.116034, kurtosis 5.27213 ) 
[3] diff-output of <AffineTransform> ( min -0.0353402, max 0.0368422, mean 6.10416e-05, stddev 0.00177919, skewness 0.508624, kurtosis 24.1516 ) 
[4] diff-output of <Sigmoid> ( min -0.154192, max 0.148518, mean -2.42802e-05, stddev 0.0140615, skewness 0.0512122, kurtosis 3.74445 ) 
[5] diff-output of <AffineTransform> ( min -0.0338441, max 0.02983, mean 6.0486e-05, stddev 0.00180871, skewness 0.505211, kurtosis 26.982 ) 
[6] diff-output of <Sigmoid> ( min -0.136872, max 0.180506, mean 2.8004e-05, stddev 0.0149942, skewness 0.0903023, kurtosis 3.29613 ) 
[7] diff-output of <AffineTransform> ( min -0.0326867, max 0.0363184, mean 6.63805e-05, stddev 0.00193182, skewness 0.527046, kurtosis 21.4107 ) 
[8] diff-output of <Sigmoid> ( min -0.155221, max 0.149739, mean -5.47125e-05, stddev 0.0158605, skewness 0.0590644, kurtosis 2.39516 ) 
[9] diff-output of <AffineTransform> ( min -0.0315782, max 0.0319609, mean 6.76736e-05, stddev 0.00221143, skewness 0.505974, kurtosis 22.2171 ) 
[10] diff-output of <Sigmoid> ( min -0.193872, max 0.169816, mean 2.41314e-07, stddev 0.0237561, skewness 0.0337306, kurtosis 1.30918 ) 
[11] diff-output of <AffineTransform> ( min -0.0779412, max 0.0851253, mean 9.5105e-05, stddev 0.00699681, skewness 0.234019, kurtosis 15.3956 ) 
[12] diff-output of <Sigmoid> ( min -0.40133, max 0.377409, mean 0.000823067, stddev 0.0913568, skewness -0.00985858, kurtosis 0.00489831 ) 
[13] diff-output of <AffineTransform> ( min -0.999934, max 0.0120478, mean 2.85e-10, stddev 0.0227666, skewness -43.882, kurtosis 1923.42 ) 
[14] diff-output of <Softmax> ( min -0.999934, max 0.0120478, mean 2.85e-10, stddev 0.0227666, skewness -43.882, kurtosis 1923.42 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -0.243879, max 0.231365, mean 0.00044639, stddev 0.0300565, skewness 0.0610651, kurtosis 1.4558 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.0866616, max 0.126486, mean 0.0149786, stddev 0.0301934, skewness 0.138705, kurtosis 0.459581 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.0662876, max 0.0982472, mean 0.00205552, stddev 0.00795345, skewness 0.521991, kurtosis 3.92414 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.0771125, max 0.113249, mean 0.0156266, stddev 0.0306772, skewness 0.0849225, kurtosis 0.0708787 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.0745891, max 0.110844, mean 0.00214878, stddev 0.00760465, skewness 0.409286, kurtosis 3.3639 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.0838628, max 0.128752, mean 0.0154844, stddev 0.0306193, skewness 0.128136, kurtosis 0.419265 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.0983625, max 0.135623, mean 0.00196611, stddev 0.00768283, skewness 0.603112, kurtosis 6.35833 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.106459, max 0.144567, mean 0.0169934, stddev 0.0338695, skewness 0.0555807, kurtosis 0.361261 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.105138, max 0.178471, mean 0.00212436, stddev 0.00878864, skewness 0.678553, kurtosis 6.42053 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.127386, max 0.195358, mean 0.0173244, stddev 0.0389246, skewness 0.278298, kurtosis 1.0124 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.716597, max 0.601865, mean 0.00248496, stddev 0.0280691, skewness 0.405282, kurtosis 26.5792 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.621262, max 0.725166, mean 0.0243469, stddev 0.148596, skewness 0.211731, kurtosis 2.34789 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -16.8865, max 0.265287, mean -5.74398e-09, stddev 0.099417, skewness -43.5771, kurtosis 5123.26 ) , lr-coef 1, max-norm 0
  bias_grad ( min -16.8476, max 0.483991, mean 1.48393e-09, stddev 0.560586, skewness -16.4051, kurtosis 443.071 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-pdf[5.5.734~1-794732a]:main():ali-to-pdf.cc:68) Converted 3696 alignments to pdf sequences.
LOG (ali-to-post[5.5.734~1-794732a]:main():ali-to-post.cc:73) Converted 3696 alignments.
LOG (copy-feats[5.5.734~1-794732a]:main():copy-feats.cc:143) Copied 3328 feature matrices.
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:384) ### After 1012992 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.21036, max 7.88956, mean 0.00637491, stddev 0.994874, skewness 0.113357, kurtosis 2.26778 ) 
[1] output of <AffineTransform> ( min -33.4713, max 22.9694, mean -3.31741, stddev 3.85303, skewness 0.144664, kurtosis 1.82882 ) 
[2] output of <Sigmoid> ( min 2.90815e-15, max 1, mean 0.193945, stddev 0.303123, skewness 1.61159, kurtosis 1.18977 ) 
[3] output of <AffineTransform> ( min -28.928, max 17.9665, mean -3.4462, stddev 2.57285, skewness -0.00499487, kurtosis 2.54048 ) 
[4] output of <Sigmoid> ( min 2.73361e-13, max 1, mean 0.121076, stddev 0.211046, skewness 2.5361, kurtosis 5.98546 ) 
[5] output of <AffineTransform> ( min -14.0386, max 12.4982, mean -2.98236, stddev 2.03692, skewness 0.657387, kurtosis 2.46738 ) 
[6] output of <Sigmoid> ( min 8.00031e-07, max 0.999996, mean 0.124492, stddev 0.202623, skewness 2.59873, kurtosis 6.52394 ) 
[7] output of <AffineTransform> ( min -22.4452, max 20.85, mean -2.15404, stddev 2.06365, skewness 0.395407, kurtosis 3.33155 ) 
[8] output of <Sigmoid> ( min 1.78715e-10, max 1, mean 0.193312, stddev 0.239569, skewness 1.79644, kurtosis 2.46301 ) 
[9] output of <AffineTransform> ( min -14.9466, max 15.5084, mean -2.18014, stddev 2.5708, skewness 0.912561, kurtosis 2.12451 ) 
[10] output of <Sigmoid> ( min 3.22689e-07, max 1, mean 0.214747, stddev 0.286174, skewness 1.54001, kurtosis 1.14187 ) 
[11] output of <AffineTransform> ( min -31.0325, max 26.2928, mean -3.61412, stddev 3.32248, skewness 0.736896, kurtosis 2.5454 ) 
[12] output of <Sigmoid> ( min 3.33251e-14, max 1, mean 0.147584, stddev 0.282361, skewness 2.08348, kurtosis 2.92174 ) 
[13] output of <AffineTransform> ( min -12.7182, max 19.8326, mean -0.0192898, stddev 3.03258, skewness 0.655996, kurtosis 1.138 ) 
[14] output of <Softmax> ( min 3.57798e-13, max 0.99889, mean 0.000518569, stddev 0.0146027, skewness 47.3477, kurtosis 2565.55 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -2.21318, max 0.715411, mean 0.000143337, stddev 0.0441048, skewness -1.34526, kurtosis 72.5613 ) 
[1] diff-output of <AffineTransform> ( min -0.196617, max 0.409459, mean 8.25335e-05, stddev 0.00778623, skewness 1.62445, kurtosis 99.681 ) 
[2] diff-output of <Sigmoid> ( min -1.14459, max 2.79977, mean 0.00049306, stddev 0.068167, skewness 0.604257, kurtosis 28.7674 ) 
[3] diff-output of <AffineTransform> ( min -0.255791, max 0.266432, mean 5.78333e-05, stddev 0.00882724, skewness 0.33684, kurtosis 69.548 ) 
[4] diff-output of <Sigmoid> ( min -1.67906, max 1.51841, mean 0.000348326, stddev 0.0815327, skewness 0.0518584, kurtosis 12.1028 ) 
[5] diff-output of <AffineTransform> ( min -0.218366, max 0.394098, mean 6.45666e-05, stddev 0.00938528, skewness 0.279474, kurtosis 57.6629 ) 
[6] diff-output of <Sigmoid> ( min -0.983401, max 1.78557, mean 0.000584993, stddev 0.0767348, skewness 0.144022, kurtosis 11.1214 ) 
[7] diff-output of <AffineTransform> ( min -0.166343, max 0.185031, mean 3.91199e-05, stddev 0.00820699, skewness -0.0241212, kurtosis 27.2055 ) 
[8] diff-output of <Sigmoid> ( min -0.68998, max 1.08327, mean 0.00027215, stddev 0.0568452, skewness 0.0107454, kurtosis 8.86748 ) 
[9] diff-output of <AffineTransform> ( min -0.116913, max 0.153665, mean 3.56304e-05, stddev 0.00625349, skewness 0.0213269, kurtosis 25.9867 ) 
[10] diff-output of <Sigmoid> ( min -0.6008, max 0.670568, mean 0.000128716, stddev 0.045623, skewness -0.112481, kurtosis 7.53493 ) 
[11] diff-output of <AffineTransform> ( min -0.131465, max 0.144489, mean 1.58732e-06, stddev 0.00777759, skewness 0.0782025, kurtosis 31.7597 ) 
[12] diff-output of <Sigmoid> ( min -1.32651, max 1.12088, mean 0.000761435, stddev 0.0824689, skewness -0.059557, kurtosis 3.73693 ) 
[13] diff-output of <AffineTransform> ( min -0.999999, max 0.94801, mean -9.14706e-09, stddev 0.01744, skewness -30.6257, kurtosis 2079.66 ) 
[14] diff-output of <Softmax> ( min -0.999999, max 0.94801, mean -9.14706e-09, stddev 0.01744, skewness -30.6257, kurtosis 2079.66 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.9812, max 1.9542, mean -0.000135515, stddev 0.122645, skewness 0.0276049, kurtosis 3.49514 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.450357, max 0.647277, mean 0.0211286, stddev 0.125675, skewness 0.112827, kurtosis 1.36863 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.770384, max 0.533312, mean 0.00283325, stddev 0.0511115, skewness 0.0187082, kurtosis 6.3652 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.745441, max 0.625895, mean 0.0148053, stddev 0.14066, skewness 0.119225, kurtosis 2.38468 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.67918, max 0.619852, mean 0.00204004, stddev 0.0364167, skewness 0.278165, kurtosis 9.53865 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.829731, max 0.887807, mean 0.0165291, stddev 0.148692, skewness 0.263818, kurtosis 3.00419 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.476249, max 0.456649, mean 0.00122502, stddev 0.0308122, skewness 0.110668, kurtosis 7.63146 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.627208, max 0.607405, mean 0.0100147, stddev 0.12856, skewness 0.021554, kurtosis 1.49454 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.324883, max 0.332784, mean 0.00175664, stddev 0.0307245, skewness 0.236129, kurtosis 3.67997 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.404463, max 0.463065, mean 0.00912138, stddev 0.0993755, skewness 0.250002, kurtosis 1.09005 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.422589, max 0.569326, mean 4.2667e-05, stddev 0.0448542, skewness 0.0552623, kurtosis 3.73232 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.455361, max 0.633211, mean 0.000406337, stddev 0.123431, skewness 0.0986818, kurtosis 1.59085 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.9965, max 1.96976, mean 2.38035e-09, stddev 0.0920079, skewness -5.08028, kurtosis 68.4201 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.87429, max 1.24432, mean -1.73126e-09, stddev 0.287541, skewness -1.98954, kurtosis 9.1125 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:395) Done 3328 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.763905 min, processing 22101.2 frames per sec; i/o time 2.46632%]
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 37614 216 186 380 133 108 339 588 415 2364 944 124 1446 467 142 200 440 282 444 415 596 437 143 810 434 252 254 309 472 738 646 1036 178 243 1381 668 1893 1078 400 136 117 241 135 365 622 468 155 416 3097 14611 2493 618 408 235 51771 1168 777 228 126 428 747 457 798 272 98 454 1896 1626 409 418 2680 178 690 281 333 325 584 1311 226 2446 3054 314 731 182 373 1087 182 328 630 717 294 207 1002 657 60 523 535 375 435 372 386 562 341 1111 328 238 337 276 252 710 996 131 339 179 670 652 666 308 288 1560 404 643 248 145 284 539 576 422 213 1237 470 576 382 533 345 319 612 207 497 390 354 215 758 133 353 358 478 429 280 791 97 527 601 1967 340 367 193 152 311 447 251 328 792 331 757 89 192 136 721 229 272 304 905 374 111 801 237 575 1661 593 78 323 456 229 482 317 137 470 482 1087 211 153 678 175 731 353 540 91 311 197 169 518 123 1173 370 429 388 487 376 167 395 341 363 364 1022 429 233 430 524 207 301 116 1045 235 111 966 500 707 493 383 255 294 217 383 213 394 200 539 443 428 660 328 537 378 272 361 126 279 241 669 167 389 240 433 331 437 427 117 148 383 272 315 871 420 321 1435 93 188 144 353 338 735 760 339 709 614 1416 140 1136 127 890 243 614 583 190 437 272 585 283 566 440 372 165 215 193 356 618 382 266 520 889 244 320 275 506 723 211 206 276 236 548 512 243 430 388 738 338 772 406 465 70 248 481 665 441 373 210 296 440 186 142 344 499 1312 353 472 355 367 1354 308 385 603 167 588 252 196 260 148 237 527 418 784 596 370 758 203 562 290 782 104 502 443 63 543 479 303 174 295 490 191 265 245 235 423 312 168 742 374 222 143 148 65 303 396 412 156 121 128 251 480 821 112 255 233 232 278 270 385 324 114 1345 333 315 1218 1563 314 252 399 372 1243 277 206 610 85 221 722 402 1005 389 424 294 115 494 279 294 209 245 315 1167 433 428 534 239 125 502 276 663 628 512 2599 304 229 381 414 308 946 609 199 1086 164 131 131 171 326 204 2044 177 391 239 260 812 374 820 74 206 244 680 203 323 125 217 193 134 438 364 564 106 241 693 603 251 1088 530 586 374 167 368 316 407 299 448 690 222 487 761 219 122 872 438 117 179 186 442 218 272 329 344 95 310 217 294 494 478 168 456 505 144 153 647 108 483 306 581 69 322 237 751 1361 238 151 286 479 543 359 159 671 435 174 184 766 596 798 303 344 335 222 250 71 844 620 248 292 82 102 449 750 429 418 287 119 311 408 574 263 1945 754 171 301 122 1833 305 488 297 999 784 409 783 668 72 312 345 348 261 290 391 346 522 140 179 263 177 119 631 995 224 649 308 447 323 744 257 161 501 401 163 153 364 452 152 481 373 652 346 925 158 372 307 394 833 339 127 302 375 211 440 317 319 181 455 372 358 777 413 685 160 446 200 749 906 81 462 109 930 915 669 163 242 567 944 219 548 46 573 633 748 611 240 290 121 407 450 361 194 260 129 108 873 599 187 551 178 193 748 810 417 670 136 465 102 327 553 348 164 108 725 535 315 370 197 300 221 322 920 191 407 584 288 182 406 372 375 1085 185 383 693 277 188 526 791 309 337 364 513 297 496 529 348 327 428 339 420 348 311 912 570 215 283 181 197 310 106 491 84 250 182 819 212 579 312 140 478 554 534 191 139 1196 445 315 486 723 232 304 227 930 299 207 695 203 276 1422 309 431 393 294 426 296 448 395 180 462 138 206 89 387 468 269 627 469 824 136 462 410 143 302 116 492 153 211 446 299 169 191 1232 150 764 247 490 325 1056 298 286 301 201 323 238 121 204 155 782 228 191 374 203 1553 143 111 301 571 601 1341 559 161 296 440 208 208 659 27 439 652 212 225 122 291 432 247 388 514 968 272 355 330 311 453 375 381 1796 601 167 154 391 1612 289 934 995 221 236 544 350 411 535 570 258 359 1029 328 119 412 334 503 202 93 538 337 152 286 504 160 737 103 397 386 402 1068 746 201 618 702 198 386 447 661 97 662 757 281 563 365 219 431 957 488 295 223 189 183 149 867 254 158 485 237 725 167 83 130 711 823 272 292 299 482 360 287 897 166 803 393 198 316 305 328 596 35 357 288 124 253 349 93 538 676 219 341 386 988 298 293 374 380 314 122 507 268 560 627 140 200 198 897 221 158 324 930 217 297 444 1331 350 723 383 301 576 394 120 337 627 281 645 486 312 454 903 244 1111 215 649 166 320 386 410 560 700 240 216 702 205 473 303 813 153 851 630 983 929 336 797 403 163 138 302 1163 284 144 920 430 183 352 417 239 235 406 421 385 194 546 537 527 195 440 139 425 253 167 557 616 182 503 316 551 172 350 301 298 313 198 216 1202 720 464 203 388 218 1487 141 1000 216 399 805 708 1049 499 138 390 140 174 363 218 340 334 303 846 382 219 193 705 395 225 507 265 1131 201 1164 377 666 495 1268 1167 379 832 259 397 393 421 361 476 364 269 378 211 958 396 473 1016 469 868 417 367 400 502 1215 1010 499 974 207 211 575 209 136 158 848 405 200 666 668 468 95 413 383 111 361 646 168 196 277 224 1446 706 215 977 140 596 278 517 241 184 595 965 703 164 153 395 723 515 152 362 537 167 769 397 550 1124 1066 365 373 502 356 726 1199 770 198 674 580 381 507 459 121 1126 303 544 707 1190 352 477 384 365 274 275 307 334 372 309 139 490 199 341 551 1239 339 239 514 111 193 343 371 301 411 336 319 197 293 513 239 294 259 1678 731 329 486 1388 255 356 115 479 457 515 298 509 477 669 907 367 166 298 1121 221 393 389 1189 1538 467 642 573 695 292 445 387 316 193 267 354 838 378 1236 358 561 535 421 704 465 604 366 509 364 136 452 276 342 390 512 270 680 716 707 650 202 188 590 222 413 205 164 267 96 496 482 243 362 525 326 483 779 542 429 117 778 627 542 313 430 426 400 236 174 900 562 430 206 615 608 440 744 186 666 511 551 824 190 314 452 441 202 1643 517 555 422 576 365 399 105 630 1462 177 225 688 245 264 405 584 174 300 881 472 366 1215 759 370 195 289 282 238 701 37 150 126 514 960 733 155 994 252 269 322 684 455 509 295 264 385 383 260 789 653 113 166 189 225 20 398 499 301 521 683 126 202 208 755 619 446 519 638 118 320 1393 155 339 221 998 302 152 322 291 292 1078 363 633 952 696 206 163 57 1143 1470 235 750 925 55 949 190 1157 142 238 368 645 432 508 627 292 262 1520 538 221 253 280 568 463 2791 178 681 335 293 531 652 2285 1337 534 204 454 1136 124 101 760 133 763 184 611 606 531 503 467 159 691 773 341 595 123 168 497 209 207 1071 164 282 244 591 588 786 731 413 445 1679 424 221 363 261 358 438 429 376 232 464 108 552 455 196 526 685 689 484 510 402 277 144 219 556 160 295 461 530 367 239 316 721 540 546 363 272 629 766 173 427 218 341 402 420 387 851 297 191 263 412 1258 511 543 630 383 632 350 273 525 249 610 317 383 192 532 927 284 703 1187 345 234 237 529 640 1153 184 205 689 665 682 338 254 448 575 838 1039 528 493 197 317 243 915 614 243 409 211 727 286 532 948 308 151 162 442 480 456 395 1410 1151 499 468 149 663 616 838 373 238 1263 506 1015 160 468 2725 190 667 729 531 314 779 494 448 409 393 217 97 437 381 208 127 720 257 394 438 52 502 969 121 410 194 524 737 213 202 386 329 295 401 324 155 503 363 297 234 642 2282 731 305 1195 780 711 334 338 259 446 228 274 152 1986 3421 196 654 231 219 269 1113 263 375 80 235 893 536 455 155 1863 434 296 224 396 136 176 426 475 182 1538 895 333 996 378 395 182 218 186 156 487 140 1216 174 282 773 446 303 833 426 500 356 282 537 421 492 149 55 187 304 597 388 814 375 1468 614 420 194 258 117 663 574 681 648 139 220 250 424 918 667 312 181 228 357 524 439 524 552 1428 515 332 292 908 191 117 987 582 431 182 557 1382 323 260 1189 861 1231 549 313 646 511 485 435 653 889 769 262 193 633 354 413 455 264 1091 506 177 117 159 2171 2543 405 157 556 363 861 652 680 799 386 346 587 621 491 204 336 434 703 228 623 158 488 450 259 244 641 225 155 626 854 491 373 1849 136 991 194 305 1887 971 715 348 795 551 344 260 660 839 173 401 413 387 386 2469 393 1038 212 254 1036 830 226 244 441 219 583 352 673 3172 414 538 359 402 967 462 85 360 1024 151 268 1352 800 382 462 1131 167 530 312 973 157 135 109 579 1380 577 167 325 660 641 486 120 263 246 324 337 144 415 530 558 277 512 312 643 381 144 742 452 634 1127 406 730 897 847 217 524 129 756 982 267 319 491 292 146 676 373 74 200 267 368 488 440 301 460 235 828 303 748 414 ]
@@@ Loss per-class: [ 0.821504 2.46418 2.78563 2.40431 3.4431 4.88024 2.69391 1.85836 2.22994 1.1291 0.892612 3.92446 1.49063 1.8793 3.37026 3.15905 1.93363 4.26537 2.41426 2.15188 2.3446 1.68008 2.70693 1.91215 2.66918 2.10755 2.36132 1.88436 1.94115 1.45419 1.4594 1.88979 2.47988 2.75846 0.97094 1.29689 0.949887 0.853238 2.44542 4.84036 3.99008 2.69524 4.62802 1.99914 1.72399 1.5005 2.84707 2.36767 1.14099 1.59138 0.668922 1.54342 1.61022 2.99083 0.492568 1.55766 1.04787 2.70878 3.89264 1.49075 1.41555 2.71203 1.929 2.79544 3.40102 2.02217 1.51307 1.36581 2.41354 2.11393 0.847602 2.82688 1.51528 2.51706 2.19163 2.66333 1.68832 1.08074 3.49965 1.13211 1.47236 1.7222 1.53864 2.5459 2.88278 1.38355 2.51268 3.12566 2.3867 1.70981 2.19061 3.27389 1.67484 1.97829 4.30922 2.30006 2.46917 2.06296 2.68569 2.42986 2.14306 1.906 3.24975 1.41784 3.63159 2.48741 1.66044 2.33165 3.65456 1.7057 1.78766 3.34835 3.01731 2.76294 2.40415 1.97331 1.47666 2.37759 3.2735 1.59254 1.99891 1.24801 3.86634 3.12194 3.15378 1.43006 2.6478 2.22862 2.78876 1.5461 1.8951 2.19567 2.0935 2.2367 2.44895 2.55217 1.78255 3.43726 2.48537 2.54899 2.44274 2.46314 1.24048 2.85189 1.58578 2.19702 2.2635 2.97663 2.68582 2.29535 3.92761 1.60937 1.89934 2.12439 1.78665 2.54624 2.89611 2.66661 1.84332 1.95609 3.4995 2.17647 1.61819 3.03065 1.14163 3.97551 2.97615 3.41751 2.04929 3.25551 1.93458 1.58142 2.35742 2.4104 3.96069 1.81814 2.00458 2.08844 1.25234 2.4645 3.94318 2.32946 1.69524 2.87049 1.45103 2.93956 3.2412 1.95258 2.39337 1.788 3.61641 2.71611 1.12026 2.77234 1.86556 1.91593 2.06322 4.05704 2.23117 2.51438 3.04096 2.32516 2.73644 1.68871 2.13154 1.86614 2.77451 2.09677 1.82289 2.93258 1.84263 1.57994 3.90339 2.72924 1.28044 2.28658 2.27439 1.86593 2.79515 1.82583 1.73851 4.66399 2.0341 3.38296 4.55615 2.48726 2.8355 1.70527 1.4895 2.20548 1.96456 3.31146 2.84858 1.3247 2.59856 1.90783 2.77627 2.34138 1.70326 2.31519 0.870105 2.31656 1.33707 1.63118 2.46697 2.92895 2.9971 2.48893 3.3954 1.24606 2.04065 2.99313 2.26567 1.90499 2.34606 2.29932 1.74738 3.75419 2.85521 1.81512 3.09571 3.75531 1.4795 2.42814 2.30481 1.17803 3.94833 2.49537 4.34518 1.69902 2.4402 1.71318 1.60328 2.77915 2.50963 1.7884 0.842731 4.52303 1.06715 4.15395 1.59213 3.15258 1.8125 3.29561 3.12905 2.04303 2.51617 1.66275 2.35968 2.77154 1.63385 1.59793 2.71434 2.60477 3.04943 2.62957 1.27343 2.60596 2.14401 1.95538 1.35873 2.59023 2.56993 2.07987 1.75655 1.79758 2.42993 1.9147 2.29183 2.91819 2.18528 2.83959 2.76461 1.81875 2.00194 1.51386 1.92706 2.057 2.63263 1.75031 5.31241 3.63937 2.64348 1.71453 1.72094 3.25835 2.29404 3.00806 1.51032 2.21308 3.82715 2.95031 2.17634 0.972083 3.0471 2.06674 2.18356 2.30386 1.91399 2.21466 1.67431 2.43736 3.1947 2.40388 3.0183 2.72207 3.32667 2.89269 2.53458 2.39694 2.97194 1.15943 2.21539 1.90841 2.47103 2.50076 1.72712 2.54173 1.82449 2.67402 1.91071 4.06763 5.01732 1.48185 2.76075 2.68203 2.93882 3.18811 1.79382 2.9948 2.52525 2.69307 3.62198 1.90865 2.10827 2.71118 1.40309 2.39726 1.7931 3.16633 3.3466 5.31698 2.85342 2.00547 2.16627 2.63937 3.58968 2.78742 3.56742 1.72841 1.47298 3.17013 2.05544 3.75025 2.41484 2.4482 2.60277 2.47608 3.26821 3.93096 1.68457 2.86629 2.59521 2.34088 1.57168 2.04409 2.52457 2.8879 1.51926 1.47402 2.02185 3.13678 1.85673 4.77508 2.26604 1.71009 1.69487 1.25877 2.23969 2.01073 1.90332 3.42715 2.56606 2.00346 2.29903 3.38147 3.15495 3.06986 2.51434 2.12061 1.72281 1.73772 3.1246 3.08287 2.21971 2.6902 1.90466 2.02249 1.59217 1.44761 1.5571 2.91305 1.76645 2.23162 2.70171 1.74074 2.34937 3.24819 1.43927 3.47859 3.80783 4.06347 3.0387 2.11459 3.49609 0.971547 2.35481 2.54262 3.06184 3.00592 1.43755 2.65398 2.07367 4.33261 2.55979 2.9293 1.17818 2.68805 2.16106 4.68152 3.68803 3.25556 4.17448 1.386 2.94286 1.91276 3.44976 2.83847 2.05881 2.15617 2.146 1.49674 2.07038 1.94159 2.27765 3.75505 2.49326 1.57665 2.26125 2.4864 2.63064 1.34744 2.73874 2.45976 2.10938 2.97743 3.91541 1.58843 2.03766 3.51824 2.79673 3.81437 2.52443 3.11472 2.33898 2.01522 2.39631 4.52041 3.10768 2.56212 3.02956 2.69061 2.09964 2.92503 1.52994 1.45199 2.43543 2.88995 2.20502 3.55524 2.35338 2.48901 1.93544 4.0621 2.54825 4.34188 1.95135 1.55382 2.74389 2.56964 2.49205 1.85191 2.76283 1.81947 3.13881 1.85082 4.09498 2.6979 2.61076 2.23673 1.69247 2.08003 1.84247 2.72633 2.1805 3.7872 3.46676 3.52944 1.21094 1.98732 2.95288 2.28875 4.68359 3.67926 1.88501 2.05889 2.43525 2.77078 1.86572 3.66079 3.36096 2.02949 1.70455 3.51739 1.97922 1.97188 3.07154 2.81719 4.03219 2.09235 2.71161 2.48498 1.95104 1.94478 1.29183 2.38201 1.82956 1.75577 4.34407 2.44148 2.95899 2.68803 3.53172 2.97059 2.70515 2.34058 2.45347 3.74233 4.05207 2.56625 2.89509 4.01171 2.24343 2.47853 2.66225 2.43959 2.20705 2.21246 2.3721 2.2283 1.93244 3.34583 2.72937 2.55035 3.89915 2.77837 2.62354 2.48186 3.21998 2.66024 2.48863 1.37676 1.85414 1.73765 3.55801 2.26308 2.83756 2.13317 2.23305 1.71413 2.29774 3.33193 1.34152 1.99977 2.81761 2.02576 2.79205 3.09914 3.87684 2.54025 1.66102 2.14103 3.16068 2.56874 2.55189 2.90543 2.56042 2.2585 2.00836 3.70339 2.1068 3.20962 1.7279 2.14044 1.88259 2.89084 3.92371 3.18702 1.78794 2.3148 2.22508 5.73559 2.08626 1.98297 1.67391 2.73726 2.36218 1.84432 2.94557 2.58015 1.79013 1.95865 2.67391 2.75469 4.26205 3.2817 2.06714 1.44502 3.82808 2.19599 2.32647 3.05561 1.91826 1.37169 2.48474 2.10659 2.90245 2.30229 4.02971 1.95027 1.7568 1.93216 3.30428 4.10274 1.71346 3.43645 3.78798 2.23511 2.86196 4.06641 4.08063 3.20623 1.64389 2.92652 2.66831 1.86001 2.18428 4.60624 2.67912 2.55084 2.54745 1.62635 2.70015 2.07362 1.12627 3.17487 3.34883 2.61297 1.47961 2.06456 2.85048 2.12705 2.39651 3.90639 1.95822 2.06174 2.39183 1.96404 1.98389 2.62671 1.96644 2.33373 2.3394 1.65223 1.77606 2.43598 3.49951 2.67154 4.00401 3.87852 3.89761 2.57161 7.29555 2.84468 3.31356 1.99957 3.16108 1.5822 2.55655 3.10506 2.35321 3.2697 2.2924 3.44153 2.68556 2.2626 3.09581 3.34804 1.67418 1.68832 2.97832 1.97763 3.07659 1.59577 2.44329 2.77908 1.73335 2.77684 2.84573 1.86476 2.59266 2.59796 2.39876 3.40415 3.08093 4.15539 1.97845 2.60144 2.69078 1.72158 3.94147 4.08656 3.74867 2.37163 2.35334 3.60073 1.85364 2.28971 2.21081 2.76229 2.03007 2.91447 3.36675 3.37746 4.35221 2.43058 3.87251 2.21053 2.39706 2.33572 3.98216 3.71068 2.18279 2.79415 2.19624 2.59031 1.86859 2.01915 1.87596 2.81061 2.56455 3.91795 2.77732 2.4137 3.4645 4.06342 5.08934 2.30633 1.81082 3.40711 2.62778 3.14469 3.22204 1.36781 3.29111 4.31954 2.05117 1.54059 2.53342 1.95332 2.42597 3.87792 2.25876 2.18119 1.76485 2.74571 2.61172 4.84475 2.83607 3.06645 2.52798 3.22656 3.99202 3.24831 2.41449 2.53348 2.58431 2.58195 2.39018 2.48367 2.58936 2.09564 2.90674 1.83458 3.96933 1.97503 1.63158 2.57379 3.11755 3.7768 2.19233 1.60107 2.72346 1.82876 1.6428 5.07778 2.88364 2.10739 2.42342 3.15018 2.20261 2.49683 2.76632 3.13879 1.58228 3.59849 3.9649 2.28106 2.15455 2.28504 3.17905 4.35519 2.28704 2.82052 2.83663 2.49117 1.63803 2.83348 1.57613 3.74919 2.08374 1.94488 2.66257 1.35591 2.15822 3.90698 1.66819 1.76498 2.29672 2.14453 2.33216 2.0373 4.66468 2.38066 2.7182 2.68371 1.72596 2.03513 3.48246 3.37595 1.95457 1.29079 3.04826 2.46428 2.89576 2.94633 2.81489 1.64977 2.36253 3.66435 2.13606 2.51472 2.51726 4.40449 4.02927 3.81749 1.61053 1.43991 2.80118 2.42373 2.59441 1.90662 1.54748 2.17914 1.82108 3.31398 1.68825 2.39004 3.70096 2.50909 2.87175 5.22076 1.87281 5.95811 3.38432 1.69432 3.80939 2.67357 2.08297 3.40464 2.38447 2.29574 2.66052 2.74969 1.71389 1.54696 3.10997 4.07231 2.07346 2.12945 2.51182 5.68351 1.65519 2.44696 2.1068 2.26817 3.6254 2.64498 3.30736 1.58414 2.7108 2.89596 2.16769 1.97095 2.54599 3.20743 2.42285 1.18238 1.65758 1.7855 2.37563 3.75773 2.1212 2.20574 2.95847 2.06966 1.99228 3.13556 2.1602 1.63554 2.76277 3.17543 2.54852 2.95401 1.52955 2.81045 2.5798 2.85352 3.42733 2.78302 2.59221 2.54781 1.56477 1.851 3.29141 1.53942 3.98022 2.08713 1.98258 2.05545 2.73956 1.25272 1.82953 2.37331 1.68221 2.33175 1.89579 2.55221 3.23548 3.93792 2.05948 1.67841 3.78999 2.62451 1.40542 2.13154 2.77663 2.86594 2.93093 2.95037 2.62312 2.33668 2.66983 2.4614 2.47488 2.43462 2.39778 2.09207 3.40949 2.59496 3.72436 2.29877 4.19121 4.3513 2.66269 1.70395 2.56519 2.26651 2.83295 2.33879 3.65268 2.40597 3.1674 2.81208 1.88072 4.11002 2.65196 1.68254 1.99748 2.66844 3.58443 2.77885 2.29693 1.88513 3.74002 1.28079 3.81997 2.28635 1.5629 2.60799 1.04954 2.21349 3.0892 2.12707 3.21594 4.17299 1.82394 2.45692 2.86309 3.6487 2.64639 1.77107 3.04741 3.11525 2.82396 2.79509 2.07211 2.3024 2.64142 2.64202 1.65302 4.04264 2.17917 3.40263 1.80959 2.04352 1.46238 1.77435 3.19108 2.50758 2.08641 2.82943 3.45145 2.25131 1.91337 3.11522 2.8822 3.22974 2.52711 3.27667 1.52728 4.12941 2.17519 1.59884 2.48495 1.66188 2.41727 2.02755 2.42595 3.99952 1.70814 1.93854 2.17041 1.77494 2.97732 3.24366 2.25936 1.93724 2.8899 3.75476 2.50675 2.3749 3.06802 1.79281 2.14486 2.71025 3.63494 2.29375 3.47412 3.25381 2.68565 2.19301 3.81342 2.54127 3.15907 3.76541 1.47773 2.42059 2.76096 1.55525 3.01717 2.47025 2.74801 2.21651 3.3722 3.94194 2.24684 1.99471 2.59039 3.59351 3.50366 2.74465 2.00768 2.73302 4.11586 2.39536 1.97572 2.81019 2.0002 2.42422 1.80237 2.28016 2.67364 1.79583 2.38464 2.55952 1.88462 2.43098 1.78119 1.93377 3.41605 3.11967 3.0893 1.72133 2.75324 2.74793 3.54258 1.17022 2.79441 2.567 2.26102 1.19311 2.35012 3.14028 2.86437 3.07942 2.98234 2.22498 3.32242 2.20485 3.32691 2.88504 3.07079 1.74953 3.32998 2.36402 2.16801 1.13042 3.27267 3.32294 2.47258 3.26988 2.57466 2.07164 2.84341 3.14075 3.98532 2.72059 2.95868 3.14403 2.63748 2.53692 3.0221 3.43586 3.43016 1.14746 1.44537 3.45258 2.63144 2.04693 4.66381 3.37707 4.40215 3.30272 2.56524 2.42537 2.66833 2.026 2.11086 1.78547 1.96189 3.52395 2.45554 2.277 2.39586 2.54787 1.90528 1.9246 1.38609 1.58303 2.13016 2.32947 2.23671 1.47155 2.50072 1.93779 3.29336 3.34209 2.88112 3.95819 2.84799 2.42116 2.10184 1.2585 3.40896 1.99567 2.34424 1.92402 2.29569 1.98235 2.84561 3.35838 2.54897 2.30331 4.79002 2.0306 2.49334 3.34502 2.04018 2.73854 2.63056 3.18748 2.11085 2.17463 2.60156 4.18654 3.07274 1.90937 4.26194 2.23444 2.78638 3.39183 2.2388 3.31737 3.25844 3.0454 2.17681 2.39825 2.27672 3.606 2.29519 2.93363 1.84756 1.96236 3.58818 2.19354 2.22512 1.88379 3.07313 3.07512 2.16668 4.16337 2.89916 4.74714 1.4492 2.59452 2.21058 2.78433 2.27977 2.30299 2.14789 2.74858 3.32195 1.92836 2.76867 2.54918 2.09584 2.99162 3.32776 2.59733 2.55171 3.75041 1.38376 2.21108 2.64797 2.47703 3.00442 5.36957 1.98505 5.28583 2.64369 1.08538 2.53744 2.90789 1.84928 2.62581 2.52224 2.69437 2.0204 2.32955 2.14436 2.2391 2.43928 2.18326 1.86887 2.0472 2.08836 2.02135 2.70261 2.2023 2.49533 1.97966 4.84689 3.86261 5.56399 2.13488 1.40488 2.07316 3.22856 1.80587 3.42359 3.78587 2.74602 3.46864 2.1103 2.10237 3.34871 2.26419 2.43884 3.15244 4.66136 1.85629 2.13559 4.21594 3.87067 3.91139 3.34374 8.64787 2.42972 1.86092 2.65068 2.27809 1.73006 3.62651 4.08368 3.10798 1.62659 2.06307 2.51357 2.84116 3.47264 2.95353 3.19363 1.22159 4.4096 2.78685 4.29796 1.05359 2.99654 2.6906 2.26835 3.66659 4.75473 1.45679 2.20081 2.33982 2.2797 2.48169 3.89117 5.4711 4.48018 2.54119 2.12268 3.40151 2.30043 1.16184 4.1012 1.39557 3.27004 1.24784 4.09959 3.10174 2.54119 2.24001 3.08866 2.27253 2.65614 3.06347 2.99031 2.05612 1.85 5.86329 3.2077 3.32138 3.54754 2.58629 1.89881 3.21804 1.3824 2.00758 2.82826 2.4208 3.11234 1.65551 2.08892 3.88739 3.47446 2.25473 2.05057 5.25864 4.30818 2.11173 3.52715 2.25576 2.89867 1.92711 1.64078 3.52075 2.22703 2.35581 3.23288 2.08544 1.70963 3.60524 3.59329 3.34709 3.64984 3.26054 3.50411 2.83236 2.5196 3.99878 2.80308 3.93342 1.65882 1.4184 2.03235 2.13122 2.62387 2.08984 1.61785 2.21624 3.30248 2.74218 2.67446 2.71227 2.42629 2.98362 3.36126 3.04579 1.74526 3.13763 2.32254 2.92917 3.08078 2.60633 2.61424 1.94082 3.38646 2.07895 2.40738 2.39781 3.90643 2.97495 2.67076 2.8925 2.75087 3.68536 2.95142 2.47909 3.24209 3.26417 2.79834 2.96859 3.67767 2.10882 2.32734 2.40381 1.76738 4.1358 3.04423 2.75958 3.18943 2.62177 4.01974 1.97414 2.08147 3.17892 3.92106 2.1617 2.67896 2.07019 2.50654 2.65347 2.19958 3.10965 3.20222 2.36794 3.33758 2.12703 4.74848 2.50432 3.59946 3.48911 4.14851 2.38559 2.38393 2.89482 2.71913 1.86106 2.18402 2.91777 3.3741 2.86497 2.16045 2.375 3.02321 2.99833 1.69907 2.40557 2.49403 2.52814 3.20298 2.7168 2.03616 1.54456 2.19264 2.50465 2.60505 4.35691 2.06492 3.30433 1.99544 2.32205 4.22252 1.8197 3.37391 2.22771 2.57712 2.68219 2.02884 4.41899 4.08573 3.06138 2.28849 1.546 2.0535 3.15416 1.54436 1.48728 2.72437 3.37872 4.23323 2.82348 1.95948 2.24601 2.72268 3.01728 2.14643 2.6288 2.67908 3.45747 2.17711 1.6977 3.19433 3.77357 2.45036 2.30872 2.45376 2.26297 2.24799 2.74933 2.6777 3.21849 4.86273 4.7049 2.28163 3.5782 3.33768 4.6926 3.08626 3.32171 3.5278 2.41152 6.09289 2.59751 1.84233 3.38237 2.29569 2.8589 1.9236 1.86118 2.77228 3.45227 3.43446 2.31908 2.48049 2.25778 2.11447 3.03807 1.96885 3.43975 2.55243 3.68806 2.91303 1.10571 1.80856 2.4104 1.82996 2.08169 2.26564 2.64557 2.38508 2.48214 2.5014 3.39243 2.86844 5.21652 1.3073 1.06749 2.38625 2.07639 2.54281 3.1094 3.0758 1.12979 3.72308 2.95467 4.13946 3.27693 1.44786 1.99008 2.62875 2.46015 2.12625 2.53662 2.93416 2.04939 1.38441 3.55634 5.76052 2.80404 2.35116 3.5329 1.53861 2.43787 3.62878 1.53738 2.61972 3.67991 3.54242 2.76643 2.79567 3.51169 1.95217 3.41134 2.58392 3.97748 3.25792 2.3498 3.12228 3.17991 1.80419 2.26943 1.93694 1.94204 3.27442 2.80854 3.00586 2.29776 4.85564 5.96503 3.45669 3.21155 1.68914 2.90106 2.71822 3.56097 0.955928 3.26031 3.23549 3.7432 2.7286 5.40871 2.80606 2.70303 2.41921 1.89917 3.74979 3.15409 2.73064 4.19461 1.49461 2.30631 2.43614 3.71012 3.17689 2.92056 3.69044 3.77545 2.76598 1.8954 1.9923 3.01507 3.13254 4.26558 2.01748 4.35529 3.76361 1.61598 2.33279 3.04101 3.14305 1.59187 2.16712 2.8284 2.01595 2.37353 2.38216 2.47881 2.07247 3.47156 1.54277 2.47305 3.53505 2.69173 1.709 2.37263 2.61387 3.46905 2.8493 2.14897 3.01883 2.34017 2.26916 3.02637 1.6648 1.9973 3.04589 2.93121 2.86772 1.77889 1.7816 2.45239 4.5273 2.19646 3.31435 2.58818 3.24267 2.55819 1.94582 3.45062 2.13878 2.82638 2.14156 2.60383 3.84288 2.82353 2.24505 2.22763 3.63428 3.26626 3.27077 4.44482 2.50119 2.91065 4.72782 2.40073 3.89433 3.26029 2.27076 2.04849 2.74059 2.44473 1.69084 3.57747 1.59054 3.99011 3.12808 1.91549 1.53477 2.16882 3.2975 2.29794 2.62879 2.63516 3.62264 2.38336 2.391 2.67933 3.05465 2.57618 3.04858 2.85953 1.25985 3.05599 1.6741 3.18997 3.63578 1.54146 1.63813 2.73983 6.28193 2.10279 2.64639 2.2443 3.84588 1.84304 1.25275 1.89972 1.52549 2.51653 3.14593 2.39878 2.95118 6.02882 2.93695 1.64887 3.49352 2.20998 1.36562 2.14293 2.71222 3.59268 1.69471 3.19551 2.09979 2.86206 3.37622 4.41575 2.91064 4.55019 1.99802 2.77647 2.85564 2.98324 2.9311 2.38404 1.91367 2.51259 4.64785 4.03933 2.44677 2.78278 2.70232 4.20023 1.91846 2.66122 3.2772 3.07067 2.86018 2.78742 3.51537 2.43292 3.26761 1.83827 2.56723 1.91103 1.59515 4.7353 2.35917 2.36436 2.04947 3.31928 2.63971 5.39754 2.00282 1.74653 3.33835 2.5179 2.40551 3.88069 4.22853 2.29024 3.2993 5.97731 3.51644 3.6248 3.85518 2.16746 2.03463 4.18177 3.95593 3.92802 2.17175 2.94656 2.70866 2.77096 ]
@@@ Frame-accuracy per-class: [ 72.1557 43.418 30.563 35.4796 28.4644 0.921659 29.4551 56.2447 44.5247 70.5012 77.819 10.4418 56.3429 51.7647 20.3509 33.9152 49.7162 7.07965 45.6693 45.9687 44.2582 56 36.2369 49.3523 29.4591 52.2772 39.6857 44.2649 53.7566 63.1009 61.4076 43.9942 46.4986 36.961 78.2483 70.0075 77.6868 78.535 36.7041 4.3956 28.9362 24.0166 13.2841 37.2093 62.49 62.54 34.7267 43.9376 69.1203 46.0391 81.7726 56.4268 61.4443 34.3949 86.0647 62.2165 73.6977 26.6958 9.48617 56.2427 63.4114 32.3497 51.221 28.9908 30.4569 43.5644 56.3143 64.9247 44.6886 47.3118 79.4628 39.7759 55.0326 31.2611 40.1799 27.6498 55.9453 74.7236 19.8675 70.2228 38.7952 50.2385 64.3882 38.3562 25.1673 61.8851 33.9726 15.2207 41.5543 43.6237 41.7657 18.7952 60.7481 43.8023 13.2231 36.6762 34.7339 42.8762 30.7692 36.2416 44.7607 54.2222 14.0556 56.7701 8.82801 36.8973 67.2593 40.868 19.0099 61.0837 57.2002 19.7719 17.3785 38.4401 39.821 54.5594 60.6152 37.9254 21.8371 56.3281 43.0161 67.9099 11.67 37.1134 26.362 66.1724 20.8153 48.284 30.445 62.0606 53.7726 42.6713 53.3333 46.298 42.547 39.4366 54.0408 14.9398 35.9799 42.5096 38.3639 43.1555 66.8425 32.9588 61.669 46.304 40.7524 29.5693 41.3547 36.0076 22.5641 58.5782 46.2178 39.4917 55.5066 37.2789 29.9742 38.6885 55.8587 49.6089 18.6879 42.9224 62.5868 20.8145 75.5116 24.581 45.1948 18.315 50.1733 17.8649 51.0092 65.6814 38.984 35.514 22.4215 54.2732 49.2632 44.3093 69.1544 35.7203 20.3822 40.1855 57.3932 33.9869 58.8601 21.1024 24 49.0967 42.6943 54.5287 14.6572 28.6645 75.4606 34.7578 53.9986 51.4851 50.1388 19.6721 46.549 39.4937 25.9587 37.0299 40.4858 52.663 46.9636 51.9208 26.7696 47.1795 61.089 23.2836 55.8786 63.836 15.956 35.3909 67.7751 49.3597 44.1113 53.6585 16.5872 51.0843 58.3748 1.71674 48.0153 24.2038 1.79372 37.9721 37.5624 59.6466 64.4377 41.4602 50.0978 20.3735 39.0805 66.2321 32.3185 57.0342 31.9202 36.886 58.1736 35.9393 83.7245 44.14 68.4651 57.5958 48.4404 29.0456 22.9249 46.8694 26.501 66.0194 45.3731 39.0244 43.659 54.2099 49.4721 47.5429 52.1637 14.4681 40.404 56.8449 20.1835 8.8748 65.9782 38.2878 43.8569 68.2689 20.3209 37.1353 5.53633 60.5375 36.3368 58.0557 58.7771 30.9278 40.451 47.3556 81.539 4.98221 65.5521 7.84314 56.0359 23.4086 55.3295 22.2793 33.0709 54.4 33.0275 58.4116 36.3316 31.068 61.067 57.9866 36.2538 32.0186 27.907 30.575 69.1997 29.0196 48.4053 51.8732 67.1164 31.0838 43.3697 51.5426 55.4788 54.8721 37.8251 52.3002 38.3363 32.1353 39.3801 34.1463 39.0144 56.2137 49.4208 65.6737 44.904 49.3204 34.9323 58.217 7.0922 15.2918 38.4216 61.3073 52.3216 27.8447 47.0309 24.2833 62.4291 46.1126 17.5439 26.1248 44.4444 77.3333 32.5318 48.6772 52.0394 44.3537 50.4245 44.7326 56.2905 24.855 32.2388 42.6508 31.6832 37.1501 21.1132 32.9966 42.1053 38.673 31.5412 72.0204 47.1081 53.9811 33.3553 41.2776 58.3111 37.1773 52.6518 41.1483 58.7065 13.9797 1.5748 62.3735 25.4432 34.5964 30.3725 21.6582 52.3955 27.154 43.6911 39.5112 19.1083 58.7957 44.16 35.6083 65.1852 44.0587 59.3258 22.2997 26.936 6.10687 30.972 43.3796 49.9394 41.5335 25.5144 32.6848 17.8926 55.5671 63.7858 23.1111 46.5753 9.85011 40.4301 44.1652 41.7745 38.6511 17.2573 25.3275 51.2821 32.9835 26.6244 40.1313 58.5865 49.6025 45.1485 29.7872 62.0134 64.2541 50.4505 24.6973 52.5799 9.35673 46.0497 57.9931 55.1553 71.9045 40.0513 56.066 47.1986 34.632 39.8382 49.7317 44.1426 25.2983 27.2912 28.5261 35.803 43.3679 52.9755 57.2498 34.6555 27.0916 30.8458 35.8047 50.4898 51.8695 58.9268 66.0512 59.7701 31.3725 51.9004 42.9433 34.3598 59.9049 38.2281 23.5589 65.5315 20.6687 21.2928 17.4905 23.3236 45.9418 23.9609 75.4708 47.3239 31.6731 31.7328 23.8004 64 27.7704 50.457 17.4497 39.2252 24.1309 72.5937 46.683 49.1499 4.78088 22.5287 17.0543 22.3048 65.2223 37.037 56.1559 25.3521 32.2981 42.682 43.4134 52.4851 61.6445 42.9783 53.1969 45.6609 10.7463 39.0773 58.7678 33.6196 39.0651 34.1137 66.3287 37.7528 38.7692 52.7905 19.59 19.5918 63.2665 43.3295 20.4255 30.6407 14.4772 40.904 20.595 40.7339 47.648 42.09 7.32984 27.3752 34.9425 25.4669 32.9626 47.4399 37.3887 60.6791 61.9189 33.218 35.8306 49.4208 25.8065 39.2968 32.6264 55.2021 24.4604 39.6899 10.9474 50.0333 60.6684 27.673 41.5842 36.3002 52.9718 37.9025 54.242 28.8401 53.7602 11.7107 42.9799 34.6883 44.6184 55.1551 40.7013 57.3311 29.0276 39.9404 24.2697 15.1697 30.7692 70.9295 52.6994 29.7787 42.0513 10.9091 23.4146 46.7186 49.3005 40.0466 31.5412 57.3913 30.1255 22.7929 50.4284 54.4822 18.9753 40.3495 51.2922 33.2362 30.1824 9.79592 35.8876 32.0786 38.2805 53.1092 50.4252 70.6182 46.1538 52.074 53.4031 23.4483 33.28 20.5499 37.5897 24.0918 37.1773 35.249 36.3636 35.4067 18.5053 11.1421 39.0892 32.1127 13.3891 39.2716 31.6424 40.5345 30.639 45.705 48.2682 35.2396 40.2955 54.3689 26.0062 26.7198 35.3674 19.5719 42.3453 35.6653 34.4751 28.8525 26.999 30.7898 68.046 51.3709 57.2663 25.2366 45.3691 33.4959 43.346 41.9916 57.732 54.1176 14.876 70.8389 56.7376 30.42 52.5984 34.1158 34.1598 20.1976 35.4362 58.2985 46.4309 30.4716 38.9497 45.4829 27.0997 40.8978 35.0901 46.1114 33.1288 48 19.1781 51.5852 46.8596 53.0246 43.4251 12.3711 10.0441 45.5267 41.9134 41.021 19.3548 39.2328 46.8824 55.7114 31.2347 46.5696 55.0775 30.4527 35.5828 53.2741 53.3887 37.018 28.7908 20.8494 27.6498 43.3887 63.7198 10.1333 49.5014 44.2577 38.2429 53.7074 68.1061 42.1557 49.5153 37.3626 45.9721 22.439 54.6565 57.0912 48.2066 26.7477 24.8848 55.2722 19.6078 12.9952 43.7247 24.3038 9.98336 13.0926 24.8062 59.6415 37.0757 35.8282 56.2874 53.0329 4.93151 30.2583 41.0738 42.3435 57.2087 30.1887 53.7158 72.5306 26.3063 24.9337 39.6961 63.4239 51.0501 26.963 43.6214 36.6115 15.1261 54.7835 46.2701 43.0416 48.5496 49.0082 36.5243 48.7515 44.1894 39.8074 56.8767 58.3699 50.116 30.3351 30.854 13.6709 15.4589 16.9014 39.6745 2.36686 34.7305 30.6849 57.4741 25.4118 61.7774 42.24 35.5872 39.4984 22.9035 41.3471 17.7546 32.2581 40.117 27.8339 23.1379 52.8263 53.6282 28.3871 48.9327 25.0549 64.4815 43.7396 37.5904 53.7743 28.5012 35.443 48.2953 28.7561 34.7625 39.136 21.0526 25.3224 14.5025 57.748 34.8925 42.1053 61.1892 23.1047 10.1695 25.6983 40.2581 42.6894 11.8738 51.6335 47.9233 50.5761 32.2344 39.3514 30.6943 25.784 17.8512 13.7339 36.5482 14.3322 47.2813 45.6887 39.0651 14.1593 16.188 44.1379 38.5382 44.7351 38.3838 56.0652 55.914 58.5897 36.5159 38.7435 13.5987 36.7246 43.5858 20.5451 14.8148 8.80196 43.7299 63.2588 24.5077 32.8982 25.9012 17.6904 64.3064 21.6028 8.96861 47.0978 62.4672 35.5777 50.9877 39.3208 19.8142 45.8685 46.538 59.4724 28.2974 40.3336 14.5455 35.7224 23.6015 35.7647 27.051 18.7755 25.729 37.6879 40.404 39.1248 29.5432 39.9587 36.3303 25.5977 46.2935 30.1766 56.8908 9.58722 54.7837 61.9538 32.2527 27.4627 20.712 41.8902 62.9457 36.6149 55.6447 65.4947 4.96614 28.3298 40.404 41.0842 29.4046 41.6433 35.057 26.3056 25.5911 64.7887 19.4825 11.7155 41.4545 43.0493 42.8997 24.1975 32.0856 44.7539 19.2593 29.5082 39.7906 57.4827 18.6916 65.3559 12.5604 58.3648 46.8305 28.5714 65.9803 48.8948 13.8958 60.3072 57.7936 38.2872 51.4877 43.352 46.8632 13.3333 42.2642 20.462 37.3002 58.3851 47.8796 27.7904 12.978 49.295 71.0338 25.0423 43.8479 34.3008 25.6131 30.7692 60.5187 36.1493 29.0221 54.3769 43.3684 34.0455 11.3433 19.1617 16.092 60.1546 60.9593 40.7339 45.4701 38.3973 50.1554 61.8585 55.3043 48.1337 23.4234 53.267 50.5718 20.1511 39.1785 37.9705 6.08828 51.9698 0 23.2168 61.3518 20.0803 42.6036 45.4936 21.3904 30.455 46.2676 36.4465 36.0176 58.7322 59.5852 27.1357 21.4651 51.5354 51.774 38.7917 5.71429 62.069 42.0857 48.8849 40.9562 19.9288 33.9152 26.7003 63.3983 38.8262 29.653 47.7658 51.1553 42.7586 22.521 38.2452 68.4942 57.9173 56.5308 50.5867 26.8657 41.6305 45.8809 31.5353 50.3704 51.7928 28.7744 41.983 53.443 37.44 22.8823 38.7382 20.4499 66.7566 34.8028 33.8722 37.2372 14.6646 30.2717 37.2716 35.1472 58.2441 52.3909 19.3995 64.3416 12.1655 49.4192 47.117 46.343 29.9674 74.3394 50.2776 34.2654 60.1399 42.4963 53.4169 37.4226 33.6391 14.4404 50.5785 61.2806 20.3866 26.9896 65.2906 49.0128 32.6975 30.922 24.9102 30.0626 38.6412 41.8204 35.1127 33.9818 39.5887 34.7667 38.8837 51.1848 11.2532 38.5925 20.7885 44.6533 11.0454 17.3134 33.9013 61.3139 42.1918 44.29 33.4913 38.2593 28.9855 34.2368 28.524 34.5059 47.2089 13.0982 33.7182 59.1268 49.8265 28.2024 20.6388 33.462 43.4783 52.5042 21.2014 73.4633 21.2471 42.0526 58.8454 29.7812 73.273 43.043 25.9928 46.3508 29.1815 13.7536 58.3219 30.6636 21.1454 14.0508 34.9259 51.8606 25.8824 29.6128 35.1421 32.8845 49.8104 38.5809 34.2857 30.8851 60.274 18.8586 40.8759 10.0662 48.012 48.6377 64.3279 45.7388 24.5059 32.1922 47.0135 28.9308 18.0432 45.3144 51.4523 28.7513 34.5679 33.3952 42.2721 30.26 60.5112 21.6898 44.1394 62.2725 37.0607 58.4917 39.2814 45.9864 40.1998 12.1393 53.9696 52.2514 47.4474 48.1272 32.7711 27.896 44.8306 51.5513 37.3626 11.3565 38.0672 34.2787 25.4364 51.4629 39.641 34.5784 28.2723 35.792 27.3794 28.6996 21.8534 39.2885 17.8042 41.2214 13.6937 14.6993 65.3992 40.1982 35.2668 56.0614 24.911 40.57 27.289 39.2271 22.3602 9.7561 40.3023 53.651 40.3696 27.9635 24.7557 31.0999 51.9696 34.5296 13.7705 37.5172 43.5349 25.0746 56.1404 40.7547 56.3124 36.5496 35.5368 53.6252 40.4284 35.0249 54.979 44.0468 60.025 54.1207 25.6927 26.2417 25.323 56.3565 33.3005 35.9086 23.8683 69.4186 26.6886 37.8329 45.6537 71.9866 38.8652 24.2932 29.1287 29.275 23.6794 53.7205 10.4065 49.6263 24.4295 31.0178 41.5771 54.0265 25.0627 39.5315 44.9683 74.9496 32.106 22.1294 35.7629 19.7309 37.7261 55.6041 33.109 31.8408 10.4496 34.1753 27.23 18.2278 31.3458 37.9747 22.9645 25.4669 19.2678 70.4796 66.1654 19.4234 28.5714 47.1732 12.1331 21.0379 15.5844 15.8498 32.5683 45.5868 40.201 41.6094 52.356 55.8626 52.2314 15.7823 35.4354 43.5511 35.8449 41.535 52.3507 55.199 61.5385 56.0286 57.5401 47.1595 42.0227 60.532 41.3675 48.7093 25.5484 25.2765 25.8398 5.98131 37.5176 40.0716 44.3857 65.5884 23.431 48.4417 44.4444 50.7711 48.5451 46.6165 29.115 21.5553 34.7399 41.701 3.663 42.4309 40.5063 22.7737 51.9846 28.6829 47.6895 23.0713 43.545 48.1979 35.3574 13.3333 45.0928 42.1677 11.6854 40.1451 28.2238 22.4924 51.9626 27.9793 20.5438 27.772 42.7105 42.4828 43.5775 16.8453 44.6743 37.075 58.8018 49.8254 34.0426 49.711 45.4183 56.0369 22.6475 26.2485 45.2521 13.7328 32.5581 3.4384 66.4076 32.3556 38.0952 35.3511 48.5784 42.8924 46.311 32.908 23.0563 47.4119 38.9052 36.99 51.6677 29.9213 24.1653 33.1492 35.3341 13.8272 67.5996 40.9662 36.3636 44.0237 25.6722 4.37756 50.5632 4.73934 33.9413 72.6154 36.6197 25.2772 51.4161 30.1426 41.2098 37.4846 45.6801 42.4069 47.2546 44.3562 35.1323 38.7449 53.7227 53.8512 48.0432 50.1279 40.4145 48.1416 45.7023 52.459 34.6667 18.6047 0.790514 46.6472 63.925 47.4438 31.5113 47.2599 26.9307 13.3581 31.0078 21.1833 49.8353 47.4975 21.3198 38.5633 35.5383 19.8175 6.14203 52.3116 49.2731 8.81057 22.8228 23.219 25.7206 0 49.1844 49.4494 40.796 43.9118 52.0849 15.8103 14.321 23.9808 60.3574 48.9104 38.2979 28.6814 17.2279 32.9114 22.1529 68.8913 10.9325 37.408 17.1558 73.6104 26.7769 36.0656 42.1705 13.3791 15.0427 64.4414 52.2696 36.1484 48.084 37.9038 15.0121 4.28135 31.3043 32.3568 48.0109 22.5053 44.2372 67.0989 14.4144 63.7177 29.3963 68.0778 14.7368 26.8344 32.0217 43.6871 27.052 43.0678 34.2629 29.7436 35.0476 39.5265 57.3816 6.77201 29.5858 31.3725 25.1539 39.698 53.2689 24.0896 64.4167 50.3726 33.3901 37.4412 20.8429 56.4865 49.5701 15.5285 19.5599 39.3839 42.9388 4.81928 15.7635 44.313 29.9625 37.0661 41.1924 52.6574 61.9951 8.09031 45.0844 42.5668 31.348 49.8915 61.9263 17.5695 23.6776 12.9555 20.178 18.6935 11.9332 35.6627 38.2641 16.4134 20.885 11.4519 53.5926 68.6491 43.9924 46.2064 33.3736 50.7295 55.4332 47.821 19.4131 35.7634 31.3576 27.0572 42.1893 21.8859 23.3732 23.6559 56.1895 22.1198 41.448 18.6608 23.9186 30.3894 32.9686 47.2806 20.227 47.6004 38.5093 34.955 8.3045 31.4351 36.1186 39.8754 36.2098 19.5016 28.8407 33.4694 30.8977 15.4818 25.5024 22.0167 16.6514 51.9945 40 41.7792 56.4905 12.1037 36.4912 35.6979 21.3763 31.3043 14.0309 58.8387 48.2678 28.9076 15.1436 47.0588 35.1515 46.8017 38.5142 40.8464 43.299 30.2477 30.83 39.087 20.1097 43.0067 7.21443 33.0876 18.8976 22.1643 9.87013 42.2535 43.1267 26.7135 29.7086 44.3789 38.7844 30.7036 24 29.6506 49.1803 34.5904 25.4743 28.7105 52.0667 39.9699 35.3114 42.2452 22.7898 41.0256 50.2172 60.2266 38.8648 42.0057 33.4347 10.1266 50.7087 28.7474 49.2627 40.358 14.3737 53.2357 31.2057 51.5464 34.904 35.1174 46.2836 17.1799 19.802 34.4615 41.5819 59.1051 54.1073 19.7219 65.7923 64.8719 30.8308 18.7834 12.0401 32.7054 50.4461 45.7961 31.0576 30.608 45.3502 38.3021 35.1551 22.4299 43.3298 55.1825 29.9213 15.7303 42.2207 44.0263 34.9762 41.95 43.6805 32.7759 33.9438 20.0762 5.51724 5.12821 47.3143 22.8047 28.2974 12.549 19.9861 19.8058 21.5463 44.6978 0 31.4428 46.9314 22.2222 47.2594 31.3625 55.2908 46.1017 33.2553 21.2346 24.8383 43.0956 42.978 47.3225 42.527 26.3666 51.8371 16.5062 45.3782 16.2047 27.2374 71.3253 45.3862 39.2799 55.6253 55.221 44.4132 37.6682 45.1994 43.1599 33.5946 20.1313 32.4226 3.27869 63.8309 59.623 44.7837 48.7395 33.2613 27.3349 31.5399 69.5106 18.5958 26.3648 22.3602 24.2038 63.2345 56.1044 34.6872 48.8746 37.5101 52.0138 33.3895 47.216 63.0517 21.2454 1.13314 32.5909 45.8465 13.1507 58.4335 40.871 19.1904 63.5223 42.2721 15.9292 17.5342 29.7483 33.7802 24.9201 47.3846 23.4875 27.8668 9.74212 25.1327 41.629 24.4121 18.7809 55.3089 43.3763 54.7453 54.1374 24.4248 34.6047 23.7248 43.6548 8.02676 5.40541 16.5333 29.2282 59.0795 34.4916 28.6065 25.0333 78.1069 21.9691 23.0678 15.9383 36.7505 8.51064 25.6217 38.4682 38.0044 51.3493 12.1864 24.9433 41.9162 12.7208 62.2754 44.0449 41.6 20.3857 23.1947 32.1678 23.2602 19.1126 33.1745 49.2308 39.132 27.7401 31.2782 10.9402 45.0193 10.4439 24.6809 62.7848 37.2532 22.4797 26.3014 57.5785 41.0127 27.8207 56.8138 42.623 39.466 37.7588 57.5068 18.8198 64.9652 36.9501 16.2719 33.5247 58.3015 34.2889 29.3697 24 32.0413 41.6732 22.0028 33.3736 39.2975 32.8922 56.8026 47.5814 33.2394 26.383 35.1097 52.3601 43.8765 43.8964 8.25397 40.4313 24.2091 38.1892 27.5862 40.8523 51.4071 12.9366 47.0418 28.5957 46.3395 30.1119 15.1589 25.26 43.9586 43.0704 15.3173 21.9727 25.2366 9.00716 40.6215 26.975 11.8609 40.53 13.7472 30.2251 38.3081 47.0451 41.5056 38.2865 59.9622 30.7692 56.8835 7.19794 22.9133 41.9603 58.0546 37.7358 24.1033 33.5638 37.3527 33.672 22.2649 46.4799 38.3562 32.2767 15.6912 40.6288 24.5161 25.6145 67.7465 31.5121 57.4868 24 19.6464 58.466 65.5027 39.7351 1.22699 45.9796 40.5467 33.9332 15.3191 56.7186 67.6438 57.4186 61.8384 29.4854 13.6646 41.3437 28.1081 1.16959 31.068 54.7584 17.1617 44.3203 59.2976 46.8457 32.6797 17.0811 55.9434 26.2687 50.8954 37.44 16.5383 17.1429 31.7343 7.30594 51.4236 35.5668 25.974 40.597 28.2642 39.2127 54.2479 38.2323 4.14938 11.7647 42.1907 38.829 35.2593 8.99654 55.1143 38.2658 22.3814 32.7928 29.2683 42.24 21.6006 39.5806 26.2976 55.3535 52.1547 54.8463 61.8182 6.64207 36.961 44.9025 53.9233 28.046 39.4662 5.40541 51.5532 56.1832 23.5514 47.8873 46.7955 15.7265 13.6519 44.1981 21.1513 5.36913 16.9576 19.4393 14.654 45.8547 57.2077 8.62355 13.8979 22.9299 48.8835 28.3361 36.2057 28.2268 ]

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:406) AvgLoss: 2.10682 (Xent), [AvgXent: 2.10682, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 47.8388% <<

