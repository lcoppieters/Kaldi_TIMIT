vgnd012
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter01_learnrate0.008_tr2.1068_cv1.9075 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02 
WARNING (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:228) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:408) Selecting from 1 GPUs
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:423) cudaSetDevice(0): Tesla K80	free:11372M, used:68M, total:11441M, free/total:0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:471) Device: 0, mem_ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuId():cu-device.cc:352) Trying to select device: 0
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:SelectGpuIdAuto():cu-device.cc:481) Success selecting device 0 free mem ratio: 0.993991
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:FinalizeActiveGpu():cu-device.cc:308) The active GPU is [0]: Tesla K80	free:11300M, used:140M, total:11441M, free/total:0.987698 version 3.7
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
ali-to-post ark:- ark:- 
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.49621, max 8.18284, mean 0.00945758, stddev 0.991793, skewness 0.143257, kurtosis 2.14069 ) 
[1] output of <AffineTransform> ( min -34.9505, max 21.2283, mean -3.3049, stddev 3.8611, skewness 0.142021, kurtosis 1.80115 ) 
[2] output of <Sigmoid> ( min 6.62477e-16, max 1, mean 0.194676, stddev 0.303728, skewness 1.60893, kurtosis 1.17953 ) 
[3] output of <AffineTransform> ( min -24.4689, max 15.3636, mean -3.45537, stddev 2.56348, skewness -0.0156915, kurtosis 2.45227 ) 
[4] output of <Sigmoid> ( min 2.36195e-11, max 1, mean 0.120161, stddev 0.209394, skewness 2.5409, kurtosis 6.04013 ) 
[5] output of <AffineTransform> ( min -13.7132, max 11.7776, mean -2.98278, stddev 2.01574, skewness 0.655081, kurtosis 2.4266 ) 
[6] output of <Sigmoid> ( min 1.10769e-06, max 0.999992, mean 0.12376, stddev 0.201359, skewness 2.60246, kurtosis 6.55405 ) 
[7] output of <AffineTransform> ( min -22.5922, max 16.8117, mean -2.1543, stddev 2.04726, skewness 0.383968, kurtosis 3.19355 ) 
[8] output of <Sigmoid> ( min 1.54285e-10, max 1, mean 0.192485, stddev 0.238774, skewness 1.80446, kurtosis 2.49033 ) 
[9] output of <AffineTransform> ( min -14.9594, max 16.8713, mean -2.19063, stddev 2.5564, skewness 0.917551, kurtosis 2.14128 ) 
[10] output of <Sigmoid> ( min 3.18563e-07, max 1, mean 0.213018, stddev 0.285515, skewness 1.55668, kurtosis 1.19136 ) 
[11] output of <AffineTransform> ( min -30.294, max 24.76, mean -3.61898, stddev 3.30878, skewness 0.736887, kurtosis 2.56699 ) 
[12] output of <Sigmoid> ( min 6.97418e-14, max 1, mean 0.145998, stddev 0.280677, skewness 2.10706, kurtosis 3.03279 ) 
[13] output of <AffineTransform> ( min -12.6141, max 19.6757, mean -0.0222089, stddev 3.03521, skewness 0.651402, kurtosis 1.13383 ) 
[14] output of <Softmax> ( min 2.37021e-13, max 0.996148, mean 0.00051857, stddev 0.0142823, skewness 46.4588, kurtosis 2473.76 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -2.40518, max 1.8389, mean -0.000613581, stddev 0.0525647, skewness -1.61671, kurtosis 107.225 ) 
[1] diff-output of <AffineTransform> ( min -0.57968, max 0.275157, mean 5.26798e-05, stddev 0.00882381, skewness -2.31276, kurtosis 205.378 ) 
[2] diff-output of <Sigmoid> ( min -2.78375, max 1.659, mean -0.000183068, stddev 0.0764567, skewness -0.287237, kurtosis 26.1269 ) 
[3] diff-output of <AffineTransform> ( min -0.424238, max 0.30917, mean 7.2737e-05, stddev 0.00987666, skewness -0.587701, kurtosis 79.8972 ) 
[4] diff-output of <Sigmoid> ( min -2.0553, max 1.56354, mean -0.000126037, stddev 0.0898076, skewness -0.0901666, kurtosis 13.9551 ) 
[5] diff-output of <AffineTransform> ( min -0.484437, max 0.294341, mean 0.000106865, stddev 0.0103717, skewness -0.494683, kurtosis 80.294 ) 
[6] diff-output of <Sigmoid> ( min -1.99383, max 1.34762, mean 0.000576838, stddev 0.0840993, skewness -0.190971, kurtosis 12.1939 ) 
[7] diff-output of <AffineTransform> ( min -0.262498, max 0.182021, mean 7.17673e-05, stddev 0.00900762, skewness -0.181441, kurtosis 31.188 ) 
[8] diff-output of <Sigmoid> ( min -1.15908, max 0.85347, mean 0.000225629, stddev 0.0621078, skewness -0.119522, kurtosis 9.55578 ) 
[9] diff-output of <AffineTransform> ( min -0.187467, max 0.145302, mean 4.69425e-05, stddev 0.00686396, skewness -0.404283, kurtosis 30.4836 ) 
[10] diff-output of <Sigmoid> ( min -0.93353, max 0.667882, mean 0.00018097, stddev 0.0502325, skewness -0.183604, kurtosis 8.50825 ) 
[11] diff-output of <AffineTransform> ( min -0.191298, max 0.206116, mean 5.92768e-05, stddev 0.00848831, skewness -0.0657253, kurtosis 32.793 ) 
[12] diff-output of <Sigmoid> ( min -0.900686, max 0.984453, mean 0.00101917, stddev 0.090825, skewness -0.0683596, kurtosis 3.42614 ) 
[13] diff-output of <AffineTransform> ( min -0.999997, max 0.987751, mean -1.08044e-08, stddev 0.0188648, skewness -28.0205, kurtosis 1905.32 ) 
[14] diff-output of <Softmax> ( min -0.999997, max 0.987751, mean -1.08044e-08, stddev 0.0188648, skewness -28.0205, kurtosis 1905.32 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.91352, max 2.19453, mean 0.000308579, stddev 0.136478, skewness 0.00772793, kurtosis 5.26911 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.765424, max 0.508165, mean 0.0134861, stddev 0.141342, skewness -0.170988, kurtosis 1.88447 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.628292, max 0.662052, mean 0.00301752, stddev 0.0560419, skewness 0.167133, kurtosis 5.94203 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.530205, max 0.78877, mean 0.0186207, stddev 0.15261, skewness 0.254052, kurtosis 1.56121 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.640831, max 0.525484, mean 0.00284217, stddev 0.0386792, skewness 0.352572, kurtosis 9.34946 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.587188, max 0.702134, mean 0.0273576, stddev 0.15179, skewness 0.347639, kurtosis 1.59256 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.406338, max 0.467457, mean 0.00200517, stddev 0.0326033, skewness 0.202938, kurtosis 6.96782 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.593065, max 0.695376, mean 0.0183724, stddev 0.133286, skewness 0.0743923, kurtosis 1.48379 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.401626, max 0.347233, mean 0.0020851, stddev 0.0322562, skewness 0.0900227, kurtosis 3.90781 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.35786, max 0.411481, mean 0.0120173, stddev 0.102037, skewness 0.171808, kurtosis 0.840104 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.468637, max 0.470301, mean 0.00305332, stddev 0.0483899, skewness 0.230671, kurtosis 3.70257 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.456548, max 0.509356, mean 0.0151748, stddev 0.135743, skewness 0.163611, kurtosis 1.03262 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.14209, max 1.83497, mean -1.57337e-08, stddev 0.0973393, skewness -4.87734, kurtosis 78.1557 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.85212, max 1.67684, mean 3.09153e-09, stddev 0.30543, skewness -2.04134, kurtosis 12.2525 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-pdf[5.5.734~1-794732a]:main():ali-to-pdf.cc:68) Converted 3696 alignments to pdf sequences.
LOG (ali-to-post[5.5.734~1-794732a]:main():ali-to-post.cc:73) Converted 3696 alignments.
LOG (copy-feats[5.5.734~1-794732a]:main():copy-feats.cc:143) Copied 3328 feature matrices.
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:384) ### After 1012992 frames,
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.21036, max 7.88956, mean 0.00637491, stddev 0.994874, skewness 0.113357, kurtosis 2.26778 ) 
[1] output of <AffineTransform> ( min -41.1768, max 27.5543, mean -3.4048, stddev 4.48518, skewness 0.129673, kurtosis 1.79069 ) 
[2] output of <Sigmoid> ( min 1.30961e-18, max 1, mean 0.214534, stddev 0.326665, skewness 1.435, kurtosis 0.52593 ) 
[3] output of <AffineTransform> ( min -29.3192, max 20.5034, mean -3.73857, stddev 2.92581, skewness -0.0590235, kurtosis 2.14261 ) 
[4] output of <Sigmoid> ( min 1.84857e-13, max 1, mean 0.122478, stddev 0.222394, skewness 2.462, kurtosis 5.40453 ) 
[5] output of <AffineTransform> ( min -14.4916, max 12.8386, mean -3.05001, stddev 2.1185, skewness 0.598974, kurtosis 2.25415 ) 
[6] output of <Sigmoid> ( min 5.086e-07, max 0.999997, mean 0.124975, stddev 0.206019, skewness 2.55372, kurtosis 6.20619 ) 
[7] output of <AffineTransform> ( min -22.7269, max 19.9753, mean -2.07051, stddev 2.11457, skewness 0.380468, kurtosis 3.11042 ) 
[8] output of <Sigmoid> ( min 1.34839e-10, max 1, mean 0.205012, stddev 0.247728, skewness 1.67784, kurtosis 1.96002 ) 
[9] output of <AffineTransform> ( min -15.7489, max 16.7965, mean -2.16202, stddev 2.71249, skewness 0.891555, kurtosis 1.99296 ) 
[10] output of <Sigmoid> ( min 1.44651e-07, max 1, mean 0.22324, stddev 0.296461, skewness 1.45873, kurtosis 0.823707 ) 
[11] output of <AffineTransform> ( min -30.295, max 24.9385, mean -3.98298, stddev 3.61103, skewness 0.639736, kurtosis 2.22336 ) 
[12] output of <Sigmoid> ( min 6.96718e-14, max 1, mean 0.140904, stddev 0.282965, skewness 2.14428, kurtosis 3.13994 ) 
[13] output of <AffineTransform> ( min -14.6274, max 22.9325, mean -0.0184779, stddev 3.40383, skewness 0.633554, kurtosis 1.0626 ) 
[14] output of <Softmax> ( min 5.71793e-15, max 0.999523, mean 0.000518599, stddev 0.0158084, skewness 46.5163, kurtosis 2419.83 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.91619, max 0.809049, mean 0.000518897, stddev 0.0503407, skewness -1.12098, kurtosis 46.9604 ) 
[1] diff-output of <AffineTransform> ( min -0.247672, max 0.338203, mean 6.96562e-05, stddev 0.00757859, skewness 0.350468, kurtosis 73.8784 ) 
[2] diff-output of <Sigmoid> ( min -1.00266, max 1.66144, mean 0.000538154, stddev 0.0688784, skewness 0.152639, kurtosis 13.2277 ) 
[3] diff-output of <AffineTransform> ( min -0.234207, max 0.30934, mean 7.14609e-05, stddev 0.0090281, skewness 0.260655, kurtosis 62.813 ) 
[4] diff-output of <Sigmoid> ( min -1.37249, max 1.55273, mean 0.000393394, stddev 0.086471, skewness -0.0176973, kurtosis 10.5798 ) 
[5] diff-output of <AffineTransform> ( min -0.289451, max 0.265706, mean 8.22507e-05, stddev 0.00986549, skewness -0.140089, kurtosis 49.7006 ) 
[6] diff-output of <Sigmoid> ( min -1.18862, max 1.44322, mean 0.000734538, stddev 0.0830678, skewness 0.0675086, kurtosis 9.88082 ) 
[7] diff-output of <AffineTransform> ( min -0.199487, max 0.215027, mean 4.91154e-05, stddev 0.00859465, skewness 0.048695, kurtosis 28.4295 ) 
[8] diff-output of <Sigmoid> ( min -0.867792, max 0.885872, mean 0.000285746, stddev 0.0593426, skewness -0.0339756, kurtosis 9.14192 ) 
[9] diff-output of <AffineTransform> ( min -0.118488, max 0.105127, mean 3.68602e-05, stddev 0.00640001, skewness -0.0299038, kurtosis 25.9611 ) 
[10] diff-output of <Sigmoid> ( min -0.618656, max 0.538595, mean 9.99863e-05, stddev 0.0477503, skewness -0.133849, kurtosis 8.55496 ) 
[11] diff-output of <AffineTransform> ( min -0.207303, max 0.16375, mean 6.78616e-06, stddev 0.00766612, skewness 0.0963502, kurtosis 44.0036 ) 
[12] diff-output of <Sigmoid> ( min -1.52873, max 1.29455, mean 0.000713313, stddev 0.0838347, skewness -0.0734126, kurtosis 5.97082 ) 
[13] diff-output of <AffineTransform> ( min -0.999998, max 0.971412, mean -9.34414e-09, stddev 0.0163226, skewness -27.8705, kurtosis 2262.88 ) 
[14] diff-output of <Softmax> ( min -0.999998, max 0.971412, mean -9.34414e-09, stddev 0.0163226, skewness -27.8705, kurtosis 2262.88 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.63325, max 1.59474, mean 5.1955e-05, stddev 0.119727, skewness 0.0395048, kurtosis 2.45117 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.455038, max 0.507719, mean 0.017832, stddev 0.120706, skewness -0.141683, kurtosis 0.796133 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.632561, max 0.739222, mean 0.00411266, stddev 0.0570821, skewness 0.110314, kurtosis 5.02334 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.639877, max 0.720936, mean 0.018294, stddev 0.146448, skewness 0.074231, kurtosis 1.92434 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.505051, max 0.474439, mean 0.00264465, stddev 0.0393912, skewness 0.134986, kurtosis 7.40204 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.794804, max 0.751839, mean 0.0210562, stddev 0.149342, skewness 0.179713, kurtosis 1.93384 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.585343, max 0.438909, mean 0.00161912, stddev 0.0322396, skewness 0.100581, kurtosis 6.91889 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.670188, max 0.532151, mean 0.0125736, stddev 0.126902, skewness -0.0176478, kurtosis 1.32422 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.365964, max 0.312917, mean 0.00198697, stddev 0.0323117, skewness 0.171599, kurtosis 2.93536 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.318222, max 0.409876, mean 0.00943618, stddev 0.0969696, skewness 0.219128, kurtosis 0.531954 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.375397, max 0.468605, mean 0.000443697, stddev 0.0459635, skewness 0.068459, kurtosis 3.48534 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.438153, max 0.527442, mean 0.00173725, stddev 0.122639, skewness 0.0538111, kurtosis 1.15455 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.72945, max 1.43862, mean -1.84212e-08, stddev 0.084917, skewness -4.7823, kurtosis 73.1153 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.72474, max 1.38813, mean 1.73126e-09, stddev 0.266516, skewness -1.87379, kurtosis 9.23921 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:395) Done 3328 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.764705 min, processing 22078 frames per sec; i/o time 2.48795%]
LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 37614 216 186 380 133 108 339 588 415 2364 944 124 1446 467 142 200 440 282 444 415 596 437 143 810 434 252 254 309 472 738 646 1036 178 243 1381 668 1893 1078 400 136 117 241 135 365 622 468 155 416 3097 14611 2493 618 408 235 51771 1168 777 228 126 428 747 457 798 272 98 454 1896 1626 409 418 2680 178 690 281 333 325 584 1311 226 2446 3054 314 731 182 373 1087 182 328 630 717 294 207 1002 657 60 523 535 375 435 372 386 562 341 1111 328 238 337 276 252 710 996 131 339 179 670 652 666 308 288 1560 404 643 248 145 284 539 576 422 213 1237 470 576 382 533 345 319 612 207 497 390 354 215 758 133 353 358 478 429 280 791 97 527 601 1967 340 367 193 152 311 447 251 328 792 331 757 89 192 136 721 229 272 304 905 374 111 801 237 575 1661 593 78 323 456 229 482 317 137 470 482 1087 211 153 678 175 731 353 540 91 311 197 169 518 123 1173 370 429 388 487 376 167 395 341 363 364 1022 429 233 430 524 207 301 116 1045 235 111 966 500 707 493 383 255 294 217 383 213 394 200 539 443 428 660 328 537 378 272 361 126 279 241 669 167 389 240 433 331 437 427 117 148 383 272 315 871 420 321 1435 93 188 144 353 338 735 760 339 709 614 1416 140 1136 127 890 243 614 583 190 437 272 585 283 566 440 372 165 215 193 356 618 382 266 520 889 244 320 275 506 723 211 206 276 236 548 512 243 430 388 738 338 772 406 465 70 248 481 665 441 373 210 296 440 186 142 344 499 1312 353 472 355 367 1354 308 385 603 167 588 252 196 260 148 237 527 418 784 596 370 758 203 562 290 782 104 502 443 63 543 479 303 174 295 490 191 265 245 235 423 312 168 742 374 222 143 148 65 303 396 412 156 121 128 251 480 821 112 255 233 232 278 270 385 324 114 1345 333 315 1218 1563 314 252 399 372 1243 277 206 610 85 221 722 402 1005 389 424 294 115 494 279 294 209 245 315 1167 433 428 534 239 125 502 276 663 628 512 2599 304 229 381 414 308 946 609 199 1086 164 131 131 171 326 204 2044 177 391 239 260 812 374 820 74 206 244 680 203 323 125 217 193 134 438 364 564 106 241 693 603 251 1088 530 586 374 167 368 316 407 299 448 690 222 487 761 219 122 872 438 117 179 186 442 218 272 329 344 95 310 217 294 494 478 168 456 505 144 153 647 108 483 306 581 69 322 237 751 1361 238 151 286 479 543 359 159 671 435 174 184 766 596 798 303 344 335 222 250 71 844 620 248 292 82 102 449 750 429 418 287 119 311 408 574 263 1945 754 171 301 122 1833 305 488 297 999 784 409 783 668 72 312 345 348 261 290 391 346 522 140 179 263 177 119 631 995 224 649 308 447 323 744 257 161 501 401 163 153 364 452 152 481 373 652 346 925 158 372 307 394 833 339 127 302 375 211 440 317 319 181 455 372 358 777 413 685 160 446 200 749 906 81 462 109 930 915 669 163 242 567 944 219 548 46 573 633 748 611 240 290 121 407 450 361 194 260 129 108 873 599 187 551 178 193 748 810 417 670 136 465 102 327 553 348 164 108 725 535 315 370 197 300 221 322 920 191 407 584 288 182 406 372 375 1085 185 383 693 277 188 526 791 309 337 364 513 297 496 529 348 327 428 339 420 348 311 912 570 215 283 181 197 310 106 491 84 250 182 819 212 579 312 140 478 554 534 191 139 1196 445 315 486 723 232 304 227 930 299 207 695 203 276 1422 309 431 393 294 426 296 448 395 180 462 138 206 89 387 468 269 627 469 824 136 462 410 143 302 116 492 153 211 446 299 169 191 1232 150 764 247 490 325 1056 298 286 301 201 323 238 121 204 155 782 228 191 374 203 1553 143 111 301 571 601 1341 559 161 296 440 208 208 659 27 439 652 212 225 122 291 432 247 388 514 968 272 355 330 311 453 375 381 1796 601 167 154 391 1612 289 934 995 221 236 544 350 411 535 570 258 359 1029 328 119 412 334 503 202 93 538 337 152 286 504 160 737 103 397 386 402 1068 746 201 618 702 198 386 447 661 97 662 757 281 563 365 219 431 957 488 295 223 189 183 149 867 254 158 485 237 725 167 83 130 711 823 272 292 299 482 360 287 897 166 803 393 198 316 305 328 596 35 357 288 124 253 349 93 538 676 219 341 386 988 298 293 374 380 314 122 507 268 560 627 140 200 198 897 221 158 324 930 217 297 444 1331 350 723 383 301 576 394 120 337 627 281 645 486 312 454 903 244 1111 215 649 166 320 386 410 560 700 240 216 702 205 473 303 813 153 851 630 983 929 336 797 403 163 138 302 1163 284 144 920 430 183 352 417 239 235 406 421 385 194 546 537 527 195 440 139 425 253 167 557 616 182 503 316 551 172 350 301 298 313 198 216 1202 720 464 203 388 218 1487 141 1000 216 399 805 708 1049 499 138 390 140 174 363 218 340 334 303 846 382 219 193 705 395 225 507 265 1131 201 1164 377 666 495 1268 1167 379 832 259 397 393 421 361 476 364 269 378 211 958 396 473 1016 469 868 417 367 400 502 1215 1010 499 974 207 211 575 209 136 158 848 405 200 666 668 468 95 413 383 111 361 646 168 196 277 224 1446 706 215 977 140 596 278 517 241 184 595 965 703 164 153 395 723 515 152 362 537 167 769 397 550 1124 1066 365 373 502 356 726 1199 770 198 674 580 381 507 459 121 1126 303 544 707 1190 352 477 384 365 274 275 307 334 372 309 139 490 199 341 551 1239 339 239 514 111 193 343 371 301 411 336 319 197 293 513 239 294 259 1678 731 329 486 1388 255 356 115 479 457 515 298 509 477 669 907 367 166 298 1121 221 393 389 1189 1538 467 642 573 695 292 445 387 316 193 267 354 838 378 1236 358 561 535 421 704 465 604 366 509 364 136 452 276 342 390 512 270 680 716 707 650 202 188 590 222 413 205 164 267 96 496 482 243 362 525 326 483 779 542 429 117 778 627 542 313 430 426 400 236 174 900 562 430 206 615 608 440 744 186 666 511 551 824 190 314 452 441 202 1643 517 555 422 576 365 399 105 630 1462 177 225 688 245 264 405 584 174 300 881 472 366 1215 759 370 195 289 282 238 701 37 150 126 514 960 733 155 994 252 269 322 684 455 509 295 264 385 383 260 789 653 113 166 189 225 20 398 499 301 521 683 126 202 208 755 619 446 519 638 118 320 1393 155 339 221 998 302 152 322 291 292 1078 363 633 952 696 206 163 57 1143 1470 235 750 925 55 949 190 1157 142 238 368 645 432 508 627 292 262 1520 538 221 253 280 568 463 2791 178 681 335 293 531 652 2285 1337 534 204 454 1136 124 101 760 133 763 184 611 606 531 503 467 159 691 773 341 595 123 168 497 209 207 1071 164 282 244 591 588 786 731 413 445 1679 424 221 363 261 358 438 429 376 232 464 108 552 455 196 526 685 689 484 510 402 277 144 219 556 160 295 461 530 367 239 316 721 540 546 363 272 629 766 173 427 218 341 402 420 387 851 297 191 263 412 1258 511 543 630 383 632 350 273 525 249 610 317 383 192 532 927 284 703 1187 345 234 237 529 640 1153 184 205 689 665 682 338 254 448 575 838 1039 528 493 197 317 243 915 614 243 409 211 727 286 532 948 308 151 162 442 480 456 395 1410 1151 499 468 149 663 616 838 373 238 1263 506 1015 160 468 2725 190 667 729 531 314 779 494 448 409 393 217 97 437 381 208 127 720 257 394 438 52 502 969 121 410 194 524 737 213 202 386 329 295 401 324 155 503 363 297 234 642 2282 731 305 1195 780 711 334 338 259 446 228 274 152 1986 3421 196 654 231 219 269 1113 263 375 80 235 893 536 455 155 1863 434 296 224 396 136 176 426 475 182 1538 895 333 996 378 395 182 218 186 156 487 140 1216 174 282 773 446 303 833 426 500 356 282 537 421 492 149 55 187 304 597 388 814 375 1468 614 420 194 258 117 663 574 681 648 139 220 250 424 918 667 312 181 228 357 524 439 524 552 1428 515 332 292 908 191 117 987 582 431 182 557 1382 323 260 1189 861 1231 549 313 646 511 485 435 653 889 769 262 193 633 354 413 455 264 1091 506 177 117 159 2171 2543 405 157 556 363 861 652 680 799 386 346 587 621 491 204 336 434 703 228 623 158 488 450 259 244 641 225 155 626 854 491 373 1849 136 991 194 305 1887 971 715 348 795 551 344 260 660 839 173 401 413 387 386 2469 393 1038 212 254 1036 830 226 244 441 219 583 352 673 3172 414 538 359 402 967 462 85 360 1024 151 268 1352 800 382 462 1131 167 530 312 973 157 135 109 579 1380 577 167 325 660 641 486 120 263 246 324 337 144 415 530 558 277 512 312 643 381 144 742 452 634 1127 406 730 897 847 217 524 129 756 982 267 319 491 292 146 676 373 74 200 267 368 488 440 301 460 235 828 303 748 414 ]
@@@ Loss per-class: [ 0.637293 1.24315 1.40512 1.41095 1.5949 2.89347 1.98958 0.854901 1.47083 0.805695 0.497073 2.47741 1.04548 1.21368 1.93902 1.95128 1.38496 3.45494 1.4981 1.13817 1.21854 1.01083 1.16408 1.37523 1.71312 0.989486 1.29926 1.12794 1.21463 0.810254 0.772074 1.39282 1.05854 1.43682 0.578991 0.594087 0.596516 0.425998 1.53386 3.07485 2.13192 1.6527 2.54636 1.23992 1.00819 0.676887 1.53374 1.50563 0.896247 1.1584 0.411747 1.0113 0.885541 1.52021 0.405285 1.06489 0.598804 1.53935 2.48994 0.834824 0.945943 1.79563 1.44175 1.69673 1.75102 1.31892 1.15425 1.043 1.26764 1.32551 0.581938 1.33367 0.819165 1.53336 1.35727 1.54308 1.13115 0.66005 2.14496 0.841431 1.22793 1.02105 0.994375 1.433 1.94283 0.920155 1.34957 2.24722 1.55943 1.17465 1.44833 2.14766 0.964079 1.47869 2.1035 1.72979 1.65387 1.23347 1.85503 1.45044 1.36172 1.25298 2.41019 1.04759 2.5991 1.51384 0.802897 1.06323 2.04842 1.19986 1.3432 1.37089 1.69392 1.58611 1.775 1.21836 0.956572 1.26603 2.18182 1.05 1.24741 0.763485 2.47418 1.55039 2.18217 0.880679 2.07774 1.43046 1.56148 1.04385 1.03759 1.34391 1.07601 1.41408 1.39472 1.44711 1.1742 2.09475 1.72688 1.58526 1.38662 1.40858 0.74453 1.09477 0.815233 1.31927 1.45785 2.04802 1.94618 1.683 1.92113 0.898333 1.15456 1.50705 0.920987 1.61205 1.923 1.16738 1.13755 1.11127 2.30015 1.43454 0.859869 2.05486 0.678996 1.68603 0.972286 2.01412 1.36983 2.03771 0.993281 0.577792 1.81778 1.5559 1.98188 1.0551 0.995949 1.31317 0.859882 1.85572 1.62568 1.30843 1.02973 1.82085 0.790613 2.1972 1.74877 1.193 1.81256 1.2805 2.30091 1.56472 0.662605 1.17426 1.2584 1.04721 1.34939 1.73919 1.18188 1.50589 1.7413 1.55601 1.41074 1.12965 1.39919 1.12826 1.59794 1.39736 1.00334 1.8129 0.921086 0.861677 2.55901 1.93254 0.895234 1.3044 1.26404 1.10917 2.08674 0.802925 1.00807 3.19056 1.35468 2.33073 3.09328 1.91752 1.94282 1.01725 0.951057 1.54671 1.09776 2.20566 1.45765 0.639908 1.55652 1.12861 1.61579 1.7093 0.987246 1.66308 0.451502 1.47476 0.80382 0.927704 1.20521 1.87586 1.70933 1.35775 2.23054 0.727153 0.922182 1.47115 1.11097 1.0559 0.877485 1.59489 0.993547 2.3618 1.13191 0.943029 2.20384 2.72551 0.849794 1.59921 1.2313 0.847225 1.6672 1.28731 2.82636 0.950052 1.7259 1.01604 0.963601 1.88716 1.78565 1.13949 0.525774 3.01871 0.584438 2.424 1.08371 1.74759 0.885423 2.30758 1.55178 1.24164 1.37688 0.836406 1.17033 2.17025 0.941138 0.955992 1.1609 1.46187 1.49575 1.63327 0.732045 1.7848 1.15775 1.0726 0.677994 1.49407 1.74122 1.14944 1.01371 0.903082 1.47286 0.788795 1.20542 1.65822 1.30345 2.11353 1.50492 1.00949 1.32302 0.782286 1.19652 1.30063 1.48797 0.931757 2.85351 2.66696 1.5434 1.07787 1.01517 2.39547 1.35687 1.71051 0.938947 0.904325 1.87267 2.17966 1.50095 0.562719 1.98266 1.28817 1.33609 1.47506 1.49843 1.18848 0.928138 1.80608 1.81241 1.76694 1.69282 1.41452 1.91955 1.60151 1.50267 1.61268 1.9763 0.712557 1.52171 1.09679 1.8443 1.45627 0.980527 1.50105 1.38246 1.11634 1.20792 2.81255 2.38618 0.794683 1.6396 1.57528 1.47183 2.33024 0.848812 1.6594 1.50612 1.46769 2.27494 0.892164 1.31183 1.53906 0.893581 1.46622 0.891369 1.60883 1.75466 2.8632 1.53217 1.30753 1.52638 1.25034 2.03407 1.29713 2.57826 1.03553 1.04357 1.43335 1.15581 2.73508 1.40599 1.22516 1.39053 1.55147 2.35651 1.87832 1.08608 1.56228 1.69521 1.82901 1.12506 1.10837 1.24656 1.9116 0.656684 1.09721 1.01211 1.70644 1.10054 2.40122 1.17565 1.22742 1.07124 0.579595 1.17968 1.1037 1.14266 1.4044 1.86861 0.95186 1.25573 1.66912 1.98353 2.01153 1.94694 1.41461 0.995234 0.991853 1.96267 1.69599 1.307 1.80183 1.13478 1.13908 0.872369 0.980293 0.799076 1.49442 1.11561 1.44344 1.72742 1.26681 1.47806 2.08205 0.857564 1.98072 2.3399 2.33086 2.0483 1.37966 1.64529 0.71341 1.20707 1.55489 1.53313 1.92818 0.832937 1.73168 1.30238 2.02625 1.4332 1.64459 0.637614 1.49084 1.17636 3.4073 2.18459 2.16082 2.38713 0.790337 1.86851 1.14073 1.58654 1.77204 1.34237 1.60903 0.945255 1.02682 1.33707 1.24588 1.41995 2.51728 1.62338 0.89637 1.49341 1.24034 1.70642 0.842772 1.39623 1.60202 1.47048 1.82614 1.9186 0.998766 1.33764 1.87587 1.72021 2.70844 1.63688 1.77516 1.27482 1.085 1.66173 2.75272 1.93545 1.48783 2.34418 1.84098 1.34772 1.55775 0.899531 0.839751 1.17869 1.20024 1.27871 2.00979 1.62056 1.51965 1.22303 1.49812 1.48186 3.04071 1.39109 1.09189 1.80368 1.31013 1.45924 1.15994 1.90323 1.06342 2.00297 1.30412 3.24877 1.35237 1.3853 1.72598 0.965852 1.51932 1.19029 1.76962 1.22569 2.12667 2.22665 1.62526 0.621445 1.41705 1.804 1.22076 2.71118 1.93955 1.11123 1.41143 1.57262 1.72817 1.01667 1.80327 2.09935 1.0079 0.97893 2.34893 1.55173 1.32808 1.77689 1.84415 2.26881 1.66394 1.76552 1.78269 1.22841 1.25652 0.759449 1.75862 1.17764 1.32013 2.04948 1.65712 2.01889 1.63872 2.5971 1.83731 1.57082 1.37671 1.60444 2.30451 2.84235 1.19086 1.58902 2.22215 1.57878 1.92799 1.3872 1.70001 1.1834 1.54986 1.4139 1.61831 0.856573 1.72823 1.7439 1.91274 2.2857 1.15941 1.64408 1.47182 1.53336 1.96885 1.57399 0.73099 1.06775 1.10641 1.74498 1.5523 1.60531 1.43283 1.61213 0.955182 1.06563 2.50734 0.720106 0.957928 2.0647 1.15035 1.56533 1.24816 2.56322 1.73251 0.81744 1.38192 2.05304 1.91516 1.16305 1.88605 1.12661 1.74388 1.26003 1.55581 1.35927 1.54871 1.23769 1.4117 1.15153 1.03867 2.52812 2.44974 1.28935 1.19007 1.49014 1.9936 1.44073 1.2079 1.07943 2.01579 1.26668 0.959983 1.28059 1.64259 1.27314 1.00272 1.64665 1.62286 2.43392 1.88431 1.59599 0.806158 2.78491 1.45169 1.29753 1.57725 1.26993 0.995044 1.76322 1.38649 1.39938 1.48528 2.13117 1.09906 1.09275 1.26549 1.76259 2.45564 1.01132 2.61516 2.64281 1.30872 1.57082 3.11594 2.73434 2.16704 1.14248 1.512 1.75713 1.06717 1.1849 3.06583 2.01254 1.56166 1.46849 1.17552 1.50477 1.2225 0.582521 1.89621 1.59624 1.68305 0.822366 1.17546 1.87194 1.30964 1.45178 2.49028 1.36091 1.36215 1.58791 1.00919 1.19235 1.8224 1.02768 1.39661 1.42035 1.12338 0.966495 1.31259 2.26218 1.47935 3.0512 3.02396 2.26806 1.67693 5.58572 1.66261 1.99937 1.47355 1.59247 0.893271 1.2911 1.73117 1.80002 2.31067 1.61947 2.04344 1.44069 1.69722 2.16973 2.39862 0.938211 1.23822 1.92027 0.942715 1.75823 0.963386 1.48976 1.50449 1.11069 1.61251 1.67194 1.3355 1.87657 1.78554 1.45079 2.255 2.29838 2.86086 1.20441 1.88781 1.35334 1.03661 2.17998 2.46036 1.96383 1.50964 1.40248 2.53101 1.25124 1.54841 1.47028 1.34012 1.39444 2.21034 1.85492 2.13319 2.02872 1.60149 2.5287 0.992376 1.44973 1.57764 2.30238 2.36558 1.6471 1.54334 1.34497 1.74124 1.22443 1.00423 1.33879 1.76273 1.57332 3.13802 1.61587 1.41306 2.05911 2.31679 3.84408 0.91805 1.18502 1.93106 1.42051 1.99934 1.74459 1.00896 1.89775 2.53438 1.05764 0.862305 1.71609 1.42729 1.7035 2.23394 1.0417 1.41847 0.962498 1.30742 1.56717 2.73428 1.84898 2.40921 1.04159 1.69047 2.47296 1.59846 1.71544 1.69986 1.80713 1.8938 1.74086 1.42607 1.61404 1.25806 1.77835 0.877456 2.98632 1.02857 1.14487 1.76897 1.81377 2.36646 1.50278 1.13816 1.7615 1.42014 1.14071 4.00405 1.79154 1.34923 1.35299 2.16973 1.5556 1.9088 1.83138 2.3647 1.05607 2.4611 2.25888 1.55926 1.28247 1.528 1.73094 2.15291 1.50776 2.11378 1.78921 1.39792 1.02831 1.4312 0.999336 2.13983 1.1561 1.31379 1.69649 0.770269 1.33688 2.87989 1.13209 1.28012 1.2674 1.24414 1.55835 1.3234 2.40475 1.75328 2.11417 1.5445 1.03915 1.14584 2.18321 2.6035 1.39028 0.767138 1.89118 1.45813 1.59079 1.58698 1.41634 1.08761 1.43703 2.06495 1.33266 1.31512 1.77207 2.93564 1.86861 2.11878 1.09924 0.903053 1.46257 1.46885 1.56848 1.12466 0.89726 1.08944 1.368 1.99502 1.05668 1.59055 2.44173 1.44764 1.65334 4.15927 1.26776 2.49465 2.43392 0.755321 2.10176 1.22125 1.3061 1.58458 1.63942 1.5511 1.53401 1.7167 0.857996 1.01679 1.83651 2.97631 1.26936 1.32571 1.43965 4.19566 1.14931 1.3778 1.1982 1.62699 2.1772 1.59352 2.00985 1.04499 1.5122 1.68877 1.02781 1.38121 1.54391 2.11768 1.42816 0.736523 0.973063 1.26864 1.6049 2.30988 1.46464 1.10364 1.49102 1.09927 1.1219 1.96729 1.54392 0.844369 1.75532 2.43626 1.90318 1.98063 1.02028 1.54498 1.99128 1.50914 2.46319 1.89698 1.65433 1.93567 1.08729 1.05261 2.04837 0.889333 3.18777 1.40579 1.15922 1.4517 1.51433 0.740875 1.29026 1.87296 1.1895 1.49285 1.3299 1.47319 1.39663 2.40524 1.06952 1.11914 2.45542 1.1573 0.815564 1.26356 1.31196 1.84398 2.08117 1.79742 1.3727 1.28867 1.81054 1.61439 1.50166 1.80068 1.65771 1.4219 1.90962 1.48028 1.91105 1.63865 2.70038 2.64186 1.99822 1.03277 1.19185 1.6583 1.71867 1.81436 2.45434 1.56338 1.99092 1.95719 1.00892 2.70655 1.6126 1.22505 1.4294 1.77956 1.98914 1.85876 1.29526 1.36706 1.97069 0.76535 2.53236 1.5397 1.07376 1.87355 0.630405 1.60477 1.57032 1.07103 1.52401 2.71998 1.16497 1.43517 2.07815 2.74955 1.46305 1.26964 2.14704 2.09081 1.48106 1.9775 1.14637 1.35121 1.9491 1.44016 1.1784 2.7648 1.50349 2.49884 1.13048 1.19429 0.878525 1.3378 2.18995 1.63863 1.34913 1.77257 2.48752 1.29748 1.15053 2.08928 1.94813 2.15898 1.8094 1.86664 1.00586 3.20494 1.42184 1.06235 1.63653 1.19595 1.36846 1.28019 1.57998 3.10418 1.1812 1.43322 1.33196 1.37232 1.68246 1.87607 1.46597 0.99584 1.35975 2.14157 1.73539 1.35723 1.94122 1.28156 1.41411 1.73372 1.78888 1.42049 1.9783 1.29295 1.62973 1.64153 2.8326 1.12875 2.25254 2.22824 0.9765 1.64562 1.38102 1.03728 1.37616 1.89996 1.64973 1.56404 2.22373 2.76694 1.61636 1.46492 1.86287 2.2401 2.52772 1.87585 1.41144 1.99453 2.74126 1.59627 1.27534 1.56971 1.31435 1.56473 1.22067 1.77086 2.00732 1.06879 1.32376 1.79575 1.02323 1.71687 1.27762 1.42253 2.29979 2.30485 2.29121 0.895805 1.74728 1.759 1.83319 0.620235 1.51669 1.80762 1.59711 0.838653 1.40671 2.22809 1.97584 1.88371 1.79286 1.06707 2.35852 1.17177 2.07386 1.72637 1.50542 1.07482 1.91795 1.44024 1.55674 0.722002 1.84784 1.95955 1.56346 1.72899 1.34609 1.32972 1.91427 2.03137 2.97691 1.66509 1.92043 2.09438 1.71041 1.76158 1.89203 2.4019 2.29193 0.743905 0.76234 2.19837 1.87734 1.5849 3.42061 2.31776 2.62784 2.49966 1.83804 1.57816 1.69458 1.22979 1.38756 1.13114 1.37059 2.411 1.28354 1.44799 1.90572 1.28688 0.988622 1.08194 0.981205 1.14366 1.32049 1.61493 1.50193 0.925544 1.43923 1.35553 2.4309 2.4684 1.82524 2.95337 1.80327 1.84151 1.39371 0.86002 2.40053 1.3258 1.61969 1.09749 1.64311 1.40399 2.0993 2.28375 1.88309 1.52691 3.017 1.32607 1.44671 2.37992 1.26597 1.8094 1.3326 2.5488 1.49626 1.55767 1.92636 3.14355 1.36313 1.28962 2.94972 1.45701 1.52071 1.95134 0.958036 1.58115 2.47202 2.30115 1.19548 1.32651 1.51547 2.41977 1.49092 2.11675 1.12256 1.22242 2.09058 1.32722 1.49667 1.11587 2.12882 2.19118 1.20605 3.11243 1.55691 3.03737 0.925153 1.75169 1.44802 1.31509 1.53564 1.65806 1.28462 2.13311 2.02227 1.30542 1.98688 1.79865 1.40908 1.38626 2.44483 1.87549 1.74762 2.74911 0.994449 1.47076 1.89906 1.63675 2.36572 4.15457 1.10295 3.47952 1.95381 0.727506 1.43846 1.77821 1.21896 1.48019 1.33831 2.04424 1.48182 1.16204 1.35569 1.56797 1.57573 1.39037 1.40491 1.29937 1.35325 0.842334 1.66709 1.26729 1.39162 1.39586 1.75584 2.30892 4.35237 1.18867 0.979129 1.46513 1.66836 1.37258 2.27231 2.62768 1.66541 2.75585 1.22293 1.18283 2.48942 1.07334 1.64456 2.39434 3.66682 1.20312 1.59829 2.15709 2.14059 2.75851 2.02197 2.60611 1.52483 1.236 1.57299 1.631 1.06519 2.04767 2.98789 2.07986 1.02405 1.41983 1.70899 1.93284 2.66459 1.65173 2.14694 0.825645 2.37792 1.68747 3.08243 0.654258 2.07524 1.31036 1.35879 2.6957 3.74951 1.02016 1.38865 1.66309 1.58459 1.78579 2.64037 3.63342 2.29266 1.94955 1.58773 2.14728 1.49194 0.69114 1.82687 0.903567 1.92353 0.767106 2.73711 1.82049 1.48721 1.49568 2.13101 1.50124 1.90866 1.83871 1.92663 1.59766 1.10999 4.69623 1.61231 2.06759 2.58861 1.71897 1.39962 1.99805 0.849018 1.21646 1.80525 1.81964 2.43681 1.15971 1.51383 2.92137 1.94564 1.53132 1.44899 3.87115 2.27479 1.3527 2.01753 1.66244 1.59171 1.20646 0.996166 2.76848 1.47686 1.52869 1.68971 1.49923 1.05838 2.44862 2.63778 1.6229 1.9882 2.4786 2.41696 1.83603 1.65781 2.17469 1.6648 2.62639 1.15355 0.838605 1.41047 1.56685 1.85389 1.5013 1.27448 1.29998 1.94841 1.71102 1.72974 1.74432 1.63625 2.23079 2.4452 1.83227 0.998584 1.38618 1.54127 2.28858 2.09164 1.92472 1.77804 1.33349 2.5405 1.26378 1.42036 1.36213 2.52015 1.90004 1.96496 1.41411 1.62375 2.78608 2.09247 1.736 2.02119 2.09205 2.11511 2.26121 2.82357 1.31448 1.38989 1.69907 1.14934 2.61186 2.17811 1.83398 2.03123 2.00246 2.86412 1.16378 1.48729 1.9152 2.36621 0.937404 1.61914 1.58368 1.63597 1.59975 1.49796 2.031 2.31553 1.4105 2.02149 1.56033 3.52755 1.84811 2.55908 2.63581 2.90589 1.52715 1.72813 1.73614 2.05647 1.31934 1.35482 1.67438 2.04021 1.99224 1.38973 1.83526 1.59439 2.15742 1.14763 1.81071 1.79512 1.48985 2.01473 1.62634 1.27187 0.933651 1.68836 1.59926 1.67574 3.28317 1.17335 1.65753 1.39874 1.73839 2.65904 1.19772 1.98223 1.28398 1.79519 1.79745 1.54947 3.3448 2.11865 1.86162 1.46858 0.958888 1.30657 2.52738 1.01416 1.10697 1.76195 2.59568 2.55984 2.08178 1.3629 1.65341 1.94545 1.96747 1.54839 1.97143 2.10148 2.00449 1.46665 1.23011 1.81196 2.95625 1.77723 1.26142 1.64874 1.61258 1.58456 1.80861 1.67428 2.35175 3.8 2.99268 1.35469 2.59845 1.62711 2.96363 2.40643 2.31651 2.57623 1.52629 3.07567 1.83065 1.38038 1.76429 1.34437 1.38211 1.26792 1.17181 1.67359 2.32574 2.56634 1.46393 1.56983 1.49522 1.19864 1.52195 1.11342 2.53641 1.44417 2.26071 2.11812 0.712372 1.26124 1.39245 1.25119 1.2363 1.46598 1.78295 1.3278 1.1661 1.66476 2.13017 1.52085 3.75881 1.03024 0.872657 1.211 1.27809 1.40708 1.58656 1.93525 0.503112 2.72845 2.01228 1.78215 2.18271 0.954559 1.18298 1.9572 1.0429 1.68176 1.63961 1.67939 1.12484 0.779578 1.48636 4.51202 1.73044 1.3817 2.36717 1.15602 1.88254 2.63907 0.863246 1.75461 2.78053 2.14629 1.65454 1.84789 1.95602 0.928998 1.4604 2.00972 2.27516 1.83098 1.804 2.41762 1.5707 1.18355 1.46981 1.21999 1.27398 2.1168 2.05413 2.33006 1.70837 3.64829 3.21625 2.39099 1.90368 1.17421 1.90089 1.70668 2.42505 0.621455 2.41264 2.34266 2.50484 1.72327 3.31922 1.93711 1.67536 1.85505 1.19062 1.6432 1.96314 1.41558 3.31142 1.04541 1.3444 1.62536 2.5476 2.05731 1.93728 2.80278 2.84152 1.91217 1.27384 1.55769 2.33446 1.80695 2.97448 1.5344 2.99792 1.86219 1.04512 1.60039 2.14537 1.89443 0.939581 1.63146 1.78551 1.07926 1.77022 1.81089 1.91333 1.20921 2.58882 0.949221 1.71477 2.63409 1.77556 1.00856 1.82763 1.97418 2.12005 1.42221 1.40658 1.89956 1.66812 1.60458 1.62052 1.24415 1.35888 1.58965 1.4095 1.51989 1.30585 1.38476 1.5611 3.25304 1.50328 2.52345 1.94103 2.3508 1.75872 1.31717 2.68944 1.19468 2.11416 1.31899 1.66513 2.63328 1.81964 1.51864 1.54288 2.49423 2.43105 1.98075 3.49448 1.85828 1.74139 3.45554 1.58175 2.69044 1.50163 1.6617 1.46454 1.80376 1.57712 1.26661 1.75343 1.09996 2.7263 1.96026 1.42852 1.03595 1.58905 2.00965 1.72775 1.76466 1.72276 2.45507 1.6543 1.81832 1.64209 2.02277 1.77282 2.30689 1.77063 0.919579 2.16798 1.17008 1.67221 2.33599 1.04041 1.08774 1.37114 5.22547 1.27521 1.4267 1.70483 2.95472 1.28711 0.963813 1.07047 0.94572 1.57251 2.23019 1.72159 2.08426 4.46804 1.8775 1.08689 2.21844 1.19733 0.997028 1.33177 1.90521 2.83508 1.20778 1.63856 1.33946 1.87723 2.62483 3.04858 1.46095 2.76092 1.37638 2.17371 1.98201 1.41245 2.07975 1.51885 1.30611 1.78172 3.15063 3.20656 1.177 1.46912 1.59847 2.51995 1.18587 1.95632 2.52101 1.91241 1.92875 1.46969 2.75228 1.11165 1.43034 1.14732 1.3746 1.06455 1.12941 3.80035 1.76315 1.61531 1.40542 1.84349 1.6293 3.88968 1.2832 1.25527 2.11103 1.2714 1.5158 2.70542 3.04979 1.57602 2.40377 4.05443 2.5255 2.54997 3.09192 1.45812 1.27402 3.03337 2.87106 2.97193 1.43682 2.06722 2.03459 1.88089 ]
@@@ Frame-accuracy per-class: [ 76.295 63.2794 54.6917 53.6137 56.1798 21.1982 42.7099 76.6355 58.7244 75.9569 85.9714 30.5221 65.5375 64.385 40 53.3666 58.5698 11.3274 58.7177 65.704 67.0578 67.6571 63.4146 60.7033 46.7204 74.8515 58.9391 63.6511 63.2804 75.2877 79.1957 53.7385 72.8291 65.2977 82.9533 82.2737 84.9221 88.0853 56.1798 21.2454 45.9574 38.9234 35.4244 55.5404 72.6104 80.0427 55.9486 60.9844 72.9621 57.4479 86.906 66.6128 72.9498 57.7495 87.1425 69.4908 81.2862 52.5164 33.2016 72.8121 72.3746 45.2459 56.4809 55.4128 54.8223 60.7261 64.0654 69.7203 63.0037 61.4098 83.4919 66.1064 71.6872 49.7336 59.97 51.6129 62.2754 81.281 40.1766 74.9642 42.4947 67.0906 70.4033 55.3425 37.751 71.0805 60.274 31.9635 58.2078 55.8885 56.3667 33.7349 75.3117 51.4068 36.3636 45.4632 48.9262 61.7843 45.9242 56.6443 59.5084 64.5333 27.2328 64.2375 19.1781 54.9266 79.1111 69.4394 41.1881 68.9655 62.3181 60.8365 44.1826 60.7242 48.7696 67.7395 69.9175 60.2917 40.5546 66.0045 58.8381 75.9907 31.3883 58.4192 40.7733 73.9574 28.9679 60.8284 51.9906 72.3232 72.2635 59.8439 67.9739 59.9813 57.3082 55.0861 64.9796 37.1084 50.4523 57.3624 56.4175 58.9327 77.2577 61.4232 75.2475 60.251 58.7252 41.9092 52.4064 48.3891 49.2308 70.9005 64.3392 55.0953 71.953 53.6054 47.5452 64.918 67.4157 64.8045 34.9901 54.4901 74.3218 38.009 79.736 55.8659 77.4026 38.0952 63.4789 37.4728 72.2936 83.7438 48.2606 52.8705 45.7399 69.9938 69.0526 61.1642 74.6915 45.1559 57.3248 63.3694 69.6605 47.9303 77.0984 31.811 51.6364 69.288 51.399 61.8851 37.8251 54.0717 80.619 56.9801 63.568 68.4583 63.6448 46.9945 69.3419 56.2025 47.7876 54.5805 63.1579 63.8262 60.4588 67.0547 53.5393 58.6667 72.2444 41.194 72.3135 74.3777 34.9381 48.834 74.2298 65.1921 58.6724 66.899 24.7855 70.8434 71.3101 12.8755 62.3625 38.6412 14.3498 44.9043 51.7483 70.2473 73.5562 57.6271 66.5362 39.7284 58.8506 80.0522 54.8009 66.6667 52.8678 49.4903 70.124 48.5414 88.2665 55.7078 78.1395 70.0132 68.2569 45.6432 42.6877 61.8962 46.3768 76.6243 68.6567 62.9012 69.8545 70.1269 77.2247 55.3143 69.4737 28.9362 66.6667 73.0117 36.6972 20.9192 76.1905 52.7943 64.0747 74.7475 47.0588 59.4164 16.609 74.116 52.8804 69.6125 72.3208 45.6554 50.1762 60.3743 85.3512 22.0641 79.3665 21.1765 66.7041 46.8172 74.3694 37.8749 59.8425 70.1714 53.211 73.9539 63.1393 39.188 73.7798 71.9463 62.2356 54.7564 51.1628 51.3324 78.9006 43.9216 64.5403 70.8934 79.8201 52.3517 54.2902 68.9655 70.2863 73.3932 52.9551 77.4818 63.6528 54.5455 61.0757 48.3902 59.5483 72.7062 57.1429 77.3189 61.1521 65.6311 52.1525 72.1805 26.9504 31.3883 57.7362 71.6754 66.5912 38.5542 57.4822 45.1939 73.0988 70.2413 54.7368 36.865 57.0571 83.6571 50.0707 60.7407 66.6667 59.5918 57.069 67.423 69.2607 40.2651 57.3134 49.4477 52.6733 60.5598 48.3685 55.2189 58.1053 54.5972 49.2234 80.3059 57.8374 68.0162 46.0119 59.9509 74.8444 58.5198 58.9137 61.244 70.8458 28.1849 25.1969 76.9089 51.7205 50.4119 57.3066 30.7953 74.8216 51.6971 58.0038 63.1365 36.9427 74.6163 63.68 55.7864 72.5926 58.2109 77.7528 50.1742 49.1582 27.4809 55.6837 59.0164 59.1515 67.0927 40.3292 66.1479 39.3638 69.5109 69.6287 56.8889 64.9706 18.8437 59.7849 66.7864 65.8041 58.3658 31.1248 50.655 64.437 55.4723 45.9588 46.8609 66.0058 67.7266 68.1188 46.3079 82.6846 66.4254 70.2703 47.9419 69.7789 39.7661 65.9142 64.4983 68.5714 84.1372 63.9281 69.7291 64.5161 63.2035 50.9606 71.1986 64.5161 45.8234 43.9919 43.1062 43.2548 56.0554 67.4446 72.9654 52.1921 50.996 58.1095 47.7396 69.0279 70.008 75.9024 74.0527 75.8621 61.0022 60.8126 56.6948 48.6224 65.0819 57.4241 40.1003 76.3921 42.5532 42.5856 42.5856 42.5656 58.193 58.6797 79.0902 67.0423 53.8953 56.3674 41.4587 77.2923 45.1268 63.2541 56.3758 56.6586 47.4438 81.5577 63.3907 66.7697 16.7331 48.7356 35.6589 43.1227 73.6602 56.5158 71.3906 52.5822 50.1035 59.9856 53.8525 75.1491 70.4639 57.3044 65.9847 60.3471 25.6716 52.1031 71.722 54.2331 61.4357 53.0658 77.1904 65.618 55.7949 62.6395 41.4579 50.6122 71.6332 58.8369 47.6596 45.1253 29.4906 56.7232 45.7666 63.1193 68.8923 54.2816 26.178 45.0886 54.2529 35.9932 46.7139 60.6061 58.7537 74.0416 74.184 62.2837 64.4951 65.3282 45.1613 50.6722 48.6134 67.5838 57.554 61.3953 27.7895 59.348 67.4991 40.6709 67.9868 56.1955 69.0302 49.678 68.4284 49.5298 62.9933 18.1401 59.5989 64.4986 53.4899 70.746 49.593 67.8748 44.9927 60.2086 52.5843 36.3273 50.3497 80.8763 60.9186 48.2897 62.906 31.5152 48.7805 63.8487 60.2265 57.7416 49.7013 73.0435 51.8828 46.87 71.481 69.4517 32.6376 48.2652 63.4858 55.3936 48.4245 29.3878 44.396 50.0818 47.4923 63.5294 64.032 79.4136 54.2125 63.9438 58.7883 51.0345 46.72 37.0478 56.528 38.6233 53.3563 58.2375 57.4315 53.3971 39.1459 27.8552 66.7932 57.4648 41.841 52.5732 41.3862 61.0245 44.6497 65.4781 58.1006 58.7326 50.1007 76.8932 48.2972 45.663 47.0735 44.0367 69.0554 54.321 54.8066 60.9836 39.6677 51.9411 80 64.9351 69.6921 59.306 57.7181 53.0081 58.3016 52.5495 69.2194 73.7255 26.7769 78.0293 72.3404 41.5437 65.5118 54.4601 67.2176 34.6872 52.0805 74.7559 60.5788 49.5768 46.2436 72.8972 43.673 65.8354 45.6304 60.7832 62.5767 61.8378 50.2283 61.2574 62.1518 68.2599 72.1713 29.2784 20.9692 59.5024 61.959 54.33 49.4624 53.3566 63.6148 69.2051 39.5748 67.3597 71.6007 63.3745 53.9877 62.5971 76.0719 52.9563 47.6008 38.61 47.9263 50.4865 74.8957 19.7333 62.738 63.3053 59.9483 65.4643 72.301 54.1317 63.9821 63.0037 58.4318 41.9512 68.7023 67.7507 65.7102 46.2006 47.0046 69.8828 32.8665 25.0396 63.6977 55.6962 19.3012 27.991 44.031 67.2461 56.9191 49.0798 72.0274 67.2444 16.4384 42.0664 54.2282 59.3875 66.0525 54.4474 68.3181 82.4802 51.1712 58.3554 56.4103 76.5635 67.2052 47.4074 59.5336 58.0331 34.958 64.2497 59.6789 55.6671 70.8397 62.3104 51.2518 68.9655 59.6844 60.0321 65.2055 72.2174 65.8933 47.619 51.7906 26.3291 24.1546 38.4977 57.3754 2.36686 52.2954 45.4795 61.6229 55.5294 72.4763 64.64 59.7865 49.1118 40.0361 55.0047 40.7311 55.1971 49.1433 41.0774 38.3518 70.0925 62.7505 46.4516 71.5928 49.6703 74.1537 61.4357 58.3133 66.427 52.0885 54.6112 57.2232 42.3263 46.3499 61.4994 38.0306 37.2802 32.3777 67.1126 45.0063 64.8199 72.4324 46.9314 32.9298 50.2793 57.2903 58.698 31.9109 65.3386 59.8509 62.4621 55.6777 55.5676 38.7333 52.2648 39.0083 44.6352 53.6041 35.8306 69.0307 60.6943 50.0835 32.4484 32.8982 52.6572 57.8073 59.7776 55.3535 67.686 73.7327 64.7421 53.9363 58.2897 21.5589 55.5831 61.8238 44.4444 35.3909 21.0269 73.955 69.2652 43.326 58.4856 45.9279 48.6486 70.0998 42.5087 35.8744 67.33 75.5906 50.0416 59.5602 52.7256 37.7709 72.1754 64.4722 75.2998 56.5947 59.7422 54.5455 57.3379 34.1762 66.3529 50.9978 39.1837 53.5163 50.4046 53.3333 50.4505 42.5656 49.4579 55.7798 45.8509 63.2375 53.2905 76.2955 22.6365 73.3945 68.0768 48.7116 44.1791 44.0129 53.8953 69.3953 51.8135 59.9251 70.9191 7.67494 49.0486 53.0762 63.3381 43.2564 53.7815 45.0482 43.7137 38.6648 71.8796 39.8782 41.0042 56 62.1824 51.6385 45.4321 50.2674 60.1671 32 43.9344 64.9215 67.1952 51.0903 74.3051 38.6473 73.7107 60.5433 46.7081 76.8367 66.3094 23.8213 67.0978 65.0534 58.9421 67.7878 54.7486 63.4921 37.9487 52.3774 30.8911 58.6146 68.6779 64.5691 48.2916 25.7242 57.9634 76.9703 42.978 59.9553 50.6596 52.861 55.5184 70.4323 56.5815 50.4732 66.9413 67.3684 48.7939 26.2687 47.9042 39.0805 69.993 72.374 67.5229 59.1453 59.0985 69.2228 71.2899 74.7826 55.376 40.2402 66.8326 59.2122 36.272 57.188 61.2111 13.3942 61.5256 36.6197 35.8042 81.4558 40.9639 68.6391 56.3662 51.3369 41.9684 56.7627 56.492 53.5871 73.4799 68.1841 49.5812 33.7308 59.8131 61.2352 62.6391 13.8776 68.3744 60.3352 66.1909 53.0677 37.0107 58.3541 47.8589 69.9721 58.2393 46.0568 71.1864 60.3976 56.092 37.9832 57.3678 77.5066 72.4679 64.8238 60.7562 46.1028 58.8031 69.962 55.6017 71.4074 69.6414 46.8917 53.4469 74.2035 54.4 37.6238 46.5966 36.8098 71.6149 57.0766 43.7259 60.0601 24.649 43.2083 53.5932 43.5326 67.666 66.5281 36.9515 77.153 18.0049 59.9789 62.2735 53.5956 49.5114 79.037 63.2831 43.3147 68.1011 58.841 65.8307 60.4709 64.8318 32.491 70.0826 69.2737 42.8822 65.7439 74.0902 66.4344 61.0354 47.0922 37.6048 48.8518 60.7219 63.7146 46.9751 51.1025 52.4422 46.6606 50.9767 58.7678 33.7596 58.1158 52.3297 55.9342 24.8521 42.9851 45.3812 71.2084 65.2055 51.6385 52.1327 48.2321 45.7971 50.4993 48.7562 47.2362 65.7097 33.2494 47.1132 67.027 60.6523 43.7029 44.226 47.3616 59.9542 59.7647 45.9364 80.7596 36.0277 54.8185 69.3979 41.4961 80.8957 51.6517 50.5415 69.9104 58.363 29.7994 68.2256 51.2586 32.3054 25.71 57.6606 60.3662 37.9085 45.5581 59.4315 46.0666 66.7509 58.98 44.1379 57.2505 67.4326 35.2357 55.5603 21.1921 63.3158 64.3794 75.2858 57.1306 41.6337 52.012 57.0328 48.5535 33.291 62.3962 63.3472 43.8615 44.9931 47.8664 51.7834 46.8085 71.0485 28.4994 56.1774 70.8313 53.0351 64.2487 58.4431 61.4966 53.9326 21.0945 64.1711 60.2672 63.2633 55.5156 52.0482 49.1726 56.2989 65.3938 65.2015 32.8076 52.5633 58.4464 42.8928 57.9145 55.647 52.9349 50.2618 51.5115 46.9361 61.8834 45.6432 48.7239 31.454 66.1578 27.027 37.4165 73.4877 55.6263 60.3248 68.2353 51.9573 50.461 51.3465 55.2657 40.9938 26.5583 53.2326 62.4547 49.467 48.6322 35.8306 44.5006 59.7097 46.1688 24.918 53.7931 60.093 48.9552 65.627 56.6038 66.1217 46.3317 44.7257 67.0315 60.7764 48.1592 69.5652 53.5444 67.278 58.2738 38.2872 38.5471 34.4531 74.7051 50.6404 52.8836 46.0905 81.0475 51.0708 51.056 56.1131 76.1025 55.3191 39.7906 42.9129 54.446 43.7158 71.1434 22.7642 69.6562 45.6376 49.7577 63.7993 68.0938 47.619 56.8082 56.573 79.8709 53.6082 43.0063 54.2274 41.2556 60.4651 67.54 48.9906 47.7612 22.3572 54.6805 42.8795 42.5316 49.4037 48.6855 45.0939 41.0866 34.6821 79.297 79.6992 38.8467 40.0822 52.3587 18.0039 38.1487 28.5714 26.0688 42.623 57.032 58.6265 60.4514 60.733 66.3181 61.5978 34.0136 60.6607 54.9414 42.4432 60.0451 70.9022 68.5494 66.6667 63.6984 68.877 58.2101 55.6234 71.7469 57.4359 59.9327 37.4194 38.2306 44.9612 21.3084 53.5966 47.8235 58.3884 72.9478 40.7252 58.5931 59.3838 67.8529 55.2165 58.217 44.0033 39.8363 44.3572 53.4979 16.8498 59.4475 59.3128 35.3285 65.3009 48 67.6525 29.5371 54.4313 56.2544 46.1184 25.1852 70.0265 53.514 23.8202 57.0738 53.0414 48.6322 77.0093 54.9223 29.4058 35.6477 62.8337 62.6207 57.8497 34.6095 56.4633 49.3906 69.3088 64.4936 59.5745 65.2537 57.8486 69.6774 37.9585 39.489 64.7128 24.4694 59.6195 18.9112 75.9578 48 55.9814 62.4697 59.4639 52.2597 67.1964 40.5641 42.3592 60.7652 49.2669 50.2267 61.3705 57.2178 34.6582 43.5359 50.5096 23.7037 71.798 54.2995 47.3447 57.2781 33.4779 12.0383 68.0851 11.3744 45.0436 78.7692 58.5915 46.1197 61.1474 52.5458 61.6257 47.349 54.0633 66.4756 62.2296 56.4946 54.1799 53.4789 61.4562 67.4128 60.1889 78.2609 57.3402 67.9646 60.3774 59.3015 61.3333 40.5316 7.90514 65.8892 71.5252 59.1684 61.0932 55.9075 43.1683 29.6846 46.5116 28.1958 65.6422 64.5731 29.1032 62.3819 50.3243 31.03 12.6679 62.8246 55.8531 28.1938 50.4505 39.5778 40.3548 43.9024 61.2296 62.8629 60.6965 53.4995 66.2765 37.1542 26.6667 47.482 71.7406 61.0169 51.5118 43.3109 29.9139 43.8819 37.1295 74.8475 33.4405 52.7246 27.088 80.3205 41.6529 59.0164 62.3256 23.3276 25.2991 71.9518 64.9243 48.7766 57.0079 50.682 32.4455 12.2324 50.4348 41.9764 57.1914 37.3673 59.5603 75.8509 43.2432 73.3017 50.3937 77.4946 28.7719 44.0252 51.8318 56.5453 45.0867 52.9007 47.3307 52.9915 54.0952 48.4051 68.8951 11.2867 57.1992 48.4848 37.8188 55.0162 61.0425 44.2577 75.8621 66.1699 51.448 50.9878 30.1916 66.725 56.2991 29.1862 46.9438 51.9252 56.4012 17.6707 40.3941 57.5937 53.1835 49.1159 59.6206 66.2306 74.0313 18.6265 59.5829 56.0428 57.0533 55.9653 72.786 31.3324 36.1041 39.6761 46.2908 28.7437 30.5489 53.012 55.343 37.0821 46.7257 30.6748 63.06 75.616 54.2912 56.8694 46.6747 60.3816 61.9232 64.5465 46.0497 53.0949 53.1549 44.9093 53.1357 33.993 35.3254 48.6022 69.7524 56.2212 54.8416 24.8079 41.2214 43.1149 52.0788 59.6084 35.7069 62.096 58.6335 56.5766 23.5294 47.836 49.5957 57.9439 55.4992 32.0693 41.8473 47.619 46.7641 42.0221 36.3132 33.3025 24.3367 61.8982 55.7798 53.058 68.7541 29.3948 50.5263 50.8009 41.8741 42.7329 29.2509 70.4516 56.606 49.0756 36.0313 68.6907 58.9091 55.4629 55.523 57.7737 55.1943 46.6754 45.0593 59.3438 44.2413 53.4729 19.2385 47.8296 33.7008 33.116 24.9351 55.5869 53.0458 47.4517 38.3795 56.4211 55.8611 55.8635 43.7895 44.9481 60.7338 43.6931 52.0325 36.4964 61.7839 46.1307 49.0842 59.9705 39.6857 60.6466 64.6394 73.1067 49.062 56.5752 54.1033 22.7848 68.3465 57.0842 61.4965 48.4947 29.9795 63.7363 52.9551 66.5292 48.8656 52.77 53.0311 30.7942 46.2046 52.3077 55.8192 70.5515 64.8412 29.33 72.5984 69.1272 51.8519 29.0288 35.4515 41.7483 60.9895 53.3095 43.3735 47.3795 55.9557 47.1866 44.2147 46.729 56.1366 63.658 55.1181 21.7228 53.8725 62.6529 49.9205 52.0847 55.6117 47.7146 51.2821 35.324 12.4138 12.3077 63.0857 38.27 53.717 32.1569 30.3956 34.5631 34.7275 53.5918 20.9524 46.1692 55.1831 46.9136 65.0426 58.0977 65.0143 60.8814 51.9906 40.9877 35.9638 59.7876 56.176 60.523 61.3251 53.3762 67.9245 36.0385 63.1933 38.3795 40 77.0208 55.7758 60.5565 63.2371 69.1864 59.5924 49.6263 66.7651 67.4374 50.168 40.2626 54.2805 6.55738 67.0023 64.913 65.1399 65.2406 58.7473 54.6697 46.3822 84.1491 32.6376 45.0067 55.9006 36.0934 73.4191 69.8975 44.1273 69.4534 46.8473 57.9977 54.9747 68.5969 75.9142 56.4103 2.83286 55.0996 61.409 28.4932 64.6734 47.5712 30.2849 76.0662 59.7094 28.0657 40.5479 50.8009 48.7936 43.4505 72.8205 54.0925 40.5261 33.8109 53.8053 48.0931 32.9227 47.7759 64.907 55.0996 67.7323 67.0407 41.0619 47.2558 34.8754 57.665 20.0669 23.4234 32 52.2167 63.7657 50.1931 50.8287 40.213 83.078 34.1741 31.1534 35.4756 54.1586 28.9362 44.1598 57.6153 44.7542 68.0031 43.7276 41.7234 63.0739 23.3216 68.8078 63.97 53.76 40.2204 38.9497 47.8322 31.6492 31.6268 48.2364 57.3756 48.8624 36.8574 52.0301 21.8803 52.6142 29.2428 51.0638 72.1013 52.7039 39.6292 45.4795 69.5964 53.5986 47.2952 71.785 51.5343 48.4039 46.2038 69.8817 29.0271 74.0913 52.7859 30.896 47.7612 70.0842 45.6436 38.8564 43.0476 54.2636 57.4586 44.2877 47.4002 52.2503 55.5766 63.3074 59.6249 56.9014 49.3617 58.9342 62.2611 52.8799 56.9667 18.4127 52.8302 38.7895 45.8503 40.4598 54.5187 59.7874 23.0272 66.0895 36.2553 63.395 48.6267 28.3619 43.3878 59.1484 53.3049 34.5733 31.1147 42.2713 16.9908 49.0566 51.2524 22.0859 57.0538 31.4856 61.0932 47.8851 57.9286 56.765 55.6894 64.7202 56.4103 64.6495 22.6221 41.8985 54.1457 67.1127 49.3361 46.198 45.3803 49.5014 50.508 38.0038 57.5322 48.4812 55.9078 35.8655 56.5901 35.6129 46.0543 73.4562 44.2186 63.6495 57.4118 36.5422 68.4033 71.5232 56.9536 3.27198 65.9117 59.6811 44.2159 21.844 64.1425 72.0883 71.4113 70.195 50.0695 24.8447 51.5762 42.3784 5.84795 48.5437 66.3738 38.2838 64.0596 68.6137 63.0856 49.4118 27.8919 65.665 55.5224 61.64 54.4 26.605 33.0159 57.5646 27.3973 61.2597 42.376 40.5195 66.8657 44.5469 55.7154 65.9392 53.443 17.4274 21.6319 68.5598 63.4823 52.7407 29.7578 66.6667 49.9529 32.4082 51.8919 49.7561 61.76 30.1476 67.6278 62.2837 68.8215 68.7293 70.134 68.0266 14.5141 46.4066 55.5989 62.5369 54.2529 56.6254 16.2162 61.8638 65.2417 43.7383 68.8576 60.0203 29.7436 27.3038 56.6149 29.1834 26.8456 31.9202 36.6355 25.5088 57.523 67.8774 19.9005 24.9729 33.9703 61.0742 45.4695 46.493 44.1496 ]

LOG (nnet-train-frmshuff[5.5.734~1-794732a]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.40287 (Xent), [AvgXent: 1.40287, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 59.8108% <<

